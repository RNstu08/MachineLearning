{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa21adeb-11aa-499b-9802-f4473319ba0e",
   "metadata": {},
   "source": [
    "While a single train/validation split helps, the performance measured on that one validation set can be sensitive to which specific data points ended up in the split. Cross-validation provides a more reliable and robust estimate of a model's generalization performance by systematically using different portions of the data for training and validation.\n",
    "\n",
    "## Cross-Validation (CV) for Model Evaluation\n",
    "\n",
    "This document covers:\n",
    "\n",
    "* **Rationale:** Explains why CV gives a more reliable performance estimate than a single split.\n",
    "* **K-Fold CV:** Describes the process and shows implementation using `KFold` and `cross_val_score`.\n",
    "* **Stratified K-Fold CV:** Explains its importance for classification and demonstrates its use. Highlights that it's often the default for classifiers in `cross_val_score`.\n",
    "* **Other Strategies:** Briefly mentions Leave-One-Out CV (`LOOCV`) and `ShuffleSplit`.\n",
    "* **`cross_validate`:** Shows how to use this function to get more detailed results, including multiple metrics and timing information.\n",
    "* **When to Use:** Clarifies that CV is primarily used during the model development phase on the training data for tuning and selection, before a final evaluation on the separate test set.\n",
    "\n",
    "---\n",
    "\n",
    "Cross-validation is a cornerstone technique for building reliable machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880b6dae-a1b5-4ebe-af97-146bf6837c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Iris Dataset ---\n",
      "Scaled Data shape: X=(150, 4), y=(150,)\n",
      "------------------------------\n",
      "--- K-Fold Cross-Validation ---\n",
      "KFold strategy: KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "\n",
      "K-Fold Scores (Accuracy per fold): [0.96666667 0.83333333 0.9        0.9        0.93333333]\n",
      "Mean K-Fold Accuracy: 0.9067\n",
      "Standard Deviation of K-Fold Accuracy: 0.0442\n",
      "--------------------\n",
      "--- Stratified K-Fold Cross-Validation ---\n",
      "StratifiedKFold strategy: StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "\n",
      "Stratified K-Fold Scores (Accuracy per fold): [0.93333333 0.96666667 0.8        0.93333333 0.86666667]\n",
      "Mean Stratified K-Fold Accuracy: 0.9000\n",
      "Standard Deviation of Stratified K-Fold Accuracy: 0.0596\n",
      "------------------------------\n",
      "--- Other CV Strategies ---\n",
      "- LeaveOneOutCV (LOOCV): K = number of samples. Expensive.\n",
      "- ShuffleSplit: Creates independent random splits.\n",
      "------------------------------\n",
      "--- Using cross_validate ---\n",
      "Cross-Validate Results (DataFrame):\n",
      "   fit_time  score_time  test_accuracy  train_accuracy  test_precision_macro  \\\n",
      "0  0.001534    0.006426       1.000000        0.966667              1.000000   \n",
      "1  0.001361    0.005459       0.966667        0.975000              0.969697   \n",
      "2  0.001269    0.005870       0.900000        0.983333              0.902357   \n",
      "3  0.001306    0.005239       1.000000        0.966667              1.000000   \n",
      "4  0.001263    0.005322       0.900000        0.975000              0.902357   \n",
      "\n",
      "   train_precision_macro  test_recall_macro  train_recall_macro  \\\n",
      "0               0.967419           1.000000            0.966667   \n",
      "1               0.975193           0.966667            0.975000   \n",
      "2               0.983333           0.900000            0.983333   \n",
      "3               0.966667           1.000000            0.966667   \n",
      "4               0.975193           0.900000            0.975000   \n",
      "\n",
      "   test_f1_macro  train_f1_macro  \n",
      "0       1.000000        0.966646  \n",
      "1       0.966583        0.974996  \n",
      "2       0.899749        0.983333  \n",
      "3       1.000000        0.966667  \n",
      "4       0.899749        0.974996  \n",
      "\n",
      "Average Test Scores:\n",
      "  - accuracy: 0.9533 (+/- 0.1011)\n",
      "  - precision_macro: 0.9549 (+/- 0.0990)\n",
      "  - recall_macro: 0.9533 (+/- 0.1011)\n",
      "  - f1_macro: 0.9532 (+/- 0.1014)\n",
      "\n",
      "Average Fit Time: 0.0013s\n",
      "------------------------------\n",
      "--- When to Use CV ---\n",
      "- Primary Use: During model development on the *training data portion*.\n",
      "  - Hyperparameter Tuning (e.g., inside GridSearchCV/RandomizedSearchCV).\n",
      "  - Model Selection (comparing different algorithms reliably).\n",
      "- It provides a more robust estimate of how a model configuration is likely\n",
      "  to perform on unseen data compared to a single validation set.\n",
      "- The *final* evaluation of the *chosen* model configuration should still\n",
      "  be done on the completely held-out *test set*.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, cross_validate,\n",
    "                                     KFold, StratifiedKFold, LeaveOneOut, ShuffleSplit)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression # Example model\n",
    "from sklearn.svm import SVC # Another example model\n",
    "from sklearn.metrics import accuracy_score, make_scorer # For custom scoring if needed\n",
    "\n",
    "# --- 1. Rationale for Cross-Validation ---\n",
    "# - A single train/validation split's performance metric can be noisy or biased\n",
    "#   depending on which data points land in the validation set.\n",
    "# - CV provides a more stable and reliable estimate of model performance by\n",
    "#   training and evaluating the model on multiple different subsets of the data.\n",
    "# - It uses the available data more efficiently, as each data point gets used\n",
    "#   for both training and validation across the different iterations (folds).\n",
    "\n",
    "# --- 2. Load and Prepare Data ---\n",
    "# Using Iris dataset\n",
    "print(\"--- Loading Iris Dataset ---\")\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# IMPORTANT NOTE: CV is typically performed *after* an initial train-test split,\n",
    "# using only the *training portion* (e.g., X_train_val, y_train_val from Section II)\n",
    "# for model selection and hyperparameter tuning.\n",
    "# The final test set (e.g., X_final_test, y_final_test) is still held out for the\n",
    "# very final evaluation *after* CV and tuning are complete.\n",
    "\n",
    "# For simplicity in demonstrating CV mechanics here, we'll use the *entire* X and y,\n",
    "# but remember this isn't the standard practice for final model evaluation.\n",
    "# We still scale the data first.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Scaled Data shape: X={X_scaled.shape}, y={y.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. K-Fold Cross-Validation ---\n",
    "# The most common CV technique.\n",
    "# 1. Split: The data (typically the training set) is divided into 'k' equal-sized,\n",
    "#    non-overlapping subsets called \"folds\". Common values for k are 5 or 10.\n",
    "# 2. Iterate: The process runs for 'k' iterations. In each iteration 'i':\n",
    "#    - Fold 'i' is used as the validation set.\n",
    "#    - The remaining 'k-1' folds are combined to form the training set.\n",
    "#    - The model is trained on the training folds and evaluated on the validation fold.\n",
    "# 3. Aggregate: The evaluation scores from the 'k' iterations are collected,\n",
    "#    and typically the mean and standard deviation are reported.\n",
    "\n",
    "print(\"--- K-Fold Cross-Validation ---\")\n",
    "# Define the model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Define the K-Fold strategy\n",
    "# shuffle=True is recommended to randomize data order before splitting.\n",
    "# random_state ensures reproducibility of the shuffle.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"KFold strategy: {kf}\")\n",
    "\n",
    "# Use cross_val_score to get scores for each fold\n",
    "# cv=kf tells it to use our defined KFold strategy.\n",
    "# scoring='accuracy' specifies the metric.\n",
    "scores_kfold = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nK-Fold Scores (Accuracy per fold): {scores_kfold}\")\n",
    "print(f\"Mean K-Fold Accuracy: {scores_kfold.mean():.4f}\")\n",
    "print(f\"Standard Deviation of K-Fold Accuracy: {scores_kfold.std():.4f}\")\n",
    "# Note: KFold doesn't preserve class ratios, which can be problematic for classification.\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# --- 4. Stratified K-Fold Cross-Validation ---\n",
    "# Variation of K-Fold specifically for *classification* tasks.\n",
    "# Ensures that the proportion of samples for each class is approximately\n",
    "# the same in each fold as in the original dataset.\n",
    "# Generally preferred over standard K-Fold for classification.\n",
    "\n",
    "print(\"--- Stratified K-Fold Cross-Validation ---\")\n",
    "# Define the Stratified K-Fold strategy\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"StratifiedKFold strategy: {skf}\")\n",
    "\n",
    "# Use cross_val_score with StratifiedKFold\n",
    "# Note: If you pass an integer (e.g., cv=5) to cross_val_score for a classifier,\n",
    "# it usually defaults to StratifiedKFold automatically. Explicitly defining it is clearer.\n",
    "scores_skf = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nStratified K-Fold Scores (Accuracy per fold): {scores_skf}\")\n",
    "print(f\"Mean Stratified K-Fold Accuracy: {scores_skf.mean():.4f}\")\n",
    "print(f\"Standard Deviation of Stratified K-Fold Accuracy: {scores_skf.std():.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Other CV Strategies (Brief Mention) ---\n",
    "print(\"--- Other CV Strategies ---\")\n",
    "# a) Leave-One-Out CV (LOOCV)\n",
    "# A special case of K-Fold where K equals the number of samples (N).\n",
    "# Each fold contains exactly one sample. Trains N models.\n",
    "# Computationally expensive but provides a nearly unbiased estimate (high variance).\n",
    "# loo = LeaveOneOut()\n",
    "# scores_loo = cross_val_score(model, X_scaled, y, cv=loo, scoring='accuracy')\n",
    "# print(f\"\\nMean LOOCV Accuracy: {scores_loo.mean():.4f} (computationally expensive)\")\n",
    "\n",
    "# b) ShuffleSplit\n",
    "# Randomly samples a specified number of train/test splits. Folds can overlap.\n",
    "# Useful for large datasets or when controlling the exact number of iterations is desired.\n",
    "# ss = ShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "# scores_ss = cross_val_score(model, X_scaled, y, cv=ss, scoring='accuracy')\n",
    "# print(f\"\\nMean ShuffleSplit Accuracy (10 splits): {scores_ss.mean():.4f}\")\n",
    "print(\"- LeaveOneOutCV (LOOCV): K = number of samples. Expensive.\")\n",
    "print(\"- ShuffleSplit: Creates independent random splits.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 6. Using cross_validate for More Details ---\n",
    "# cross_validate provides more information than cross_val_score, such as:\n",
    "# - Fit time per fold\n",
    "# - Score time per fold\n",
    "# - Multiple evaluation metrics simultaneously\n",
    "# - Optionally, the training scores per fold\n",
    "\n",
    "print(\"--- Using cross_validate ---\")\n",
    "model_svc = SVC(kernel='rbf', C=1.0, random_state=42) # Use a different model example\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(model_svc, X_scaled, y,\n",
    "                            cv=cv_strategy,\n",
    "                            scoring=scoring_metrics,\n",
    "                            return_train_score=True) # Get training scores too\n",
    "\n",
    "# Display results (converting dict to DataFrame is nice)\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "print(\"Cross-Validate Results (DataFrame):\")\n",
    "print(cv_results_df)\n",
    "\n",
    "# Calculate and print average test scores\n",
    "print(\"\\nAverage Test Scores:\")\n",
    "for metric in scoring_metrics:\n",
    "    mean_score = cv_results_df[f'test_{metric}'].mean()\n",
    "    std_score = cv_results_df[f'test_{metric}'].std()\n",
    "    print(f\"  - {metric}: {mean_score:.4f} (+/- {std_score*2:.4f})\")\n",
    "\n",
    "print(f\"\\nAverage Fit Time: {cv_results_df['fit_time'].mean():.4f}s\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 7. When to Use Cross-Validation ---\n",
    "print(\"--- When to Use CV ---\")\n",
    "print(\"- Primary Use: During model development on the *training data portion*.\")\n",
    "print(\"  - Hyperparameter Tuning (e.g., inside GridSearchCV/RandomizedSearchCV).\")\n",
    "print(\"  - Model Selection (comparing different algorithms reliably).\")\n",
    "print(\"- It provides a more robust estimate of how a model configuration is likely\")\n",
    "print(\"  to perform on unseen data compared to a single validation set.\")\n",
    "print(\"- The *final* evaluation of the *chosen* model configuration should still\")\n",
    "print(\"  be done on the completely held-out *test set*.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f4663-4e48-44d5-bf7b-008773f6c940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
