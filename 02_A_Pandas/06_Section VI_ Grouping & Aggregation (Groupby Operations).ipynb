{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9ac707-2282-4e45-9d48-c5e55294d54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample DataFrame ---\n",
      "  Store Product  Sales  Quantity Region\n",
      "0     A   Apple    100        10  North\n",
      "1     B  Orange    150        15  North\n",
      "2     A  Banana     80         8  South\n",
      "3     C   Apple    200        20  South\n",
      "4     B  Banana    120        12  North\n",
      "5     C  Orange     90         9  South\n",
      "6     A   Apple    110        11  North\n",
      "7     B  Orange    160        16  North\n",
      "8     C  Banana     70         7  South\n",
      "------------------------------\n",
      "--- Grouping ---\n",
      "GroupBy object (grouped by 'Store'):\n",
      " <pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001F6A7978830>\n",
      "\n",
      "GroupBy object (grouped by 'Region', 'Store'):\n",
      " <pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001F6A7932D50>\n",
      "\n",
      "Iterating through groups ('Store'):\n",
      "\n",
      "Group Name (Store): A\n",
      "  Store Product  Sales  Quantity Region\n",
      "0     A   Apple    100        10  North\n",
      "2     A  Banana     80         8  South\n",
      "6     A   Apple    110        11  North\n",
      "\n",
      "Group Name (Store): B\n",
      "  Store Product  Sales  Quantity Region\n",
      "1     B  Orange    150        15  North\n",
      "4     B  Banana    120        12  North\n",
      "7     B  Orange    160        16  North\n",
      "\n",
      "Group Name (Store): C\n",
      "  Store Product  Sales  Quantity Region\n",
      "3     C   Apple    200        20  South\n",
      "5     C  Orange     90         9  South\n",
      "8     C  Banana     70         7  South\n",
      "--------------------\n",
      "\n",
      "SeriesGroupBy object (grouped 'Sales' by 'Store'):\n",
      " <pandas.core.groupby.generic.SeriesGroupBy object at 0x000001F6A7979940>\n",
      "------------------------------\n",
      "--- Aggregation ---\n",
      "Sum per Store (applied to all numerical columns):\n",
      "                   Product  Sales  Quantity           Region\n",
      "Store                                                      \n",
      "A        AppleBananaApple    290        29  NorthSouthNorth\n",
      "B      OrangeBananaOrange    430        43  NorthNorthNorth\n",
      "C       AppleOrangeBanana    360        36  SouthSouthSouth\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1942\u001b[39m     res_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[39m, in \u001b[36mGroupBy.mean.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2452\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._cython_agg_general(\n\u001b[32m   2453\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2454\u001b[39m         alt=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2455\u001b[39m         numeric_only=numeric_only,\n\u001b[32m   2456\u001b[39m     )\n\u001b[32m   2457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6541\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6547\u001b[39m     **kwargs,\n\u001b[32m   6548\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12414\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12415\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12418\u001b[39m     **kwargs,\n\u001b[32m  12419\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12421\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12375\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12379\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6453\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6454\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6455\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6456\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6457\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1700\u001b[39m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1701\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert string \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1702\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert string 'AppleBananaApple' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSum per Store (applied to all numerical columns):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, grouped_by_store.sum())\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Calculate mean for each store\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMean per Store:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[43mgrouped_by_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# Deprecation warning might appear, use numeric_only=True if needed\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Calculate mean for each store (explicitly selecting numeric columns)\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMean per Store (numeric_only=True):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, grouped_by_store.mean(numeric_only=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2445\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2446\u001b[39m         grouped_mean,\n\u001b[32m   2447\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2448\u001b[39m         engine_kwargs,\n\u001b[32m   2449\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2450\u001b[39m     )\n\u001b[32m   2451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2452\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2453\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2454\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2456\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   1995\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   1996\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1999\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33midxmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33midxmax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[39m, in \u001b[36mBlockManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blk.is_object:\n\u001b[32m   1466\u001b[39m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[32m   1467\u001b[39m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[32m   1468\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk._split():\n\u001b[32m-> \u001b[39m\u001b[32m1469\u001b[39m         applied = \u001b[43msb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1470\u001b[39m         result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m   1471\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[39m, in \u001b[36mBlock.apply\u001b[39m\u001b[34m(self, func, **kwargs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, **kwargs) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    389\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    one\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m     result = maybe_coerce_values(result)\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._split_op_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1992\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   1994\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1995\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mG:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1944\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1945\u001b[39m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1946\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ser.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m   1949\u001b[39m     res_values = res_values.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Prepare Sample Data ---\n",
    "data = {\n",
    "    'Store': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Product': ['Apple', 'Orange', 'Banana', 'Apple', 'Banana', 'Orange', 'Apple', 'Orange', 'Banana'],\n",
    "    'Sales': [100, 150, 80, 200, 120, 90, 110, 160, 70],\n",
    "    'Quantity': [10, 15, 8, 20, 12, 9, 11, 16, 7],\n",
    "    'Region': ['North', 'North', 'South', 'South', 'North', 'South', 'North', 'North', 'South']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- Sample DataFrame ---\")\n",
    "print(df)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 2. The Split-Apply-Combine Strategy ---\n",
    "# 1. Split: Divide the data into groups based on specified keys (e.g., 'Store', 'Region').\n",
    "# 2. Apply: Apply a function to each group independently (e.g., sum(), mean(), count(), custom function).\n",
    "# 3. Combine: Combine the results of the function application into a new data structure (Series or DataFrame).\n",
    "\n",
    "\n",
    "# --- 3. Grouping (`.groupby()`) ---\n",
    "# Creates a GroupBy object, which holds information about the groups.\n",
    "# No computation is done until an action (aggregation, transformation, filter) is called.\n",
    "\n",
    "print(\"--- Grouping ---\")\n",
    "\n",
    "# Group by a single column ('Store')\n",
    "grouped_by_store = df.groupby('Store')\n",
    "print(\"GroupBy object (grouped by 'Store'):\\n\", grouped_by_store) # Shows the object type\n",
    "\n",
    "# Group by multiple columns ('Region', 'Store')\n",
    "grouped_by_region_store = df.groupby(['Region', 'Store'])\n",
    "print(\"\\nGroupBy object (grouped by 'Region', 'Store'):\\n\", grouped_by_region_store)\n",
    "\n",
    "# Iterating through groups (useful for understanding)\n",
    "print(\"\\nIterating through groups ('Store'):\")\n",
    "for name, group_df in grouped_by_store:\n",
    "    print(f\"\\nGroup Name (Store): {name}\")\n",
    "    print(group_df) # group_df is a DataFrame containing only rows for that group\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Selecting a column after grouping\n",
    "# This creates a SeriesGroupBy object, ready for aggregation on that specific column\n",
    "sales_grouped_by_store = grouped_by_store['Sales']\n",
    "print(\"\\nSeriesGroupBy object (grouped 'Sales' by 'Store'):\\n\", sales_grouped_by_store)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Aggregation ---\n",
    "# Applying functions that reduce each group to a single summary value.\n",
    "\n",
    "print(\"--- Aggregation ---\")\n",
    "\n",
    "# a) Using built-in aggregation methods directly on the GroupBy object\n",
    "# Applies the function to all valid (usually numerical) columns\n",
    "\n",
    "# Calculate sum for each store\n",
    "print(\"Sum per Store (applied to all numerical columns):\\n\", grouped_by_store.sum())\n",
    "\n",
    "# Calculate mean for each store\n",
    "print(\"\\nMean per Store:\\n\", grouped_by_store.mean()) # Deprecation warning might appear, use numeric_only=True if needed\n",
    "\n",
    "# Calculate mean for each store (explicitly selecting numeric columns)\n",
    "print(\"\\nMean per Store (numeric_only=True):\\n\", grouped_by_store.mean(numeric_only=True))\n",
    "\n",
    "\n",
    "# Calculate size of each group (includes NaN, returns Series)\n",
    "print(\"\\nSize per Store (.size()):\\n\", grouped_by_store.size())\n",
    "\n",
    "# Calculate count of non-NA values in each column per group (returns DataFrame)\n",
    "print(\"\\nCount per Store (.count()):\\n\", grouped_by_store.count())\n",
    "\n",
    "# Other common methods: .median(), .std(), .var(), .min(), .max(), .first(), .last(), .nunique()\n",
    "print(\"\\nMax Sales per Store:\\n\", grouped_by_store['Sales'].max()) # Aggregate on a specific column\n",
    "print(\"\\nNumber of unique products per Store:\\n\", grouped_by_store['Product'].nunique())\n",
    "\n",
    "# Aggregation with multiple grouping keys\n",
    "print(\"\\nMean Sales & Quantity per Region and Store:\\n\", grouped_by_region_store[['Sales', 'Quantity']].mean())\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# b) Using the .agg() or .aggregate() method for more flexibility\n",
    "# Apply multiple aggregation functions at once\n",
    "agg_funcs = ['sum', 'mean', 'count']\n",
    "agg_results = grouped_by_store['Sales'].agg(agg_funcs)\n",
    "print(f\"Multiple aggregations on 'Sales' ({agg_funcs}):\\n\", agg_results)\n",
    "\n",
    "# Apply different functions to different columns using a dictionary\n",
    "agg_dict = {\n",
    "    'Sales': ['sum', 'mean'],       # Apply sum and mean to Sales\n",
    "    'Quantity': 'sum',              # Apply sum to Quantity\n",
    "    'Product': 'nunique'            # Apply nunique to Product\n",
    "}\n",
    "agg_dict_results = grouped_by_store.agg(agg_dict)\n",
    "print(\"\\nDifferent aggregations per column using .agg(dict):\\n\", agg_dict_results)\n",
    "\n",
    "# Rename aggregated columns using tuples in the dictionary\n",
    "agg_dict_rename = {\n",
    "    'Sales': ('TotalSales', 'sum'),\n",
    "    'Quantity': ('AvgQuantity', 'mean'),\n",
    "    'Product': ('UniqueProducts', 'nunique')\n",
    "}\n",
    "try:\n",
    "    # This syntax requires pandas >= 1.5 (approximately)\n",
    "     agg_dict_rename_results = grouped_by_store.agg(\n",
    "         TotalSales=pd.NamedAgg(column='Sales', aggfunc='sum'),\n",
    "         AvgQuantity=pd.NamedAgg(column='Quantity', aggfunc='mean'),\n",
    "         UniqueProducts=pd.NamedAgg(column='Product', aggfunc='nunique')\n",
    "     )\n",
    "     print(\"\\nAggregations with renamed columns using NamedAgg:\\n\", agg_dict_rename_results)\n",
    "except AttributeError:\n",
    "     # Older pandas versions might use a different tuple syntax (less explicit)\n",
    "     # This older syntax might be deprecated or removed in future versions.\n",
    "     try:\n",
    "         agg_dict_rename_results_old = grouped_by_store.agg(**agg_dict_rename)\n",
    "         print(\"\\nAggregations with renamed columns (older syntax):\\n\", agg_dict_rename_results_old)\n",
    "     except Exception as e:\n",
    "         print(f\"\\nCould not use older rename syntax either: {e}\")\n",
    "\n",
    "# Apply custom aggregation functions\n",
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "\n",
    "agg_custom = grouped_by_store['Sales'].agg(['sum', peak_to_peak])\n",
    "print(\"\\nAggregation with custom function (peak_to_peak):\\n\", agg_custom)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Transformation (`.transform()`) ---\n",
    "# Applies a function group-wise but returns a result with the *same index* as the original DataFrame.\n",
    "# Useful for standardizing data within groups or filling missing values group-wise.\n",
    "\n",
    "print(\"--- Transformation (.transform()) ---\")\n",
    "\n",
    "# Example: Standardize Sales within each Store (z-score)\n",
    "# z = (x - mean) / std\n",
    "zscore = lambda x: (x - x.mean()) / x.std()\n",
    "df['Sales_ZScore_Store'] = grouped_by_store['Sales'].transform(zscore)\n",
    "print(\"DataFrame with Sales Z-Score calculated per Store:\\n\", df[['Store', 'Sales', 'Sales_ZScore_Store']])\n",
    "\n",
    "# Example: Fill missing values with the group mean (imagine 'Sales' had NaNs)\n",
    "# df['Sales_Filled'] = df.groupby('Store')['Sales'].transform(lambda x: x.fillna(x.mean()))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 6. Filtering (`.filter()`) ---\n",
    "# Keeps or discards entire groups based on a boolean condition evaluated per group.\n",
    "# The function passed to .filter() should return True (keep group) or False (discard group).\n",
    "\n",
    "print(\"--- Filtering (.filter()) ---\")\n",
    "\n",
    "# Keep only stores where the total sales are greater than 300\n",
    "df_filtered_sales = grouped_by_store.filter(lambda group: group['Sales'].sum() > 300)\n",
    "print(\"Filtered DataFrame (only groups where sum(Sales) > 300):\\n\", df_filtered_sales)\n",
    "\n",
    "# Keep only stores that sold more than 1 unique product type\n",
    "df_filtered_products = grouped_by_store.filter(lambda group: group['Product'].nunique() > 1)\n",
    "print(\"\\nFiltered DataFrame (only groups with > 1 unique product):\\n\", df_filtered_products)\n",
    "\n",
    "# Keep only regions where the average quantity is >= 10\n",
    "df_filtered_region_qty = grouped_by_region_store.filter(lambda group: group['Quantity'].mean() >= 10)\n",
    "print(\"\\nFiltered DataFrame (only Region/Store groups where mean(Quantity) >= 10):\\n\", df_filtered_region_qty)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1753da-5552-4fba-840f-3b7285c7aacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
