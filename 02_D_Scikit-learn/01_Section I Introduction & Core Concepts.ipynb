{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6c88bd-abc2-49e5-a4b0-93c5326d23f6",
   "metadata": {},
   "source": [
    "## I. Introduction & Core Concepts\n",
    "\n",
    "This section covers the fundamentals of the Scikit-learn library.\n",
    "\n",
    "### 1. What is Scikit-learn?\n",
    "\n",
    "* **Purpose:** Scikit-learn (often imported as `sklearn`) is the most widely used Python library for \"traditional\" machine learning (i.e., non-deep learning). It provides a comprehensive set of tools for building ML models, including algorithms for classification, regression, clustering, and dimensionality reduction, as well as utilities for preprocessing data, selecting features, evaluating models, and tuning parameters.\n",
    "* **Strengths:**\n",
    "    * **Wide Range of Algorithms:** Covers most standard ML tasks.\n",
    "    * **Preprocessing Tools:** Excellent utilities for cleaning and transforming data (scaling, encoding, imputation).\n",
    "    * **Model Evaluation:** Robust methods for assessing model performance and generalizability (cross-validation, metrics).\n",
    "    * **Consistent API:** A uniform interface across different algorithms makes it easy to swap models.\n",
    "    * **Efficiency:** Many algorithms are optimized using `NumPy`, `SciPy`, and Cython.\n",
    "    * **Great Documentation:** Extensive user guides, examples, and API references.\n",
    "* **Dependencies:** Built upon Python's core scientific libraries: `NumPy` (for array manipulation) and `SciPy` (for scientific computations). It often integrates with `Matplotlib`/`Seaborn` for visualization and `Pandas` for data handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039bca5-ba85-4f5d-86aa-153e13ed6f36",
   "metadata": {},
   "source": [
    "## 2. Installation\n",
    "\n",
    "If you don't have it installed, you can typically install it using pip:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "(Note: The import name is `sklearn`, but the package name for installation is `scikit-learn`).\n",
    "\n",
    "## 3. Key Design Principles\n",
    "\n",
    "Scikit-learn follows several key principles that make it user-friendly and powerful:\n",
    "\n",
    "* **Consistency:** All objects share a common, simple interface centered around the Estimator API (see below).\n",
    "* **Inspection:** Model parameters and results are stored as public attributes on the estimator objects after fitting (e.g., `model.coef_`).\n",
    "* **Sensible Defaults:** Algorithms have default parameter values that work reasonably well in many cases, making it easy to get started.\n",
    "* **Composition:** Easily combine multiple steps (like preprocessing and modeling) using tools like `Pipeline`.\n",
    "\n",
    "## 4. The Estimator API\n",
    "\n",
    "This is the heart of Scikit-learn's consistency. Most objects in the library are \"estimators\" and follow this pattern:\n",
    "\n",
    "* **Instantiation:** You create an instance of an estimator class, setting its hyperparameters (parameters not learned from data).\n",
    "  ```python\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  model = LinearRegression(fit_intercept=True)\n",
    "  ```\n",
    "* **Fitting:** The estimator learns from the data using the `fit()` method.\n",
    "    * Supervised learning (needs features `X` and target `y`): `estimator.fit(X, y)`\n",
    "    * Unsupervised learning (needs only features `X`): `estimator.fit(X)`\n",
    "* **Prediction/Transformation:** Once fitted, the estimator can perform tasks:\n",
    "    * `estimator.predict(X_new)`: Make predictions on new data (Classification/Regression).\n",
    "    * `estimator.predict_proba(X_new)`: Get probability estimates for each class (Classification).\n",
    "    * `estimator.transform(X_new)`: Apply data transformation (Preprocessing/Dimensionality Reduction).\n",
    "    * `estimator.fit_transform(X)`: A convenience method to fit and transform on the same data (often more efficient than calling `fit` then `transform`).\n",
    "* **Evaluation:** Estimators often have a `score()` method providing a default evaluation metric.\n",
    "    * `estimator.score(X_test, y_test)` (Supervised)\n",
    "    * `estimator.score(X_test)` (Unsupervised, metric depends on estimator)\n",
    "\n",
    "## 5. Data Representation\n",
    "\n",
    "Scikit-learn expects data primarily in these formats:\n",
    "\n",
    "* **Features (`X`):** A 2D array-like structure (`NumPy` array, `Pandas` `DataFrame`, `SciPy` sparse matrix) where rows represent samples and columns represent features. Should generally be numeric.\n",
    "* **Target (`y`):** A 1D array-like structure (`NumPy` array, `Pandas` `Series`) containing the target values (numbers for regression, class labels/integers for classification) corresponding to the rows in `X`.\n",
    "\n",
    "## 6. Loading Example Datasets\n",
    "\n",
    "Scikit-learn includes several small standard datasets within the `sklearn.datasets` module, useful for examples and testing.\n",
    "\n",
    "```python\n",
    "# --- Quick Example ---\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 1. Load Data\n",
    "iris = load_iris()\n",
    "X = iris.data # Features (NumPy array)\n",
    "y = iris.target # Target (NumPy array)\n",
    "print(f\"Feature shape: {X.shape}\") # (150 samples, 4 features)\n",
    "print(f\"Target shape: {y.shape}\") # (150 samples,)\n",
    "print(f\"Target names: {iris.target_names}\") # ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "# 2. Instantiate Estimator\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# 3. Fit Estimator\n",
    "knn.fit(X, y)\n",
    "print(f\"\\nModel fitted: {knn}\")\n",
    "\n",
    "# 4. Predict on new (or existing) data\n",
    "# Using first 5 samples as example 'new' data\n",
    "X_new = X[:5]\n",
    "predictions = knn.predict(X_new)\n",
    "print(f\"\\nPredictions for first 5 samples: {predictions}\") # Should predict class 0\n",
    "print(f\"Predicted class names: {iris.target_names[predictions]}\")\n",
    "\n",
    "# 5. Evaluate (using default score - accuracy for classifiers)\n",
    "accuracy = knn.score(X, y) # Evaluate on the training data (not ideal, just for demo)\n",
    "print(f\"\\nModel accuracy on training data: {accuracy:.4f}\")\n",
    "# --------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfa2a4-200b-45f1-8fb7-b7150909e865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
