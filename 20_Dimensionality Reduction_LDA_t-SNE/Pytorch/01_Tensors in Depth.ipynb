{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6a91b9-3112-47c4-b22d-484819e5fe3d",
   "metadata": {},
   "source": [
    "- Let's start with the absolute foundation of PyTorch: **Tensors**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1049adc-e967-456b-845b-e4d477c85695",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 1: Tensors in Depth**\n",
    "\n",
    "At its core, PyTorch is a library for numerical computation using n-dimensional arrays called **tensors**. These are similar to NumPy's `ndarrays` but come with the powerful ability to run on GPUs for accelerated computation and to keep track of operations for automatic differentiation (which we'll cover in Part 2).\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **Tensor Creation:** Various ways to create tensors.\n",
    "2.  **Tensor Attributes:** Understanding `shape`, `dtype`, and `device`.\n",
    "3.  **Tensor Operations:**\n",
    "    * Arithmetic Operations\n",
    "    * Matrix Operations\n",
    "    * Reshaping Operations\n",
    "    * Indexing, Slicing, Joining, and Mutating\n",
    "4.  **Broadcasting:** How PyTorch handles operations on tensors of different shapes.\n",
    "5.  **GPU Acceleration:** Moving tensors between CPU and GPU.\n",
    "6.  **NumPy Bridge:** Interoperability with NumPy arrays.\n",
    "\n",
    "Let's get started with examples!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d7d1be-4b55-4f00-a5e6-cb060a7fb63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from torch) (80.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in g:\\learning\\machine_learning\\pandas\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178af42e-0f30-4150-87ca-dba29445e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np # For comparison and interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50b9172-afc4-4bc2-a42b-cd4d28e98e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.7.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: G:\\learning\\Machine_learning\\Pandas\\venv\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, setuptools, sympy, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0201ebd-25c1-420e-933c-e2b486dbf0eb",
   "metadata": {},
   "source": [
    "#### 1. Tensor Creation\n",
    "\n",
    "PyTorch offers many ways to create tensors:\n",
    "\n",
    "From Python lists or sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc5b980-7e53-4e77-a2f6-826b9b10c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\learning\\Machine_learning\\Pandas\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01961f8-5a43-46d0-ba0b-2febc9c54231",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# From a Python list\u001b[39;00m\n\u001b[32m      4\u001b[39m data_list = [[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m], [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m tensor_from_list = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m(data_list)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTensor from list:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, tensor_from_list)\n\u001b[32m      8\u001b[39m tensor_float = torch.tensor([[\u001b[32m1.0\u001b[39m, \u001b[32m2.0\u001b[39m], [\u001b[32m3.0\u001b[39m, \u001b[32m4.0\u001b[39m]], dtype=torch.float32)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "import numpy as np # For comparison and interoperability\n",
    "\n",
    "# From a Python list\n",
    "data_list = [[1, 2], [3, 4]]\n",
    "tensor_from_list = torch.tensor(data_list)\n",
    "print(\"Tensor from list:\\n\", tensor_from_list)\n",
    "\n",
    "tensor_float = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32)\n",
    "print(\"\\nFloat tensor from list:\\n\", tensor_float)\n",
    "\n",
    "tensor_long = torch.tensor([1, 2, 3], dtype=torch.long)\n",
    "print(\"\\nLong tensor:\\n\", tensor_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323c3e9-b606-425c-900b-8d720ed446f3",
   "metadata": {},
   "source": [
    "Let's get started with examples!\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import numpy as np # For comparison and interoperability\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "```\n",
    "\n",
    "**1. Tensor Creation**\n",
    "\n",
    "PyTorch offers many ways to create tensors:\n",
    "\n",
    "* **From Python lists or sequences:**\n",
    "    ```python\n",
    "    # From a Python list\n",
    "    data_list = [[1, 2], [3, 4]]\n",
    "    tensor_from_list = torch.tensor(data_list)\n",
    "    print(\"Tensor from list:\\n\", tensor_from_list)\n",
    "\n",
    "    # You can specify the data type (dtype)\n",
    "    tensor_float = torch.tensor([[1.0, 2.0], [3.0, 4.0]], dtype=torch.float32)\n",
    "    print(\"\\nFloat tensor from list:\\n\", tensor_float)\n",
    "\n",
    "    tensor_long = torch.tensor([1, 2, 3], dtype=torch.long) # int64\n",
    "    print(\"\\nLong tensor:\\n\", tensor_long)\n",
    "    ```\n",
    "\n",
    "* **From NumPy arrays:**\n",
    "    ```python\n",
    "    numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "    tensor_from_numpy = torch.from_numpy(numpy_array) # Shares memory with numpy_array\n",
    "    print(\"\\nTensor from NumPy array:\\n\", tensor_from_numpy)\n",
    "\n",
    "    # Modifying the NumPy array will affect the tensor (if they share memory)\n",
    "    numpy_array[0, 0] = 99\n",
    "    print(\"Modified tensor (after modifying NumPy array):\\n\", tensor_from_numpy)\n",
    "\n",
    "    # To create a copy that doesn't share memory:\n",
    "    tensor_copy_from_numpy = torch.tensor(numpy_array) # This creates a copy\n",
    "    numpy_array[0, 0] = 100\n",
    "    print(\"Original NumPy array now:\\n\", numpy_array)\n",
    "    print(\"Tensor copy (unaffected by later NumPy mod):\\n\", tensor_copy_from_numpy)\n",
    "    ```\n",
    "\n",
    "* **Creating tensors with specific values (zeros, ones, random):**\n",
    "    ```python\n",
    "    # Tensor of zeros\n",
    "    zeros_tensor = torch.zeros(2, 3) # Shape (2 rows, 3 columns)\n",
    "    print(\"\\nZeros tensor:\\n\", zeros_tensor)\n",
    "\n",
    "    # Tensor of ones\n",
    "    ones_tensor = torch.ones(3, 2, dtype=torch.double) # Specify dtype\n",
    "    print(\"\\nOnes tensor (double precision):\\n\", ones_tensor)\n",
    "\n",
    "    # Tensor with random values (uniformly distributed between 0 and 1)\n",
    "    rand_tensor = torch.rand(2, 2)\n",
    "    print(\"\\nRandom tensor (uniform distribution):\\n\", rand_tensor)\n",
    "\n",
    "    # Tensor with random values (normally distributed with mean 0, variance 1)\n",
    "    randn_tensor = torch.randn(3, 3)\n",
    "    print(\"\\nRandom tensor (normal distribution):\\n\", randn_tensor)\n",
    "\n",
    "    # Tensor with integer random values within a range\n",
    "    randint_tensor = torch.randint(low=0, high=10, size=(2, 4)) # Integers from [0, 10)\n",
    "    print(\"\\nRandom integer tensor:\\n\", randint_tensor)\n",
    "    ```\n",
    "\n",
    "* **Creating tensors like other tensors (`*_like` methods):**\n",
    "    These methods create a new tensor with the same `shape` and `dtype` (by default) as an existing tensor.\n",
    "    ```python\n",
    "    x = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float16)\n",
    "    zeros_like_x = torch.zeros_like(x)\n",
    "    print(\"\\nZeros tensor like x:\\n\", zeros_like_x)\n",
    "    print(\"dtype of zeros_like_x:\", zeros_like_x.dtype)\n",
    "\n",
    "    rand_like_x = torch.rand_like(x, dtype=torch.float32) # Override dtype\n",
    "    print(\"\\nRandom tensor like x (but with float32 dtype):\\n\", rand_like_x)\n",
    "    print(\"dtype of rand_like_x:\", rand_like_x.dtype)\n",
    "    ```\n",
    "\n",
    "* **Creating tensors with ranges:**\n",
    "    ```python\n",
    "    # Like Python's range()\n",
    "    range_tensor = torch.arange(0, 10, 2) # Start, end (exclusive), step\n",
    "    print(\"\\nRange tensor (arange):\\n\", range_tensor)\n",
    "\n",
    "    # Linearly spaced points\n",
    "    linspace_tensor = torch.linspace(0, 1, 5) # Start, end (inclusive), number of steps\n",
    "    print(\"\\nLinspace tensor:\\n\", linspace_tensor)\n",
    "    ```\n",
    "\n",
    "**2. Tensor Attributes**\n",
    "\n",
    "Every tensor has attributes that describe its characteristics:\n",
    "\n",
    "* **`shape` (or `size()`):** The dimensions of the tensor.\n",
    "* **`dtype`:** The data type of the elements in the tensor.\n",
    "* **`device`:** The device (CPU or GPU) where the tensor's data is stored.\n",
    "\n",
    "```python\n",
    "tensor_example = torch.randn(3, 4, 5) # A 3x4x5 tensor\n",
    "\n",
    "print(\"\\n--- Tensor Attributes ---\")\n",
    "print(\"Tensor example:\\n\", tensor_example)\n",
    "print(\"Shape of tensor:\", tensor_example.shape)\n",
    "print(\"Size of tensor (alternative way):\", tensor_example.size())\n",
    "print(\"Data type (dtype) of tensor:\", tensor_example.dtype)\n",
    "print(\"Device tensor is stored on:\", tensor_example.device)\n",
    "print(\"Number of dimensions:\", tensor_example.ndim)\n",
    "print(\"Number of elements:\", tensor_example.numel())\n",
    "```\n",
    "\n",
    "**3. Tensor Operations**\n",
    "\n",
    "PyTorch provides a rich set of operations for manipulating tensors.\n",
    "\n",
    "* **Arithmetic Operations:**\n",
    "    These are typically element-wise.\n",
    "    ```python\n",
    "    a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "    b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "    print(\"\\n--- Arithmetic Operations ---\")\n",
    "    print(\"Tensor a:\\n\", a)\n",
    "    print(\"Tensor b:\\n\", b)\n",
    "\n",
    "    # Addition\n",
    "    sum_ab = a + b\n",
    "    # sum_ab_alt = torch.add(a, b)\n",
    "    print(\"a + b:\\n\", sum_ab)\n",
    "\n",
    "    # Subtraction\n",
    "    diff_ab = a - b\n",
    "    print(\"a - b:\\n\", diff_ab)\n",
    "\n",
    "    # Element-wise Multiplication\n",
    "    mul_ab = a * b\n",
    "    # mul_ab_alt = torch.mul(a, b)\n",
    "    print(\"a * b (element-wise):\\n\", mul_ab)\n",
    "\n",
    "    # Division\n",
    "    div_ab = a / b\n",
    "    print(\"a / b:\\n\", div_ab)\n",
    "\n",
    "    # Exponentiation\n",
    "    pow_a = a ** 2\n",
    "    # pow_a_alt = torch.pow(a, 2)\n",
    "    print(\"a squared:\\n\", pow_a)\n",
    "\n",
    "    # In-place operations (modify the tensor directly, often denoted by a trailing underscore `_`)\n",
    "    c = torch.ones(2, 2)\n",
    "    print(\"Tensor c before add_:\\n\", c)\n",
    "    c.add_(a) # c = c + a\n",
    "    print(\"Tensor c after c.add_(a):\\n\", c)\n",
    "    ```\n",
    "\n",
    "* **Matrix Operations:**\n",
    "    ```python\n",
    "    mat1 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "    mat2 = torch.tensor([[5., 6.], [7., 8.]])\n",
    "    vec1 = torch.tensor([1., 2., 3.])\n",
    "    vec2 = torch.tensor([4., 5., 6.])\n",
    "\n",
    "    print(\"\\n--- Matrix Operations ---\")\n",
    "    print(\"Matrix 1:\\n\", mat1)\n",
    "    print(\"Matrix 2:\\n\", mat2)\n",
    "\n",
    "    # Matrix Multiplication\n",
    "    mat_mul = torch.matmul(mat1, mat2)\n",
    "    # mat_mul_alt = mat1 @ mat2\n",
    "    print(\"Matrix multiplication (mat1 @ mat2):\\n\", mat_mul)\n",
    "\n",
    "    # Element-wise product (already covered, but important to distinguish)\n",
    "    # elem_prod = mat1 * mat2\n",
    "\n",
    "    # Dot product of two 1D tensors\n",
    "    dot_prod = torch.dot(vec1, vec2)\n",
    "    print(f\"Dot product of {vec1} and {vec2}:\", dot_prod)\n",
    "\n",
    "    # Transpose\n",
    "    mat1_t = mat1.T\n",
    "    # mat1_t_alt = torch.transpose(mat1, 0, 1)\n",
    "    print(\"Transpose of Matrix 1:\\n\", mat1_t)\n",
    "    ```\n",
    "\n",
    "* **Reshaping Operations:**\n",
    "    Changing the shape of a tensor without changing its data.\n",
    "    ```python\n",
    "    x_orig = torch.arange(12) # 0 to 11\n",
    "    print(\"\\n--- Reshaping Operations ---\")\n",
    "    print(\"Original tensor x_orig (1D, 12 elements):\\n\", x_orig)\n",
    "\n",
    "    # view(): Returns a new tensor with the same data but different shape.\n",
    "    # The new shape must be compatible with the original number of elements.\n",
    "    # Data is contiguous.\n",
    "    x_view_3_4 = x_orig.view(3, 4)\n",
    "    print(\"x_orig.view(3, 4):\\n\", x_view_3_4)\n",
    "    # x_view_3_neg1 = x_orig.view(3, -1) # -1 infers the dimension\n",
    "    # print(\"x_orig.view(3, -1):\\n\", x_view_3_neg1)\n",
    "\n",
    "    # reshape(): Similar to view(), but can operate on non-contiguous tensors\n",
    "    # (by creating a copy if necessary). Generally safer if unsure about contiguity.\n",
    "    x_reshaped_4_3 = x_orig.reshape(4, 3)\n",
    "    print(\"x_orig.reshape(4, 3):\\n\", x_reshaped_4_3)\n",
    "\n",
    "    # squeeze(): Removes dimensions of size 1.\n",
    "    x_unsqueeze_example = torch.randn(1, 3, 1, 5)\n",
    "    print(\"x_unsqueeze_example shape:\", x_unsqueeze_example.shape)\n",
    "    x_squeezed = x_unsqueeze_example.squeeze() # Removes all dimensions of size 1\n",
    "    print(\"x_squeezed shape (all ones removed):\", x_squeezed.shape)\n",
    "    x_squeezed_dim0 = x_unsqueeze_example.squeeze(0) # Removes dim 0 if it's size 1\n",
    "    print(\"x_squeezed_dim0 shape:\", x_squeezed_dim0.shape)\n",
    "\n",
    "    # unsqueeze(): Adds a dimension of size 1 at a specified position.\n",
    "    x_unsqueezed_dim0 = x_squeezed.unsqueeze(0) # Add dim at position 0\n",
    "    print(\"x_unsqueezed_dim0 shape (from squeezed):\", x_unsqueezed_dim0.shape)\n",
    "    x_unsqueezed_dim2 = x_squeezed.unsqueeze(2) # Add dim at position 2\n",
    "    print(\"x_unsqueezed_dim2 shape (from squeezed):\", x_unsqueezed_dim2.shape)\n",
    "\n",
    "    # permute(): Rearranges dimensions.\n",
    "    x_permute_example = torch.randn(2, 3, 4)\n",
    "    print(\"x_permute_example shape:\", x_permute_example.shape)\n",
    "    x_permuted = x_permute_example.permute(2, 0, 1) # old_dim2, old_dim0, old_dim1\n",
    "    print(\"x_permuted shape (4, 2, 3):\", x_permuted.shape)\n",
    "\n",
    "    # flatten(): Flattens a tensor from a start_dim to an end_dim.\n",
    "    x_flatten_example = torch.randn(2, 3, 4)\n",
    "    print(\"x_flatten_example shape:\", x_flatten_example.shape)\n",
    "    x_flattened_all = torch.flatten(x_flatten_example) # Flattens completely\n",
    "    print(\"x_flattened_all shape:\", x_flattened_all.shape)\n",
    "    x_flattened_from_dim1 = torch.flatten(x_flatten_example, start_dim=1) # Flattens from dim 1 onwards\n",
    "    print(\"x_flattened_from_dim1 shape:\", x_flattened_from_dim1.shape)\n",
    "    ```\n",
    "\n",
    "* **Indexing, Slicing, Joining, and Mutating:**\n",
    "    Similar to NumPy, PyTorch offers rich indexing and slicing capabilities.\n",
    "    ```python\n",
    "    tensor_idx_slice = torch.arange(10).reshape(2, 5) # 0-9 in a 2x5 tensor\n",
    "    print(\"\\n--- Indexing and Slicing ---\")\n",
    "    print(\"Original tensor for indexing/slicing:\\n\", tensor_idx_slice)\n",
    "\n",
    "    # Get a specific element\n",
    "    print(\"Element at [0, 0]:\", tensor_idx_slice[0, 0])\n",
    "\n",
    "    # Get a row\n",
    "    print(\"First row (tensor_idx_slice[0]):\\n\", tensor_idx_slice[0])\n",
    "    print(\"First row (tensor_idx_slice[0, :]):\\n\", tensor_idx_slice[0, :])\n",
    "\n",
    "    # Get a column\n",
    "    print(\"First column (tensor_idx_slice[:, 0]):\\n\", tensor_idx_slice[:, 0])\n",
    "\n",
    "    # Get a sub-tensor (slicing)\n",
    "    print(\"Sub-tensor (rows 0-1, cols 1-3):\\n\", tensor_idx_slice[0:2, 1:4]) # or [:, 1:4] for all rows\n",
    "\n",
    "    # Boolean indexing\n",
    "    bool_idx_tensor = torch.tensor([[True, False, True], [False, True, True]])\n",
    "    data_for_bool = torch.randn(2,3)\n",
    "    print(\"Data for boolean indexing:\\n\", data_for_bool)\n",
    "    print(\"Boolean mask:\\n\", bool_idx_tensor)\n",
    "    print(\"Elements selected by boolean mask:\\n\", data_for_bool[bool_idx_tensor]) # Returns a 1D tensor\n",
    "\n",
    "    # Joining tensors\n",
    "    t1 = torch.zeros(2, 3)\n",
    "    t2 = torch.ones(2, 3)\n",
    "    t3 = torch.full((2,3), 2)\n",
    "\n",
    "    # Concatenate along a dimension (dim=0 stacks rows, dim=1 stacks columns)\n",
    "    cat_dim0 = torch.cat((t1, t2, t3), dim=0)\n",
    "    print(\"\\nConcatenated along dim 0 (rows):\\n\", cat_dim0)\n",
    "    print(\"Shape of cat_dim0:\", cat_dim0.shape)\n",
    "\n",
    "    cat_dim1 = torch.cat((t1, t2, t3), dim=1)\n",
    "    print(\"\\nConcatenated along dim 1 (columns):\\n\", cat_dim1)\n",
    "    print(\"Shape of cat_dim1:\", cat_dim1.shape)\n",
    "\n",
    "    # Stacking (creates a new dimension)\n",
    "    stack_dim0 = torch.stack((t1, t2, t3), dim=0)\n",
    "    print(\"\\nStacked along new dim 0:\\n\", stack_dim0)\n",
    "    print(\"Shape of stack_dim0:\", stack_dim0.shape) # (3, 2, 3)\n",
    "\n",
    "    # Mutating (modifying) tensors using indexing\n",
    "    print(\"\\nTensor before mutation:\\n\", tensor_idx_slice)\n",
    "    tensor_idx_slice[0, 0] = 100\n",
    "    tensor_idx_slice[1, :] = 55 # Set whole second row to 55\n",
    "    print(\"Tensor after mutation:\\n\", tensor_idx_slice)\n",
    "    ```\n",
    "\n",
    "**4. Broadcasting**\n",
    "\n",
    "Broadcasting allows PyTorch to perform operations on tensors of different (but compatible) shapes without explicitly making copies of the data. The rules are similar to NumPy:\n",
    "\n",
    "1.  If tensors have different numbers of dimensions, prepend 1s to the shape of the smaller tensor until they have the same number of dimensions.\n",
    "2.  Two tensors are compatible in a dimension if:\n",
    "    * They are equal in that dimension, OR\n",
    "    * One of them has size 1 in that dimension.\n",
    "3.  The size of the resulting tensor in each dimension is the maximum of the sizes of the input tensors in that dimension.\n",
    "\n",
    "```python\n",
    "x_broadcast = torch.arange(3).view(3, 1) # Shape (3, 1) -> [[0], [1], [2]]\n",
    "y_broadcast = torch.arange(2).view(1, 2) # Shape (1, 2) -> [[0, 1]]\n",
    "\n",
    "print(\"\\n--- Broadcasting ---\")\n",
    "print(\"x_broadcast (shape 3x1):\\n\", x_broadcast)\n",
    "print(\"y_broadcast (shape 1x2):\\n\", y_broadcast)\n",
    "\n",
    "# x_broadcast becomes (3, 2) by repeating column values\n",
    "# y_broadcast becomes (3, 2) by repeating row values\n",
    "result_broadcast = x_broadcast + y_broadcast\n",
    "print(\"x_broadcast + y_broadcast (result shape 3x2):\\n\", result_broadcast)\n",
    "\n",
    "# Another example\n",
    "a_bc = torch.ones(3, 4) # Shape (3, 4)\n",
    "b_bc = torch.rand(4)    # Shape (4) -> effectively (1, 4) for broadcasting\n",
    "c_bc = a_bc + b_bc      # b_bc is broadcast across the rows of a_bc\n",
    "print(\"\\na_bc (3,4) + b_bc (4) result shape:\", c_bc.shape)\n",
    "```\n",
    "\n",
    "**5. GPU Acceleration**\n",
    "\n",
    "One of PyTorch's key strengths is its seamless GPU support (primarily NVIDIA GPUs via CUDA).\n",
    "\n",
    "```python\n",
    "print(\"\\n--- GPU Acceleration ---\")\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Running on GPU.\")\n",
    "    device = torch.device(\"cuda\") # Default CUDA device\n",
    "\n",
    "    # Create a tensor and move it to GPU\n",
    "    tensor_cpu = torch.randn(3, 3)\n",
    "    print(\"Tensor on CPU:\\n\", tensor_cpu)\n",
    "    print(\"Device of tensor_cpu:\", tensor_cpu.device)\n",
    "\n",
    "    tensor_gpu = tensor_cpu.to(device) # or tensor_cpu.cuda()\n",
    "    print(\"\\nTensor on GPU:\\n\", tensor_gpu)\n",
    "    print(\"Device of tensor_gpu:\", tensor_gpu.device)\n",
    "\n",
    "    # Operations can be performed directly on GPU tensors\n",
    "    result_gpu = tensor_gpu * tensor_gpu + 2\n",
    "    print(\"\\nResult of GPU operation (still on GPU):\\n\", result_gpu)\n",
    "    print(\"Device of result_gpu:\", result_gpu.device)\n",
    "\n",
    "    # To move a tensor back to CPU\n",
    "    result_cpu = result_gpu.to(torch.device(\"cpu\")) # or result_gpu.cpu()\n",
    "    print(\"\\nResult moved back to CPU:\\n\", result_cpu)\n",
    "    print(\"Device of result_cpu:\", result_cpu.device)\n",
    "\n",
    "    # Note: All tensors involved in an operation must be on the same device.\n",
    "    # Trying to operate on a CPU tensor and a GPU tensor directly will raise an error.\n",
    "    try:\n",
    "        error_prone = tensor_cpu + tensor_gpu\n",
    "    except RuntimeError as e:\n",
    "        print(\"\\nError when adding CPU and GPU tensors directly:\", e)\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available. Examples will run on CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "```\n",
    "\n",
    "**6. NumPy Bridge**\n",
    "\n",
    "PyTorch offers excellent interoperability with NumPy.\n",
    "\n",
    "* **Tensor to NumPy array:**\n",
    "    ```python\n",
    "    print(\"\\n--- NumPy Bridge ---\")\n",
    "    pytorch_tensor_np = torch.ones(5)\n",
    "    print(\"PyTorch tensor:\", pytorch_tensor_np)\n",
    "\n",
    "    # .numpy() works only on CPU tensors\n",
    "    # If tensor is on GPU, first move it to CPU: pytorch_tensor_np.cpu().numpy()\n",
    "    numpy_array_from_tensor = pytorch_tensor_np.numpy()\n",
    "    print(\"Converted NumPy array:\", numpy_array_from_tensor)\n",
    "\n",
    "    # IMPORTANT: If the tensor is on the CPU, the PyTorch tensor and NumPy array\n",
    "    # will share their underlying memory locations. Modifying one will affect the other.\n",
    "    pytorch_tensor_np.add_(1) # In-place addition\n",
    "    print(\"PyTorch tensor after in-place add:\", pytorch_tensor_np)\n",
    "    print(\"NumPy array reflects the change:\", numpy_array_from_tensor)\n",
    "    ```\n",
    "\n",
    "* **NumPy array to Tensor:**\n",
    "    ```python\n",
    "    numpy_array_to_convert = np.arange(5, dtype=np.float32)\n",
    "    print(\"\\nOriginal NumPy array:\", numpy_array_to_convert)\n",
    "\n",
    "    pytorch_tensor_from_np = torch.from_numpy(numpy_array_to_convert)\n",
    "    print(\"Converted PyTorch tensor:\", pytorch_tensor_from_np)\n",
    "\n",
    "    # Again, they share memory\n",
    "    np.add(numpy_array_to_convert, 1, out=numpy_array_to_convert) # In-place add for NumPy\n",
    "    print(\"NumPy array after in-place add:\", numpy_array_to_convert)\n",
    "    print(\"PyTorch tensor reflects the change:\", pytorch_tensor_from_np)\n",
    "    ```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e948065-3797-4bb2-aa27-47289429de39",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 2: Automatic Differentiation with `torch.autograd`**\n",
    "\n",
    "One of the most powerful features of PyTorch is `torch.autograd`, its automatic differentiation engine. This is what enables PyTorch to automatically calculate the gradients of your computation (typically a loss function) with respect to its parameters (typically the weights of a neural network). These gradients are essential for training neural networks using optimization algorithms like gradient descent.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **What is `autograd`?**\n",
    "2.  **Computation Graphs:** How PyTorch tracks operations.\n",
    "3.  **`requires_grad`:** Tracking operations for gradient computation.\n",
    "4.  **`grad_fn`:** The backward function reference.\n",
    "5.  **`.backward()`:** Computing gradients.\n",
    "6.  **`.grad`:** Accessing computed gradients.\n",
    "7.  **Gradient Accumulation:** How gradients are summed up.\n",
    "8.  **Disabling Gradient Tracking:** `torch.no_grad()` and `detach()`.\n",
    "9.  **More on `.backward()` (Vector-Jacobian Product).**\n",
    "\n",
    "Let's dive in with examples.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "```\n",
    "\n",
    "**1. What is `autograd`?**\n",
    "\n",
    "At its heart, `autograd` allows you to request the gradient of some output (usually a scalar loss value) with respect to some input(s) (usually model parameters). If you have a function $y = f(x)$, where $x$ is an input tensor and $y$ is an output tensor, `autograd` helps you compute $\\frac{\\partial y}{\\partial x}$. For neural networks, $x$ would be the parameters, and $y$ would be the loss.\n",
    "\n",
    "**2. Computation Graphs**\n",
    "\n",
    "PyTorch uses a \"define-by-run\" philosophy, meaning the computation graph is built dynamically as operations are performed. When tensors that are \"tracked\" (we'll see this with `requires_grad`) are used in operations, PyTorch records these operations, forming a directed acyclic graph (DAG).\n",
    "\n",
    "* **Nodes** in this graph are tensors.\n",
    "* **Edges** are functions (operations) that produce output tensors from input tensors.\n",
    "\n",
    "When you call `.backward()` from an output node (e.g., loss), `autograd` traverses this graph backward from that node to compute gradients for all leaf nodes that require gradients.\n",
    "\n",
    "**3. `requires_grad` Attribute**\n",
    "\n",
    "For `autograd` to track operations on a tensor and compute gradients for it, the tensor's `requires_grad` attribute must be set to `True`.\n",
    "\n",
    "* By default, tensors you create manually have `requires_grad=False`.\n",
    "* Parameters of `torch.nn.Module` (which we'll see in Part 3) typically have `requires_grad=True` by default.\n",
    "\n",
    "```python\n",
    "# Example of requires_grad\n",
    "x = torch.tensor(2.0, requires_grad=False) # Default\n",
    "y = torch.tensor(3.0, requires_grad=True)  # We want gradients for y\n",
    "z = torch.tensor(4.0, requires_grad=True)  # And for z\n",
    "\n",
    "print(f\"x: {x}, requires_grad: {x.requires_grad}\")\n",
    "print(f\"y: {y}, requires_grad: {y.requires_grad}\")\n",
    "print(f\"z: {z}, requires_grad: {z.requires_grad}\")\n",
    "\n",
    "# Operations involving tensors with requires_grad=True will produce outputs\n",
    "# that also require gradients and are part of the computation graph.\n",
    "f = y * z + x # x is not tracked\n",
    "print(f\"\\nf = y*z + x = {f}\")\n",
    "print(f\"f.requires_grad: {f.requires_grad}\") # True because y and z require_grad\n",
    "\n",
    "# You can change requires_grad in-place for an existing tensor\n",
    "a = torch.randn(2, 2)\n",
    "print(f\"\\na before: {a.requires_grad}\")\n",
    "a.requires_grad_(True) # In-place operation\n",
    "print(f\"a after: {a.requires_grad}\")\n",
    "```\n",
    "\n",
    "**4. `grad_fn` Attribute**\n",
    "\n",
    "If a tensor is the result of an operation involving tensors that require gradients, it will have a `grad_fn` attribute. This attribute references the function (like `AddBackward0`, `MulBackward0`) that created this tensor and is used by `autograd` during the backward pass to compute gradients.\n",
    "\n",
    "* User-created tensors (leaf nodes) with `requires_grad=True` will have `grad_fn=None`.\n",
    "\n",
    "```python\n",
    "w = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([0.5], requires_grad=True)\n",
    "inputs = torch.tensor([10.0, 11.0, 12.0])\n",
    "\n",
    "# A simple linear operation\n",
    "output = (w * inputs).sum() + b # output = w_0*i_0 + w_1*i_1 + w_2*i_2 + b\n",
    "\n",
    "print(f\"\\nw: {w}, grad_fn: {w.grad_fn}\") # Leaf node, so None\n",
    "print(f\"b: {b}, grad_fn: {b.grad_fn}\") # Leaf node, so None\n",
    "print(f\"inputs: {inputs}, grad_fn: {inputs.grad_fn}\") # Not requiring grad, so None\n",
    "\n",
    "print(f\"\\noutput: {output}\")\n",
    "print(f\"output.requires_grad: {output.requires_grad}\")\n",
    "print(f\"output.grad_fn: {output.grad_fn}\") # Will show something like <AddBackward0 object at ...>\n",
    "```\n",
    "The `grad_fn` shows the last operation that created `output`. `autograd` uses this chain of `grad_fn`s to go backward.\n",
    "\n",
    "**5. `.backward()` - Computing Gradients**\n",
    "\n",
    "Once you have a scalar output (like a loss value) that results from a chain of operations on tensors requiring gradients, you can call `.backward()` on this scalar. This triggers `autograd` to compute the gradients of this scalar with respect to all leaf tensors in the graph that have `requires_grad=True`.\n",
    "\n",
    "```python\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(5.0, requires_grad=True)\n",
    "y_out = x1**2 * x2 + x1 # y_out = x1^2 * x2 + x1\n",
    "\n",
    "print(f\"\\nx1 = {x1.item()}, x2 = {x2.item()}\")\n",
    "print(f\"y_out = x1^2 * x2 + x1 = {y_out.item()}\")\n",
    "\n",
    "# Now, let's compute the gradients dy_out/dx1 and dy_out/dx2\n",
    "# Analytically:\n",
    "# dy_out/dx1 = 2*x1*x2 + 1 = 2*2*5 + 1 = 21\n",
    "# dy_out/dx2 = x1^2       = 2^2       = 4\n",
    "\n",
    "y_out.backward() # This populates .grad attribute of x1 and x2\n",
    "\n",
    "# Gradients are now stored in x1.grad and x2.grad\n",
    "print(f\"\\ndy_out/dx1 (x1.grad): {x1.grad}\")\n",
    "print(f\"dy_out/dx2 (x2.grad): {x2.grad}\")\n",
    "```\n",
    "The `.grad` attribute will now hold the computed gradients.\n",
    "\n",
    "**6. `.grad` - Accessing Computed Gradients**\n",
    "\n",
    "As seen above, after calling `.backward()`, the gradients are accumulated in the `.grad` attribute of the leaf tensors (those with `requires_grad=True` for which gradients were computed).\n",
    "\n",
    "* If `requires_grad` is `False` for a tensor, its `.grad` attribute will remain `None`.\n",
    "* Only leaf nodes in the graph that have `requires_grad=True` will have their `.grad` populated. Gradients for intermediate tensors are not typically stored to save memory, but can be accessed using \"hooks\" (an advanced topic).\n",
    "\n",
    "**7. Gradient Accumulation**\n",
    "\n",
    "Crucially, PyTorch **accumulates** gradients. This means if you call `.backward()` multiple times, the newly computed gradients are *added* to the existing values in the `.grad` attribute.\n",
    "\n",
    "This behavior is useful for scenarios like training with gradient accumulation over multiple mini-batches or for custom gradient manipulations. However, in a standard training loop, you usually want to compute fresh gradients for each batch. Therefore, you **must zero out the gradients** before each new backward pass.\n",
    "\n",
    "```python\n",
    "p = torch.tensor(3.0, requires_grad=True)\n",
    "q_val = p * p # q_val = p^2\n",
    "print(f\"\\np = {p.item()}, q_val = {q_val.item()}\")\n",
    "\n",
    "# First backward pass\n",
    "q_val.backward() # dq/dp = 2*p = 6\n",
    "print(f\"After first backward pass, p.grad = {p.grad}\") # Should be 6.0\n",
    "\n",
    "# Second backward pass on the same q_val (without zeroing gradients)\n",
    "# Note: For this simple example, to call backward() again on q_val,\n",
    "# we'd typically need to rebuild parts of the graph or specify retain_graph=True\n",
    "# as the graph is freed by default after backward().\n",
    "# Let's redefine q_val for simplicity or use retain_graph.\n",
    "# Using retain_graph=True for demonstration of accumulation on the *same* graph:\n",
    "p_new = torch.tensor(3.0, requires_grad=True)\n",
    "q_new = p_new * p_new\n",
    "q_new.backward(retain_graph=True) # dq/dp = 6\n",
    "print(f\"\\nFor p_new = {p_new.item()}:\")\n",
    "print(f\"After first backward, p_new.grad = {p_new.grad}\") # 6.0\n",
    "\n",
    "q_new.backward() # Call backward again on the same q_new\n",
    "print(f\"After second backward (gradients accumulated), p_new.grad = {p_new.grad}\") # Should be 6.0 + 6.0 = 12.0\n",
    "\n",
    "# In a typical training loop, you would do this for an optimizer:\n",
    "# optimizer.zero_grad() # Clears p.grad\n",
    "# loss = ...\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# Let's demonstrate zeroing explicitly for a tensor\n",
    "p.grad.zero_() # In-place zeroing of the gradient\n",
    "print(f\"After p.grad.zero_(), p.grad = {p.grad}\") # Should be 0.0\n",
    "\n",
    "q_val_fresh = p * p # Recompute q_val using the same p\n",
    "q_val_fresh.backward()\n",
    "print(f\"After zeroing and fresh backward, p.grad = {p.grad}\") # Should be 6.0 again\n",
    "```\n",
    "In practice, `optimizer.zero_grad()` (which we'll see in Part 4) handles zeroing the gradients for all model parameters managed by the optimizer.\n",
    "\n",
    "**8. Disabling Gradient Tracking**\n",
    "\n",
    "Sometimes, you don't want PyTorch to track operations, for example:\n",
    "* During inference/evaluation (speeds up computation and saves memory).\n",
    "* When you are modifying model parameters manually (e.g., in some reinforcement learning scenarios) and don't want these modifications to be part of the gradient history.\n",
    "* When a part of your model should be \"frozen.\"\n",
    "\n",
    "PyTorch provides two main ways to do this:\n",
    "\n",
    "* **`torch.no_grad()` context manager:**\n",
    "    Any operations performed within this block will not be tracked, even if their inputs have `requires_grad=True`.\n",
    "    ```python\n",
    "    weights = torch.randn(3, 3, requires_grad=True)\n",
    "    inputs_data = torch.randn(3, 1)\n",
    "    print(f\"\\nweights.requires_grad: {weights.requires_grad}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_no_grad = weights @ inputs_data\n",
    "        print(f\"Inside torch.no_grad(): output_no_grad.requires_grad = {output_no_grad.requires_grad}\") # False\n",
    "        print(f\"output_no_grad.grad_fn = {output_no_grad.grad_fn}\") # None\n",
    "\n",
    "    # Operations outside the block are tracked again if inputs require grad\n",
    "    output_with_grad = weights @ inputs_data\n",
    "    print(f\"Outside torch.no_grad(): output_with_grad.requires_grad = {output_with_grad.requires_grad}\") # True\n",
    "    print(f\"output_with_grad.grad_fn = {output_with_grad.grad_fn}\") # Not None\n",
    "    ```\n",
    "\n",
    "* **`.detach()` method:**\n",
    "    This method creates a new tensor that shares the same data as the original tensor but is detached from the computation graph. It will have `requires_grad=False`, and no operations involving it will be tracked for gradient computation *through this detached tensor*. The original tensor remains unchanged.\n",
    "\n",
    "    ```python\n",
    "    original_tensor = torch.randn(2, 2, requires_grad=True)\n",
    "    detached_tensor = original_tensor.detach()\n",
    "\n",
    "    print(f\"\\noriginal_tensor.requires_grad: {original_tensor.requires_grad}\") # True\n",
    "    print(f\"detached_tensor.requires_grad: {detached_tensor.requires_grad}\")   # False\n",
    "\n",
    "    # Modifying the detached tensor's data will affect the original tensor's data\n",
    "    # because they share the same underlying storage.\n",
    "    detached_tensor[0,0] = 100.0\n",
    "    print(f\"original_tensor after modifying detached_tensor:\\n{original_tensor}\")\n",
    "\n",
    "    # Operations on detached_tensor won't affect gradients of original_tensor\n",
    "    # if original_tensor is used elsewhere in the graph.\n",
    "    # If you perform an operation with the original_tensor, it will still build a graph.\n",
    "    some_output = original_tensor * 2\n",
    "    print(f\"some_output.grad_fn: {some_output.grad_fn}\") # Has a grad_fn\n",
    "    ```\n",
    "    `detach()` is useful when you want to use a tensor's value without it affecting gradient computations, or if you want to prevent gradients from flowing back through a certain part of your network during a backward pass.\n",
    "\n",
    "**9. More on `.backward()` (Vector-Jacobian Product)**\n",
    "\n",
    "If `.backward()` is called on a tensor that is **not a scalar** (i.e., it has more than one element), you must provide a `gradient` argument to `.backward()`. This `gradient` argument should be a tensor of the same shape as the tensor you're calling `.backward()` on. It represents the gradient of some final scalar loss with respect to the elements of this non-scalar tensor.\n",
    "\n",
    "Essentially, `autograd` computes a **Vector-Jacobian Product (VJP)**. If $y = f(x)$ and $l$ is the final scalar loss, and $v = \\frac{\\partial l}{\\partial y}$ is a vector, then `y.backward(v)` computes $v^T \\cdot J$, where $J$ is the Jacobian matrix $\\frac{\\partial y}{\\partial x}$. The result is accumulated in `x.grad`.\n",
    "\n",
    "For neural network training, the loss function typically outputs a scalar, so you don't need to provide the `gradient` argument to `loss.backward()`. PyTorch implicitly uses a gradient of `torch.tensor(1.0)`.\n",
    "\n",
    "```python\n",
    "# Example of backward() on a non-scalar tensor\n",
    "inp = torch.randn(3, requires_grad=True)\n",
    "outp = inp * 2 # outp is not a scalar\n",
    "\n",
    "# To compute gradients for inp, we need to provide 'gradients' to backward()\n",
    "# This typically represents the gradient of a final scalar loss w.r.t. 'outp'\n",
    "grad_of_loss_wrt_outp = torch.tensor([0.1, 1.0, 0.01])\n",
    "outp.backward(gradient=grad_of_loss_wrt_outp)\n",
    "\n",
    "print(f\"\\nInput tensor inp: {inp}\")\n",
    "print(f\"Output tensor outp: {outp}\")\n",
    "print(f\"Gradient of loss w.r.t. outp (provided): {grad_of_loss_wrt_outp}\")\n",
    "print(f\"inp.grad (dL/dinp = dL/doutp * doutp/dinp = grad_of_loss_wrt_outp * 2):\\n{inp.grad}\")\n",
    "# Expected inp.grad = [0.1*2, 1.0*2, 0.01*2] = [0.2, 2.0, 0.02]\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a2ce2e-9925-4298-81ae-7ff0c45571d1",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 3: Building Neural Networks with `torch.nn`**\n",
    "\n",
    "So far, we've learned about Tensors (the data containers) and `autograd` (the engine for computing gradients). Now, we'll explore `torch.nn`, PyTorch's module specifically designed for building and training neural networks. It provides a rich collection of building blocks (layers, loss functions, etc.) and a powerful base class (`nn.Module`) for creating custom network architectures.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **Introduction to `torch.nn`:** Its purpose and structure.\n",
    "2.  **`nn.Module`:** The cornerstone for all network models.\n",
    "    * Defining custom models by subclassing `nn.Module`.\n",
    "    * The `__init__` method: Where to define layers.\n",
    "    * The `forward` method: Where to define the data flow.\n",
    "3.  **Common Layers:** Focusing on fully connected layers and activations.\n",
    "4.  **`nn.Sequential`:** A simpler way to build linear stacks of layers.\n",
    "5.  **Inspecting Model Parameters.**\n",
    "6.  **Performing a Forward Pass.**\n",
    "7.  **Example: Building a Simple Multi-Layer Perceptron (MLP).**\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.nn.functional as F # Functional API for layers/activations\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "```\n",
    "\n",
    "**1. Introduction to `torch.nn`**\n",
    "\n",
    "The `torch.nn` namespace provides all the building blocks you need to create neural networks. These blocks are often referred to as \"modules\" or \"layers.\" A key concept is that these modules are themselves subclasses of `nn.Module`, allowing them to be nested within each other to create complex architectures. Each `nn.Module` can track its own learnable parameters (weights and biases).\n",
    "\n",
    "**2. `nn.Module`: The Base Class for Models**\n",
    "\n",
    "All neural network models in PyTorch should be subclasses of `nn.Module`. This base class provides a lot of useful functionality:\n",
    "\n",
    "* It can contain other `nn.Module` instances (layers or other custom modules).\n",
    "* It registers its parameters (tensors with `requires_grad=True`). You can access all parameters of a module (and its submodules) using `model.parameters()`.\n",
    "* It provides helper methods like `model.to(device)` to move all parameters to a specific device (CPU/GPU), `model.train()` to set the model to training mode, and `model.eval()` to set it to evaluation mode (important for layers like Dropout and BatchNorm).\n",
    "\n",
    "To create your own neural network model, you typically override two methods:\n",
    "\n",
    "* **`__init__(self, ...)`:**\n",
    "    * This is the constructor. You **must** call `super().__init__()` first.\n",
    "    * This is where you define and instantiate the layers (which are also `nn.Module` instances) that your network will use. These layers become attributes of your model.\n",
    "    ```python\n",
    "    # class MyModel(nn.Module):\n",
    "    #     def __init__(self):\n",
    "    #         super().__init__()\n",
    "    #         # Define layers here, e.g.:\n",
    "    #         self.layer1 = nn.Linear(in_features, out_features)\n",
    "    #         self.activation = nn.ReLU()\n",
    "    ```\n",
    "\n",
    "* **`forward(self, x, ...)`:**\n",
    "    * This method defines how input data `x` flows through the network to produce an output.\n",
    "    * You use the layers defined in `__init__` here.\n",
    "    * The computation graph is built dynamically each time `forward` is called.\n",
    "    ```python\n",
    "    # class MyModel(nn.Module):\n",
    "    #     # ... __init__ as above\n",
    "    #     def forward(self, x):\n",
    "    #         x = self.layer1(x)\n",
    "    #         x = self.activation(x)\n",
    "    #         return x\n",
    "    ```\n",
    "\n",
    "**3. Common Layers**\n",
    "\n",
    "`torch.nn` provides a wide variety of pre-built layers. For this part, we'll focus on the most basic ones for building a simple feed-forward network.\n",
    "\n",
    "* **`nn.Linear(in_features, out_features, bias=True)`:**\n",
    "    * Applies a linear transformation to the incoming data: $y = x W^T + b$.\n",
    "    * `in_features`: Size of each input sample (number of features).\n",
    "    * `out_features`: Size of each output sample.\n",
    "    * `bias`: If `True` (default), the layer learns an additive bias.\n",
    "    * The weights ($W$) and biases ($b$) are learnable parameters, automatically initialized and tracked by the layer.\n",
    "\n",
    "* **Activation Functions (e.g., `nn.ReLU`, `nn.Sigmoid`, `nn.Tanh`):**\n",
    "    * These introduce non-linearity into the model, allowing it to learn more complex patterns.\n",
    "    * They are also `nn.Module` instances.\n",
    "    * Examples:\n",
    "        * `nn.ReLU()`: Rectified Linear Unit, $max(0, x)$.\n",
    "        * `nn.Sigmoid()`: Sigmoid function, $\\frac{1}{1 + e^{-x}}$, squashes values between 0 and 1.\n",
    "        * `nn.Tanh()`: Hyperbolic Tangent, squashes values between -1 and 1.\n",
    "    * Many activation functions also have functional counterparts in `torch.nn.functional` (often imported as `F`). For example, `F.relu(x)`, `F.sigmoid(x)`. Using the functional versions can be slightly more concise if the activation doesn't have learnable parameters (which most common ones don't).\n",
    "\n",
    "        ```python\n",
    "        # Using nn.Module activation\n",
    "        relu_layer = nn.ReLU()\n",
    "        # output = relu_layer(input_tensor)\n",
    "\n",
    "        # Using functional activation\n",
    "        # output = F.relu(input_tensor)\n",
    "        ```\n",
    "\n",
    "**4. `nn.Sequential`: A Simpler Container**\n",
    "\n",
    "For networks where data flows sequentially through a series of layers, `nn.Sequential` provides a convenient way to define them without explicitly writing the `forward` method.\n",
    "\n",
    "```python\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "\n",
    "# Define a simple sequential model\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size), # First layer\n",
    "    nn.ReLU(),                          # Activation\n",
    "    nn.Linear(hidden_size, output_size) # Second layer\n",
    ")\n",
    "\n",
    "print(\"--- Sequential Model ---\")\n",
    "print(model_sequential)\n",
    "\n",
    "# You can also pass an OrderedDict to name the layers\n",
    "from collections import OrderedDict\n",
    "model_sequential_named = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_size)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_size, output_size))\n",
    "]))\n",
    "print(\"\\n--- Sequential Model with Named Layers ---\")\n",
    "print(model_sequential_named)\n",
    "```\n",
    "\n",
    "**5. Inspecting Model Parameters**\n",
    "\n",
    "Once you define a model (either by subclassing `nn.Module` or using `nn.Sequential`), PyTorch automatically tracks its learnable parameters.\n",
    "\n",
    "* `model.parameters()`: Returns an iterator over all parameters of the model (including those of submodules).\n",
    "* `model.named_parameters()`: Returns an iterator over all parameters, yielding both the name of the parameter (e.g., `'fc1.weight'`) and the parameter tensor itself.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- Inspecting Parameters of model_sequential_named ---\")\n",
    "for name, param in model_sequential_named.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Size: {param.size()}, Requires Grad: {param.requires_grad}\")\n",
    "        # print(param.data) # To see the actual values (can be large)\n",
    "```\n",
    "Notice that each `nn.Linear` layer has a `weight` and a `bias` parameter.\n",
    "\n",
    "**6. Performing a Forward Pass**\n",
    "\n",
    "To get an output from your model, you simply call it like a function, passing the input data. This internally calls the `forward` method.\n",
    "\n",
    "```python\n",
    "# Create some dummy input data\n",
    "batch_size = 4\n",
    "dummy_input = torch.randn(batch_size, input_size) # (batch_size, number_of_features)\n",
    "print(f\"\\n--- Forward Pass with model_sequential_named ---\")\n",
    "print(f\"Dummy input shape: {dummy_input.shape}\")\n",
    "\n",
    "# Perform a forward pass\n",
    "# If the model or input is on GPU, ensure they are both on the same device\n",
    "output = model_sequential_named(dummy_input)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\") # Should be (batch_size, output_size)\n",
    "print(f\"Output tensor (first sample):\\n{output[0]}\")\n",
    "print(f\"Output requires_grad: {output.requires_grad}\") # True, as it depends on learnable params\n",
    "print(f\"Output grad_fn: {output.grad_fn}\") # Will show the last operation\n",
    "```\n",
    "\n",
    "**7. Example: Building a Simple Multi-Layer Perceptron (MLP)**\n",
    "\n",
    "Let's build a slightly more structured MLP by subclassing `nn.Module`.\n",
    "Suppose we want a network for a binary classification task with:\n",
    "* Input features: 784 (e.g., a flattened 28x28 image)\n",
    "* Hidden layer 1: 128 neurons, ReLU activation\n",
    "* Hidden layer 2: 64 neurons, ReLU activation\n",
    "* Output layer: 1 neuron (for binary classification, typically followed by a sigmoid if not included in loss)\n",
    "\n",
    "```python\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super().__init__() # Call the parent class constructor\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.relu1 = nn.ReLU() # Or use F.relu in forward\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "        # For binary classification, a sigmoid is often applied to the output.\n",
    "        # This can be done here, or often it's combined with the loss function\n",
    "        # (e.g., nn.BCEWithLogitsLoss expects raw logits).\n",
    "        # For simplicity, we'll output raw logits here.\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the data flow\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x) # Or x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        # if you want sigmoid output directly from model:\n",
    "        # x = self.sigmoid(x) \n",
    "        return x\n",
    "\n",
    "# --- Instantiate and Test SimpleMLP ---\n",
    "print(\"\\n--- Custom MLP Model (SimpleMLP) ---\")\n",
    "# Define dimensions\n",
    "input_features = 784\n",
    "h1_features = 128\n",
    "h2_features = 64\n",
    "output_features = 1 # For binary classification (raw logit)\n",
    "\n",
    "# Create an instance of the model\n",
    "mlp_model = SimpleMLP(input_features, h1_features, h2_features, output_features)\n",
    "print(mlp_model)\n",
    "\n",
    "# Print its parameters\n",
    "print(\"\\nParameters of mlp_model:\")\n",
    "for name, param in mlp_model.named_parameters():\n",
    "    print(f\"Name: {name}, Size: {param.size()}, Requires Grad: {param.requires_grad}\")\n",
    "\n",
    "# Create dummy input for the MLP\n",
    "mlp_batch_size = 10\n",
    "mlp_dummy_input = torch.randn(mlp_batch_size, input_features)\n",
    "\n",
    "# Forward pass\n",
    "mlp_output = mlp_model(mlp_dummy_input)\n",
    "print(f\"\\nMLP Dummy Input shape: {mlp_dummy_input.shape}\")\n",
    "print(f\"MLP Output shape: {mlp_output.shape}\") # (mlp_batch_size, output_features)\n",
    "print(f\"MLP Output (first sample): {mlp_output[0].item()}\") # .item() if it's a single value tensor\n",
    "print(f\"MLP Output requires_grad: {mlp_output.requires_grad}\")\n",
    "```\n",
    "\n",
    "**Key Takeaways from `nn.Module` Usage:**\n",
    "\n",
    "* **Modularity:** You can define complex models by combining simpler modules.\n",
    "* **Parameter Tracking:** `nn.Module` automatically handles the registration and tracking of all learnable parameters within it and its submodules.\n",
    "* **Clear Separation:** `__init__` is for defining *what* layers exist, and `forward` is for defining *how* data flows through them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e3353-9ee5-45b6-87ea-95f7c8d9d71b",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 4: Loss Functions and Optimizers**\n",
    "\n",
    "In this part, we'll cover two critical components for training any neural network:\n",
    "\n",
    "1.  **Loss Functions:** These functions quantify how \"wrong\" our model's predictions are compared to the actual target values. The goal of training is to minimize this loss.\n",
    "2.  **Optimizers:** These algorithms use the gradients (computed by `autograd` based on the loss) to update the model's parameters (weights and biases) in a way that (hopefully) reduces the loss.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **Understanding Loss Functions (`torch.nn`)**\n",
    "    * Purpose and common types.\n",
    "    * Examples: `nn.MSELoss`, `nn.CrossEntropyLoss`, `nn.BCELoss`, `nn.BCEWithLogitsLoss`.\n",
    "2.  **Understanding Optimizers (`torch.optim`)**\n",
    "    * Purpose and common types.\n",
    "    * Key methods: `zero_grad()`, `step()`.\n",
    "    * Examples: `optim.SGD`, `optim.Adam`.\n",
    "3.  **How They Fit Together (Conceptual).**\n",
    "\n",
    "Let's begin!\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # For functional versions if needed\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Let's use the SimpleMLP from Part 3 as a reference for some examples\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # Output raw logits\n",
    "        return x\n",
    "```\n",
    "\n",
    "**1. Understanding Loss Functions (`torch.nn`)**\n",
    "\n",
    "A loss function (or criterion) takes the model's output and the true target values as input and computes a scalar value representing the \"loss\" or \"error.\" PyTorch provides many common loss functions in the `torch.nn` module. These are typically subclasses of `nn.Module`.\n",
    "\n",
    "* **`nn.MSELoss` (Mean Squared Error Loss):**\n",
    "    * Commonly used for **regression tasks** where the goal is to predict continuous values.\n",
    "    * Calculates the mean of the squared differences between each element in the input $x$ (predictions) and target $y$.\n",
    "    * Loss = $\\frac{1}{N} \\sum (x_i - y_i)^2$\n",
    "\n",
    "    ```python\n",
    "    print(\"--- nn.MSELoss Example ---\")\n",
    "    mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "    # Dummy predictions and targets for a regression problem\n",
    "    predictions_reg = torch.randn(5, 1) # 5 samples, 1 feature each\n",
    "    targets_reg = torch.randn(5, 1)\n",
    "    print(\"Predictions (regression):\\n\", predictions_reg)\n",
    "    print(\"Targets (regression):\\n\", targets_reg)\n",
    "\n",
    "    loss_mse = mse_loss_fn(predictions_reg, targets_reg)\n",
    "    print(f\"MSE Loss: {loss_mse.item()}\") # .item() to get the scalar value\n",
    "    ```\n",
    "\n",
    "* **`nn.CrossEntropyLoss`:**\n",
    "    * Very commonly used for **multi-class classification tasks**.\n",
    "    * This criterion combines `nn.LogSoftmax` and `nn.NLLLoss` in one single class.\n",
    "    * **Input (Predictions):** Raw, unnormalized scores (logits) for each class. Shape: `(batch_size, num_classes)`.\n",
    "    * **Target:** Class indices (long integers) for each sample. Shape: `(batch_size,)`, where each value is between `0` and `num_classes-1`.\n",
    "\n",
    "    ```python\n",
    "    print(\"\\n--- nn.CrossEntropyLoss Example ---\")\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Dummy predictions (logits) and targets for a 3-class classification problem\n",
    "    # Batch size of 4 samples\n",
    "    predictions_multi_class = torch.randn(4, 3) # 4 samples, 3 classes (raw logits)\n",
    "    targets_multi_class = torch.tensor([0, 2, 1, 0]) # True class indices for each sample\n",
    "\n",
    "    print(\"Predictions (multi-class logits):\\n\", predictions_multi_class)\n",
    "    print(\"Targets (multi-class indices):\\n\", targets_multi_class)\n",
    "\n",
    "    loss_ce = ce_loss_fn(predictions_multi_class, targets_multi_class)\n",
    "    print(f\"CrossEntropy Loss: {loss_ce.item()}\")\n",
    "    ```\n",
    "\n",
    "* **`nn.BCELoss` (Binary Cross Entropy Loss):**\n",
    "    * Used for **binary classification tasks** (two classes, e.g., 0 or 1).\n",
    "    * **Input (Predictions):** Probabilities for the positive class, typically after a Sigmoid activation. Values should be between 0 and 1. Shape: `(batch_size, 1)` or `(batch_size,)`.\n",
    "    * **Target:** Probabilities or binary labels (0 or 1). Should have the same shape as input.\n",
    "\n",
    "    ```python\n",
    "    print(\"\\n--- nn.BCELoss Example ---\")\n",
    "    bce_loss_fn = nn.BCELoss()\n",
    "    sigmoid = nn.Sigmoid() # To get probabilities\n",
    "\n",
    "    # Dummy predictions (logits) and targets for a binary classification problem\n",
    "    predictions_binary_logits = torch.randn(4, 1) # Raw logits\n",
    "    predictions_binary_probs = sigmoid(predictions_binary_logits) # Probabilities (0 to 1)\n",
    "    targets_binary = torch.tensor([[0.], [1.], [1.], [0.]]) # True binary labels\n",
    "\n",
    "    print(\"Predictions (binary probabilities after sigmoid):\\n\", predictions_binary_probs)\n",
    "    print(\"Targets (binary):\\n\", targets_binary)\n",
    "\n",
    "    loss_bce = bce_loss_fn(predictions_binary_probs, targets_binary)\n",
    "    print(f\"BCE Loss: {loss_bce.item()}\")\n",
    "    ```\n",
    "\n",
    "* **`nn.BCEWithLogitsLoss`:**\n",
    "    * Also used for **binary classification tasks**.\n",
    "    * This loss combines a Sigmoid layer and the BCELoss in one single class. It is numerically more stable than using a plain Sigmoid followed by a BCELoss.\n",
    "    * **Input (Predictions):** Raw, unnormalized scores (logits). Shape: `(batch_size, 1)` or `(batch_size,)`.\n",
    "    * **Target:** Probabilities or binary labels (0 or 1). Should have the same shape as input.\n",
    "\n",
    "    ```python\n",
    "    print(\"\\n--- nn.BCEWithLogitsLoss Example ---\")\n",
    "    bce_with_logits_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Use the same raw logits and targets as before\n",
    "    # predictions_binary_logits = torch.randn(4, 1) # from above\n",
    "    # targets_binary = torch.tensor([[0.], [1.], [1.], [0.]]) # from above\n",
    "\n",
    "    print(\"Predictions (binary raw logits):\\n\", predictions_binary_logits)\n",
    "    print(\"Targets (binary):\\n\", targets_binary)\n",
    "\n",
    "    loss_bce_logits = bce_with_logits_loss_fn(predictions_binary_logits, targets_binary)\n",
    "    print(f\"BCEWithLogits Loss: {loss_bce_logits.item()}\")\n",
    "    # This value should be very similar to the loss_bce calculated above\n",
    "    ```\n",
    "    **Recommendation:** Prefer `BCEWithLogitsLoss` over `Sigmoid + BCELoss` for binary classification due to better numerical stability.\n",
    "\n",
    "**2. Understanding Optimizers (`torch.optim`)**\n",
    "\n",
    "Optimizers are algorithms that adjust the model's parameters (weights and biases) to minimize the loss function. They use the gradients computed by `autograd`.\n",
    "\n",
    "* **Initialization:** You create an optimizer instance by passing it the model's parameters (which you want to optimize) and a learning rate (`lr`).\n",
    "    * `model.parameters()`: This method (from `nn.Module`) returns an iterator over all learnable parameters of the model.\n",
    "\n",
    "* **Key Optimizer Methods in a Training Loop:**\n",
    "    1.  **`optimizer.zero_grad()`:**\n",
    "        * This method sets the gradients of all model parameters being optimized to zero.\n",
    "        * It's crucial to call this *before* calling `loss.backward()` in each iteration. Why? Because, as discussed in Part 2, PyTorch accumulates gradients by default. If you don't zero them out, gradients from previous batches/iterations will interfere with the current update.\n",
    "    2.  **`loss.backward()`:** (Covered in Part 2)\n",
    "        * This computes the gradients of the loss with respect to the model parameters (and any other tensors with `requires_grad=True` that contributed to the loss).\n",
    "    3.  **`optimizer.step()`:**\n",
    "        * This method updates the values of the model parameters using the computed gradients and the specific optimization algorithm (e.g., SGD, Adam). This is where the actual \"learning\" happens.\n",
    "\n",
    "* **Common Optimizers:**\n",
    "\n",
    "    * **`optim.SGD` (Stochastic Gradient Descent):**\n",
    "        * A fundamental optimization algorithm.\n",
    "        * Can include `momentum` (helps accelerate SGD in the relevant direction and dampens oscillations) and `weight_decay` (L2 penalty to prevent overfitting).\n",
    "        ```python\n",
    "        # model = SimpleMLP(...) # Assume model is defined\n",
    "        # learning_rate_sgd = 0.01\n",
    "        # optimizer_sgd = optim.SGD(model.parameters(), lr=learning_rate_sgd, momentum=0.9)\n",
    "        ```\n",
    "\n",
    "    * **`optim.Adam` (Adaptive Moment Estimation):**\n",
    "        * A very popular and often effective adaptive learning rate optimization algorithm. It computes adaptive learning rates for each parameter.\n",
    "        * Often works well with default hyperparameters.\n",
    "        * `weight_decay` can also be used.\n",
    "        ```python\n",
    "        # model = SimpleMLP(...)\n",
    "        # learning_rate_adam = 0.001\n",
    "        # optimizer_adam = optim.Adam(model.parameters(), lr=learning_rate_adam)\n",
    "        ```\n",
    "    * **`optim.AdamW` (Adam with Decoupled Weight Decay):**\n",
    "        * A modification of Adam that often improves generalization by changing how weight decay is applied. Generally preferred over Adam when using weight decay.\n",
    "        ```python\n",
    "        # model = SimpleMLP(...)\n",
    "        # optimizer_adamw = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        ```\n",
    "\n",
    "* **Learning Rate (`lr`):**\n",
    "    * This is a crucial hyperparameter. It determines the step size at each iteration while moving toward a minimum of a loss function.\n",
    "    * Too small: Training will be very slow.\n",
    "    * Too large: Training might oscillate or diverge, never finding the minimum.\n",
    "    * Finding a good learning rate often requires experimentation. Learning rate schedules (dynamically changing the learning rate during training) are also common.\n",
    "\n",
    "**3. How They Fit Together (Conceptual Example)**\n",
    "\n",
    "Let's imagine a single training step with our `SimpleMLP`:\n",
    "\n",
    "```python\n",
    "print(\"\\n--- Conceptual Training Step ---\")\n",
    "# 1. Define Model, Loss, Optimizer\n",
    "input_dim_ex = 10\n",
    "hidden1_ex = 20\n",
    "hidden2_ex = 15\n",
    "output_dim_ex = 1 # For binary classification (logits)\n",
    "\n",
    "model = SimpleMLP(input_dim_ex, hidden1_ex, hidden2_ex, output_dim_ex)\n",
    "criterion = nn.BCEWithLogitsLoss() # Use this for raw logit output\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 2. Dummy Input and Target\n",
    "dummy_inputs = torch.randn(8, input_dim_ex) # Batch of 8 samples\n",
    "dummy_targets = torch.randint(0, 2, (8, 1)).float() # Binary targets (0 or 1)\n",
    "\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Criterion: {criterion.__class__.__name__}\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Dummy Inputs shape: {dummy_inputs.shape}\")\n",
    "print(f\"Dummy Targets shape: {dummy_targets.shape}\")\n",
    "\n",
    "\n",
    "# --- A Single Training Step ---\n",
    "# a. Zero gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# b. Forward pass: Get model predictions\n",
    "outputs = model(dummy_inputs)\n",
    "print(f\"Model outputs shape: {outputs.shape}\")\n",
    "\n",
    "# c. Calculate loss\n",
    "loss = criterion(outputs, dummy_targets)\n",
    "print(f\"Calculated Loss: {loss.item()}\")\n",
    "\n",
    "# d. Backward pass: Compute gradients of the loss w.r.t. model parameters\n",
    "loss.backward()\n",
    "# Now model parameters (e.g., model.fc1.weight.grad) will have gradients\n",
    "\n",
    "# e. Optimizer step: Update model parameters based on gradients\n",
    "optimizer.step()\n",
    "\n",
    "# After optimizer.step(), the model's weights have been updated!\n",
    "# We could check, for example, model.fc1.weight.data to see it changed slightly.\n",
    "# For a real effect, this loop would repeat many times.\n",
    "\n",
    "print(\"Conceptual training step completed (parameters would have been updated).\")\n",
    "```\n",
    "This small snippet shows the core interaction: `optimizer.zero_grad()`, forward pass, loss calculation, `loss.backward()`, and `optimizer.step()`. This cycle is the heart of most training loops in PyTorch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf46a11f-5bcb-4b59-b2e9-05856b11934b",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 5: Data Handling with `Dataset` and `DataLoader`**\n",
    "\n",
    "Training deep learning models often involves large datasets. Loading, preprocessing, and batching this data efficiently is crucial for fast and effective training. PyTorch provides two core utilities in `torch.utils.data` to help with this:\n",
    "\n",
    "1.  **`Dataset`:** An abstract class representing your dataset. It provides a way to access individual data samples and their corresponding labels.\n",
    "2.  **`DataLoader`:** Wraps a `Dataset` and provides an iterable over it, enabling easy batching, shuffling, and parallel data loading.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **The `torch.utils.data.Dataset` Class:**\n",
    "    * Understanding its role.\n",
    "    * How to create a custom `Dataset` by implementing `__len__` and `__getitem__`.\n",
    "2.  **The `torch.utils.data.DataLoader` Class:**\n",
    "    * Its purpose: batching, shuffling, parallel loading.\n",
    "    * Key parameters: `batch_size`, `shuffle`, `num_workers`.\n",
    "3.  **Example: Creating and Using a Custom `Dataset` with `DataLoader`.**\n",
    "4.  **Using Pre-built Datasets (e.g., from `torchvision.datasets`) and Transforms.**\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd # For a slightly more realistic custom dataset example\n",
    "\n",
    "# For torchvision example\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "```\n",
    "\n",
    "**1. The `torch.utils.data.Dataset` Class**\n",
    "\n",
    "A `Dataset` object in PyTorch is anything that has a `__getitem__` method and a `__len__` method.\n",
    "* `__len__(self)` should return the total number of samples in your dataset.\n",
    "* `__getitem__(self, index)` should return the data sample (e.g., features and label) at the given `index`.\n",
    "\n",
    "You typically create your own custom dataset class by inheriting from `torch.utils.data.Dataset` and implementing these two methods.\n",
    "\n",
    "* **`__init__(self, ...)`:** In the constructor, you'll usually load your data from files, or if it's small, store it directly in memory (e.g., as lists or tensors). You might also perform initial one-time preprocessing here.\n",
    "\n",
    "**Example: A Simple Custom Dataset**\n",
    "\n",
    "Let's create a very basic dataset with some dummy features and labels.\n",
    "\n",
    "```python\n",
    "class MySimpleCustomDataset(Dataset):\n",
    "    def __init__(self, num_samples=100, num_features=5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_samples (int): Number of samples in the dataset.\n",
    "            num_features (int): Number of features per sample.\n",
    "        \"\"\"\n",
    "        print(f\"Initializing MySimpleCustomDataset with {num_samples} samples.\")\n",
    "        # Generate some random features and labels\n",
    "        self.features = torch.randn(num_samples, num_features)\n",
    "        self.labels = torch.randint(0, 2, (num_samples,)) # Binary labels (0 or 1)\n",
    "        print(\"Data generation complete.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the total number of samples in the dataset\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns the sample (features and label) at the given index\n",
    "        # It's good practice to ensure idx is in range, though DataLoader handles this.\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample_features = self.features[idx]\n",
    "        sample_label = self.labels[idx]\n",
    "        \n",
    "        # You can return them as a tuple, dictionary, or any structure you prefer\n",
    "        return sample_features, sample_label\n",
    "\n",
    "print(\"--- MySimpleCustomDataset ---\")\n",
    "simple_dataset = MySimpleCustomDataset(num_samples=10, num_features=3)\n",
    "\n",
    "# Test __len__\n",
    "print(f\"Length of simple_dataset: {len(simple_dataset)}\")\n",
    "\n",
    "# Test __getitem__\n",
    "first_sample_features, first_sample_label = simple_dataset[0]\n",
    "print(f\"First sample features: {first_sample_features}\")\n",
    "print(f\"First sample label: {first_sample_label}\")\n",
    "\n",
    "fifth_sample_features, fifth_sample_label = simple_dataset[4]\n",
    "print(f\"\\nFifth sample features: {fifth_sample_features}\")\n",
    "print(f\"Fifth sample label: {fifth_sample_label}\")\n",
    "```\n",
    "\n",
    "**Example: Custom Dataset from a Pandas DataFrame (More Realistic)**\n",
    "\n",
    "Often, your data might be in a CSV file, which you can load into a Pandas DataFrame.\n",
    "\n",
    "```python\n",
    "class PandasDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_columns, target_column):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): The pandas DataFrame containing the data.\n",
    "            feature_columns (list of str): List of column names for features.\n",
    "            target_column (str): Column name for the target label.\n",
    "        \"\"\"\n",
    "        print(\"Initializing PandasDataset...\")\n",
    "        self.features = torch.tensor(dataframe[feature_columns].values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(dataframe[target_column].values, dtype=torch.long) # Assuming classification\n",
    "        print(\"Data converted to tensors.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "print(\"\\n--- PandasDataset ---\")\n",
    "# Create a dummy Pandas DataFrame\n",
    "data = {\n",
    "    'feature1': np.random.rand(20),\n",
    "    'feature2': np.random.rand(20) * 10,\n",
    "    'feature3': np.random.rand(20) - 0.5,\n",
    "    'target': np.random.randint(0, 3, 20) # 3 classes (0, 1, 2)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample DataFrame head:\\n\", df.head())\n",
    "\n",
    "feature_cols = ['feature1', 'feature2', 'feature3']\n",
    "target_col = 'target'\n",
    "\n",
    "pandas_dataset = PandasDataset(df, feature_columns=feature_cols, target_column=target_col)\n",
    "print(f\"Length of pandas_dataset: {len(pandas_dataset)}\")\n",
    "features_pd_0, label_pd_0 = pandas_dataset[0]\n",
    "print(f\"First sample from pandas_dataset - Features: {features_pd_0}, Label: {label_pd_0}\")\n",
    "```\n",
    "\n",
    "**2. The `torch.utils.data.DataLoader` Class**\n",
    "\n",
    "Once you have a `Dataset`, you'll usually wrap it with a `DataLoader`. The `DataLoader` takes care of:\n",
    "\n",
    "* **Batching:** Grouping multiple samples into a \"batch\" for processing. Training on batches is more computationally efficient and can lead to more stable gradient estimates.\n",
    "* **Shuffling:** Randomly shuffling the data at the beginning of each epoch. This is crucial for preventing the model from learning the order of the data and helps in generalization.\n",
    "* **Parallel Data Loading (`num_workers`):** Using multiple subprocesses to load data in the background while the GPU is busy with model computations. This can significantly speed up training if data loading/preprocessing is a bottleneck.\n",
    "* **Custom Collation (`collate_fn`):** (Advanced) Allows you to define how individual samples (returned by `Dataset.__getitem__`) are combined into a batch. Useful for tasks like padding sequences of varying lengths.\n",
    "\n",
    "**Key `DataLoader` Parameters:**\n",
    "\n",
    "* `dataset`: The `Dataset` object to load data from.\n",
    "* `batch_size (int, optional)`: How many samples per batch to load (default: `1`).\n",
    "* `shuffle (bool, optional)`: Set to `True` to have the data reshuffled at every epoch (default: `False`).\n",
    "* `num_workers (int, optional)`: How many subprocesses to use for data loading. `0` means that the data will be loaded in the main process (default: `0`).\n",
    "    * **Note on `num_workers` on Windows:** If using `num_workers > 0` on Windows (or sometimes macOS with certain Python versions), you often need to wrap your main training script logic in an `if __name__ == '__main__':` block to avoid issues with multiprocessing.\n",
    "* `pin_memory (bool, optional)`: If `True`, the `DataLoader` will copy Tensors into CUDA pinned memory before returning them. This can speed up data transfer to the GPU (default: `False`).\n",
    "* `drop_last (bool, optional)`: Set to `True` to drop the last incomplete batch, if the dataset size is not divisible by the batch size (default: `False`).\n",
    "\n",
    "**3. Example: Using `DataLoader` with a Custom `Dataset`**\n",
    "\n",
    "Let's use our `MySimpleCustomDataset` with a `DataLoader`.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- DataLoader with MySimpleCustomDataset ---\")\n",
    "simple_dataset_for_loader = MySimpleCustomDataset(num_samples=60, num_features=4)\n",
    "\n",
    "# Create a DataLoader instance\n",
    "batch_size = 16\n",
    "# On Windows, if num_workers > 0, you might need if __name__ == '__main__':\n",
    "# For this interactive example, num_workers=0 is safest for broad compatibility.\n",
    "data_loader = DataLoader(dataset=simple_dataset_for_loader,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,       # Shuffle data at each epoch\n",
    "                         num_workers=0)      # Use 0 for this example\n",
    "\n",
    "# Iterate through the DataLoader (e.g., in a training epoch)\n",
    "print(f\"\\nIterating through DataLoader (batch_size={batch_size}):\")\n",
    "# In a real training loop, this would be inside an epoch loop\n",
    "for epoch in range(1): # Simulate one epoch\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    for i, (batch_features, batch_labels) in enumerate(data_loader):\n",
    "        print(f\"  Batch {i+1}:\")\n",
    "        print(f\"    Batch features shape: {batch_features.shape}\") # (batch_size, num_features)\n",
    "        print(f\"    Batch labels shape: {batch_labels.shape}\")     # (batch_size,)\n",
    "        # In a real loop, you would:\n",
    "        # 1. Move data to device (e.g., batch_features.to(device))\n",
    "        # 2. Perform forward pass\n",
    "        # 3. Calculate loss\n",
    "        # 4. Backward pass\n",
    "        # 5. Optimizer step\n",
    "        if i == 2: # Print first 3 batches for brevity\n",
    "            break \n",
    "```\n",
    "You'll notice that if `shuffle=True`, the order of samples will be different each time you iterate through the `data_loader` in a new \"epoch.\"\n",
    "\n",
    "**4. Using Pre-built Datasets (e.g., from `torchvision.datasets`) and Transforms**\n",
    "\n",
    "PyTorch's domain-specific libraries like `torchvision`, `torchaudio`, and `torchtext` (though `torchtext`'s usage has evolved) provide many pre-built datasets. `torchvision` is particularly popular for computer vision.\n",
    "\n",
    "These datasets often integrate with `torchvision.transforms`, which are common image transformations (e.g., converting to tensor, normalizing, resizing, cropping, data augmentation).\n",
    "\n",
    "**Example: MNIST Dataset from `torchvision`**\n",
    "\n",
    "```python\n",
    "print(\"\\n--- torchvision.datasets.MNIST Example ---\")\n",
    "\n",
    "# Define transformations\n",
    "# 1. Convert PIL Image to PyTorch Tensor\n",
    "# 2. Normalize the tensor (mean and std dev for MNIST are approx 0.1307 and 0.3081)\n",
    "mnist_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # (mean,), (std,) for grayscale\n",
    "])\n",
    "\n",
    "# Download and load the training data (if not already downloaded)\n",
    "# Set download=True for the first time\n",
    "try:\n",
    "    train_mnist_dataset = torchvision.datasets.MNIST(\n",
    "        root='./data_mnist',  # Directory to store the data\n",
    "        train=True,          # Get the training set\n",
    "        transform=mnist_transforms, # Apply defined transformations\n",
    "        download=True        # Download if not present\n",
    "    )\n",
    "    print(\"MNIST training dataset loaded/downloaded successfully.\")\n",
    "\n",
    "    # Create a DataLoader for the MNIST training set\n",
    "    mnist_train_loader = DataLoader(\n",
    "        dataset=train_mnist_dataset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=0 # For simplicity in this example\n",
    "    )\n",
    "\n",
    "    # Get one batch of images and labels\n",
    "    print(\"\\nIterating through MNIST DataLoader (one batch):\")\n",
    "    for images, labels in mnist_train_loader:\n",
    "        print(f\"  Images batch shape: {images.shape}\") # (batch_size, channels, height, width) -> (64, 1, 28, 28)\n",
    "        print(f\"  Labels batch shape: {labels.shape}\")   # (batch_size,) -> (64)\n",
    "        print(f\"  Sample labels from batch: {labels[:5]}\")\n",
    "        break # Just show one batch\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Could not load/download MNIST. Error: {e}\")\n",
    "    print(\"Please ensure you have an internet connection if downloading for the first time,\")\n",
    "    print(\"or check write permissions for the './data_mnist' directory.\")\n",
    "\n",
    "```\n",
    "`transforms.Compose` chains multiple transformations together. `ToTensor()` converts a PIL Image or NumPy `ndarray` in the range [0, 255] to a `torch.FloatTensor` of shape (C x H x W) in the range [0.0, 1.0]. `Normalize()` normalizes the tensor with a given mean and standard deviation.\n",
    "\n",
    "---\n",
    "\n",
    "This part has equipped you with the knowledge to handle data efficiently in PyTorch using `Dataset` and `DataLoader`. You can create custom datasets for your specific data and use DataLoaders to prepare batches for your model, along with leveraging pre-built datasets and transforms from libraries like `torchvision`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c94e3-bde0-4762-bbcd-a214ef9e9568",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 6: A Complete Training Loop**\n",
    "\n",
    "In this part, we will write the full Python script to:\n",
    "1.  Load a dataset (we'll use MNIST).\n",
    "2.  Define a simple neural network.\n",
    "3.  Define a loss function and an optimizer.\n",
    "4.  Train the network for a few epochs, printing progress.\n",
    "5.  Evaluate the network's performance on a test set.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **Setting up the Environment and Data.**\n",
    "2.  **Defining the Neural Network Model.**\n",
    "3.  **Defining Loss Function and Optimizer.**\n",
    "4.  **The Training Loop:**\n",
    "    * Iterating through epochs and batches.\n",
    "    * Moving data to the device (CPU/GPU).\n",
    "    * Zeroing gradients.\n",
    "    * Forward pass.\n",
    "    * Loss calculation.\n",
    "    * Backward pass.\n",
    "    * Optimizer step.\n",
    "5.  **The Evaluation Loop:**\n",
    "    * Using `model.eval()` and `torch.no_grad()`.\n",
    "    * Calculating accuracy.\n",
    "6.  **Running the Complete Script.**\n",
    "\n",
    "Let's put it all together!\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms # For image transformations\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Torchvision Version: {torchvision.__version__}\")\n",
    "\n",
    "# --- 1. Configuration and Device Setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 28 * 28  # MNIST images are 28x28 pixels\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "num_classes = 10      # Digits 0-9\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 5        # Train for a few epochs for demonstration\n",
    "\n",
    "# --- 2. Load MNIST Dataset ---\n",
    "# Transformations to apply to the data\n",
    "# ToTensor() converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255]\n",
    "# to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "# Normalize() normalizes a tensor image with mean and standard deviation.\n",
    "# For MNIST, the mean and std are approximately 0.1307 and 0.3081 respectively.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download and load training dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data_mnist',\n",
    "                                           train=True,\n",
    "                                           transform=transform,\n",
    "                                           download=True)\n",
    "\n",
    "# Download and load test dataset\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data_mnist',\n",
    "                                          train=False,\n",
    "                                          transform=transform,\n",
    "                                          download=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "# num_workers=0 means data loading will happen in the main process.\n",
    "# For faster loading, you can increase num_workers, but be mindful of\n",
    "# the `if __name__ == '__main__':` guard on Windows.\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True, # Shuffle training data\n",
    "                          num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False, # No need to shuffle test data\n",
    "                         num_workers=0)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "\n",
    "# --- 3. Define the Neural Network Model ---\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_s, hidden1_s, hidden2_s, output_s):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_s, hidden1_s)\n",
    "        self.fc2 = nn.Linear(hidden1_s, hidden2_s)\n",
    "        self.fc3 = nn.Linear(hidden2_s, output_s)\n",
    "        # No Softmax here because nn.CrossEntropyLoss will apply it internally\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the image (28x28) into a 1D vector (784)\n",
    "        x = x.view(-1, 28*28) # -1 infers the batch size\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # Output raw logits\n",
    "        return x\n",
    "\n",
    "model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# --- 4. Define Loss Function and Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss() # Combines LogSoftmax and NLLLoss\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# --- 5. Training Loop ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set the model to training mode (enables dropout, batchnorm updates etc.)\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 1. Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 2. Forward pass\n",
    "        outputs = model(images) # images are already flattened in the model's forward method\n",
    "\n",
    "        # 3. Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 4. Backward pass (compute gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step (update parameters)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0) # loss.item() is avg loss for batch\n",
    "\n",
    "        # Calculate training accuracy for this batch\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 100 == 0: # Print every 100 mini-batches\n",
    "            avg_batch_loss = loss.item() # Average loss for current batch\n",
    "            current_batch_accuracy = 100 * (predicted_train == labels).sum().item() / labels.size(0)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Batch Loss: {avg_batch_loss:.4f}, Batch Accuracy: {current_batch_accuracy:.2f}%\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_accuracy_train = 100 * correct_train / total_train\n",
    "    print(f\"--- Epoch {epoch+1} Finished ---\")\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy_train:.2f}%\")\n",
    "\n",
    "    # --- 6. Evaluation Loop (on Test Set after each epoch) ---\n",
    "    model.eval() # Set the model to evaluation mode (disables dropout, uses learned batchnorm stats)\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad(): # Disable gradient calculations for evaluation\n",
    "        for images_test, labels_test in test_loader:\n",
    "            images_test = images_test.to(device)\n",
    "            labels_test = labels_test.to(device)\n",
    "\n",
    "            outputs_test = model(images_test)\n",
    "            loss_test_batch = criterion(outputs_test, labels_test)\n",
    "            test_loss += loss_test_batch.item() * images_test.size(0)\n",
    "\n",
    "            _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "            total_test += labels_test.size(0)\n",
    "            correct_test += (predicted_test == labels_test).sum().item()\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_dataset)\n",
    "    accuracy_test = 100 * correct_test / total_test\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy_test:.2f}%\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"--- Training Finished ---\")\n",
    "\n",
    "# --- 7. (Optional) Save the trained model ---\n",
    "# torch.save(model.state_dict(), 'mnist_mlp_model.pth')\n",
    "# print(\"Trained model state_dict saved to mnist_mlp_model.pth\")\n",
    "\n",
    "# To load:\n",
    "# loaded_model = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "# loaded_model.load_state_dict(torch.load('mnist_mlp_model.pth'))\n",
    "# loaded_model.eval() # Don't forget for inference\n",
    "```\n",
    "\n",
    "**Explanation of the Code:**\n",
    "\n",
    "1.  **Configuration and Device:** Sets up hyperparameters and determines if a GPU is available.\n",
    "2.  **Load MNIST Dataset:**\n",
    "    * Uses `torchvision.datasets.MNIST` to download/load the dataset.\n",
    "    * `transforms.Compose` is used to chain `transforms.ToTensor()` (converts image to tensor and scales to [0,1]) and `transforms.Normalize()` (normalizes tensor values).\n",
    "    * `DataLoader` instances are created for both training and test sets. `shuffle=True` is important for the training loader.\n",
    "3.  **Define Model (`SimpleMLP`):**\n",
    "    * A simple Multi-Layer Perceptron with two hidden layers and ReLU activations.\n",
    "    * The `forward` method includes `x.view(-1, 28*28)` to flatten the 2D image (1x28x28) into a 1D vector (784 features) before passing it to the linear layers. Note that `images` from `DataLoader` will have shape `(batch_size, 1, 28, 28)`.\n",
    "4.  **Loss and Optimizer:**\n",
    "    * `nn.CrossEntropyLoss` is chosen because MNIST is a multi-class classification problem (digits 0-9). This loss function expects raw logits as model output (which our `SimpleMLP` provides).\n",
    "    * `optim.Adam` is used as the optimizer.\n",
    "5.  **Training Loop (`for epoch in range(num_epochs):`)**\n",
    "    * `model.train()`: Sets the model to training mode. This is important because some layers like Dropout and BatchNorm behave differently during training and evaluation.\n",
    "    * The inner loop iterates through batches provided by `train_loader`.\n",
    "    * **Device Transfer:** `images.to(device)` and `labels.to(device)` move the data for the current batch to the GPU if available.\n",
    "    * **`optimizer.zero_grad()`:** Clears previously accumulated gradients. This must be done before the backward pass.\n",
    "    * **Forward Pass:** `outputs = model(images)` gets the predictions from the model.\n",
    "    * **Loss Calculation:** `loss = criterion(outputs, labels)` computes the loss.\n",
    "    * **Backward Pass:** `loss.backward()` computes the gradients of the loss with respect to all model parameters that have `requires_grad=True`.\n",
    "    * **Optimizer Step:** `optimizer.step()` updates the model parameters based on the computed gradients.\n",
    "    * **Logging:** Prints loss and accuracy periodically.\n",
    "6.  **Evaluation Loop (`model.eval()`, `with torch.no_grad():`)**\n",
    "    * `model.eval()`: Sets the model to evaluation mode. This turns off dropout and makes batch normalization use its learned running statistics instead of batch statistics.\n",
    "    * `with torch.no_grad():`: Disables gradient computation within this block. This is crucial for evaluation as it reduces memory consumption and speeds up computations since we don't need gradients here.\n",
    "    * The loop iterates through the `test_loader`.\n",
    "    * It calculates the average loss and accuracy on the test set.\n",
    "7.  **Saving the Model (Optional):**\n",
    "    * `torch.save(model.state_dict(), 'filename.pth')` is the recommended way to save model parameters.\n",
    "\n",
    "**To Run This Code:**\n",
    "1.  Make sure you have PyTorch and Torchvision installed (`pip install torch torchvision`).\n",
    "2.  Save the code as a Python file (e.g., `pytorch_training.py`).\n",
    "3.  Run it from your terminal: `python pytorch_training.py`.\n",
    "\n",
    "You should see the training progress printed, with loss decreasing and accuracy (hopefully) increasing over the epochs for both training and test sets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3badb-2a4c-4b72-bbc3-37781584a983",
   "metadata": {},
   "source": [
    "**PyTorch Tutorial Part 7: Saving and Loading Models in Detail**\n",
    "\n",
    "Once you've spent time training a model, you'll want to save it for several reasons:\n",
    "* **Persistence:** To use it later for inference without retraining.\n",
    "* **Sharing:** To share your trained model with others.\n",
    "* **Resuming Training:** To continue training from where you left off, especially for long training jobs.\n",
    "* **Deployment:** To deploy the model into a production environment.\n",
    "* **Fine-tuning:** To use it as a base for transfer learning on a new task.\n",
    "\n",
    "PyTorch provides flexible ways to save and load models. We'll explore the most common and recommended approaches.\n",
    "\n",
    "**What we'll cover in this part:**\n",
    "\n",
    "1.  **What to Save?**\n",
    "2.  **Saving and Loading `state_dict` (Recommended for Inference & Sharing)**\n",
    "3.  **Saving and Loading Entire Models (Less Flexible)**\n",
    "4.  **Saving and Loading Checkpoints (For Resuming Training)**\n",
    "5.  **Handling Devices (CPU/GPU) During Save/Load.**\n",
    "6.  **Best Practices.**\n",
    "\n",
    "Let's use a slightly simplified version of our `SimpleMLP` from Part 6 for these examples.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os # For file operations\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Define a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define our SimpleMLP model (from Part 6, slightly simplified for clarity here)\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_s, hidden1_s, hidden2_s, output_s):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_s, hidden1_s)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_s, hidden2_s)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden2_s, output_s)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Assuming MNIST-like flat input\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Model dimensions (example for MNIST)\n",
    "input_size = 28 * 28\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "num_classes = 10\n",
    "\n",
    "# Create a dummy model instance for demonstration\n",
    "model_to_save = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "# In a real scenario, this model would be trained.\n",
    "# For demonstration, we'll use its initial random weights.\n",
    "print(\"Model instantiated for saving/loading examples.\")\n",
    "```\n",
    "\n",
    "**1. What to Save?**\n",
    "\n",
    "PyTorch allows you to save different aspects of your model:\n",
    "\n",
    "* **`model.state_dict()`:** This is a Python dictionary object that maps each layer to its learnable parameters (weights and biases). It only saves the parameters, not the model architecture itself. This is the **recommended approach** for saving models for inference, sharing, or transfer learning because it's more flexible and portable.\n",
    "* **Entire Model:** You can save the entire model object using `torch.save(model, PATH)`. This uses Python's `pickle` module to serialize the model object, including its architecture. While convenient, it can be brittle if the code defining the model changes or if you try to load it in a different project.\n",
    "* **Checkpoint:** A dictionary containing various pieces of information needed to resume training, such as the model's `state_dict`, the optimizer's `state_dict`, the current epoch, the latest loss, etc.\n",
    "\n",
    "**2. Saving and Loading `state_dict` (Recommended)**\n",
    "\n",
    "This method saves only the learnable parameters (weights and biases) of the model.\n",
    "\n",
    "* **Saving `state_dict`:**\n",
    "    ```python\n",
    "    print(\"\\n--- Saving and Loading state_dict ---\")\n",
    "    STATE_DICT_PATH = \"simple_mlp_statedict.pth\"\n",
    "\n",
    "    # 1. Get the state_dict\n",
    "    model_state_dict = model_to_save.state_dict()\n",
    "    # print(\"Model state_dict keys:\", model_state_dict.keys()) # See what's inside\n",
    "\n",
    "    # 2. Save it\n",
    "    torch.save(model_state_dict, STATE_DICT_PATH)\n",
    "    print(f\"Model state_dict saved to: {STATE_DICT_PATH}\")\n",
    "    ```\n",
    "\n",
    "* **Loading `state_dict`:**\n",
    "    To load the `state_dict`, you first need to create an instance of your model class (so PyTorch knows the architecture).\n",
    "    ```python\n",
    "    # 1. Instantiate the model architecture\n",
    "    # This MUST be the same architecture as the one whose state_dict was saved\n",
    "    loaded_model_from_statedict = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "    print(f\"\\nNew model instance created for loading state_dict.\")\n",
    "\n",
    "    # 2. Load the state_dict\n",
    "    # Ensure the model is on the same device as the saved parameters, or use map_location (see later)\n",
    "    state_dict_loaded = torch.load(STATE_DICT_PATH, map_location=device)\n",
    "    loaded_model_from_statedict.load_state_dict(state_dict_loaded)\n",
    "    print(f\"Model state_dict loaded from: {STATE_DICT_PATH}\")\n",
    "\n",
    "    # 3. Set the model to evaluation mode (IMPORTANT for inference)\n",
    "    # This turns off layers like Dropout and sets BatchNorm to use running statistics.\n",
    "    loaded_model_from_statedict.eval()\n",
    "    print(\"Loaded model set to evaluation mode.\")\n",
    "\n",
    "    # Now you can use loaded_model_from_statedict for inference\n",
    "    # Example:\n",
    "    dummy_input = torch.randn(1, 1, 28, 28).to(device) # Batch of 1, 1 channel, 28x28\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        output = loaded_model_from_statedict(dummy_input)\n",
    "    print(f\"Output from loaded model (state_dict): {output.argmax(dim=1).item()}\")\n",
    "    ```\n",
    "\n",
    "**3. Saving and Loading Entire Models**\n",
    "\n",
    "This method saves the entire Python object using `pickle`.\n",
    "\n",
    "* **Saving Entire Model:**\n",
    "    ```python\n",
    "    print(\"\\n--- Saving and Loading Entire Model ---\")\n",
    "    ENTIRE_MODEL_PATH = \"simple_mlp_entire_model.pth\"\n",
    "\n",
    "    torch.save(model_to_save, ENTIRE_MODEL_PATH)\n",
    "    print(f\"Entire model saved to: {ENTIRE_MODEL_PATH}\")\n",
    "    ```\n",
    "\n",
    "* **Loading Entire Model:**\n",
    "    ```python\n",
    "    # No need to instantiate the model class first\n",
    "    loaded_entire_model = torch.load(ENTIRE_MODEL_PATH, map_location=device)\n",
    "    print(f\"\\nEntire model loaded from: {ENTIRE_MODEL_PATH}\")\n",
    "\n",
    "    # Remember to set to evaluation mode\n",
    "    loaded_entire_model.eval()\n",
    "    print(\"Loaded entire model set to evaluation mode.\")\n",
    "\n",
    "    # Example inference\n",
    "    with torch.no_grad():\n",
    "        output_entire = loaded_entire_model(dummy_input)\n",
    "    print(f\"Output from loaded entire model: {output_entire.argmax(dim=1).item()}\")\n",
    "    ```\n",
    "    **Caution:** While simpler, this method is less portable. If the code defining `SimpleMLP` changes, or if you try to load this in an environment where `SimpleMLP` isn't defined exactly the same way, it might break. The `state_dict` approach is generally more robust.\n",
    "\n",
    "**4. Saving and Loading Checkpoints (For Resuming Training)**\n",
    "\n",
    "When training large models, you often want to save checkpoints periodically. A checkpoint typically includes more than just the model's parameters; it might include the optimizer's state, the current epoch, the latest loss, etc. This allows you to resume training exactly where you left off if it gets interrupted.\n",
    "\n",
    "```python\n",
    "print(\"\\n--- Saving and Loading Checkpoints ---\")\n",
    "CHECKPOINT_PATH = \"simple_mlp_checkpoint.pth\"\n",
    "\n",
    "# Assume we are in a training loop\n",
    "current_epoch = 3 # Example epoch\n",
    "current_loss = 0.567 # Example loss\n",
    "optimizer_for_checkpoint = optim.Adam(model_to_save.parameters(), lr=0.001)\n",
    "# Simulate a few optimizer steps to have a state\n",
    "for _ in range(5):\n",
    "    optimizer_for_checkpoint.zero_grad()\n",
    "    # dummy loss and backward\n",
    "    d_loss = model_to_save(torch.randn(1,1,28,28).to(device)).sum()\n",
    "    d_loss.backward()\n",
    "    optimizer_for_checkpoint.step()\n",
    "\n",
    "\n",
    "# Saving a checkpoint\n",
    "print(f\"Saving checkpoint at epoch {current_epoch}...\")\n",
    "checkpoint = {\n",
    "    'epoch': current_epoch,\n",
    "    'model_state_dict': model_to_save.state_dict(),\n",
    "    'optimizer_state_dict': optimizer_for_checkpoint.state_dict(),\n",
    "    'loss': current_loss,\n",
    "    # You can add any other information you need\n",
    "    'hyperparameters': {'input_size': input_size, 'hidden1': hidden_size1, 'hidden2': hidden_size2, 'classes': num_classes}\n",
    "}\n",
    "torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "print(f\"Checkpoint saved to: {CHECKPOINT_PATH}\")\n",
    "\n",
    "\n",
    "# Loading a checkpoint to resume training\n",
    "print(\"\\nLoading checkpoint to resume training...\")\n",
    "# 1. Instantiate model and optimizer (architecture must match)\n",
    "model_to_resume = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes).to(device)\n",
    "optimizer_to_resume = optim.Adam(model_to_resume.parameters(), lr=0.0005) # LR might be overwritten or you might store it\n",
    "\n",
    "# 2. Load the checkpoint dictionary\n",
    "loaded_checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "# 3. Load states into model and optimizer\n",
    "model_to_resume.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
    "optimizer_to_resume.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# 4. Load other information\n",
    "start_epoch = loaded_checkpoint['epoch'] + 1 # Start from the next epoch\n",
    "last_loss = loaded_checkpoint['loss']\n",
    "hyperparams = loaded_checkpoint['hyperparameters']\n",
    "\n",
    "print(f\"Resuming training from epoch {start_epoch}\")\n",
    "print(f\"Last recorded loss: {last_loss}\")\n",
    "print(f\"Loaded hyperparameters: {hyperparams}\")\n",
    "\n",
    "# 5. Set model to training mode if you are resuming training\n",
    "model_to_resume.train()\n",
    "print(\"Model set to train mode for resuming.\")\n",
    "\n",
    "# Now you can continue your training loop with model_to_resume, optimizer_to_resume, from start_epoch\n",
    "# for epoch in range(start_epoch, num_total_epochs):\n",
    "#     # ... your training code ...\n",
    "```\n",
    "\n",
    "**5. Handling Devices (CPU/GPU) During Save/Load**\n",
    "\n",
    "It's common to train a model on a GPU and then deploy it or load it for inference on a CPU (or a different GPU setup).\n",
    "\n",
    "* **Saving:** When you save `model.state_dict()`, it saves the parameters as they are, including their device information.\n",
    "* **Loading with `map_location`:** The `torch.load()` function has a `map_location` argument that is crucial for device handling:\n",
    "    * `torch.load(PATH, map_location=torch.device('cpu'))`: Loads all tensors onto the CPU, regardless of where they were when saved.\n",
    "    * `torch.load(PATH, map_location=torch.device('cuda:0'))`: Loads all tensors onto GPU 0.\n",
    "    * `torch.load(PATH, map_location=device)`: Loads onto the `device` you've defined (e.g., chosen GPU or CPU).\n",
    "\n",
    "```python\n",
    "print(\"\\n--- Handling Devices During Save/Load ---\")\n",
    "# Assume model_to_save was trained and is currently on 'device' (e.g., GPU if available)\n",
    "# model_to_save is already on 'device' from its instantiation\n",
    "\n",
    "STATE_DICT_GPU_PATH = \"model_gpu_statedict.pth\"\n",
    "torch.save(model_to_save.state_dict(), STATE_DICT_GPU_PATH)\n",
    "print(f\"Model (potentially on GPU) state_dict saved to {STATE_DICT_GPU_PATH}\")\n",
    "\n",
    "# Example 1: Load a GPU-trained model onto CPU\n",
    "print(\"\\nLoading model onto CPU explicitly:\")\n",
    "model_on_cpu = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes) # Instantiate on CPU by default\n",
    "# Load state_dict and map it to CPU\n",
    "cpu_state_dict = torch.load(STATE_DICT_GPU_PATH, map_location=torch.device('cpu'))\n",
    "model_on_cpu.load_state_dict(cpu_state_dict)\n",
    "model_on_cpu.eval()\n",
    "print(f\"Model loaded on CPU. First parameter device: {next(model_on_cpu.parameters()).device}\")\n",
    "\n",
    "# Example 2: If you have a GPU and want to ensure loading onto the current 'device'\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nLoading model onto current 'device' (which could be GPU):\")\n",
    "    model_on_current_device = SimpleMLP(input_size, hidden_size1, hidden_size2, num_classes)\n",
    "    # No need to move model_on_current_device to device yet, load_state_dict can handle if parameters are moved by map_location\n",
    "    state_dict_for_current_device = torch.load(STATE_DICT_GPU_PATH, map_location=device)\n",
    "    model_on_current_device.load_state_dict(state_dict_for_current_device)\n",
    "    model_on_current_device.to(device) # Ensure model structure itself is on the device\n",
    "    model_on_current_device.eval()\n",
    "    print(f\"Model loaded on {device}. First parameter device: {next(model_on_current_device.parameters()).device}\")\n",
    "```\n",
    "**General workflow for loading a model that might have been saved from a GPU:**\n",
    "1.  Load the `state_dict` using `map_location` to specify the target device.\n",
    "2.  Instantiate your model architecture.\n",
    "3.  Load the `state_dict` into your model instance.\n",
    "4.  If your model instance was not already on the target device, move it using `model.to(target_device)`.\n",
    "\n",
    "**6. Best Practices**\n",
    "\n",
    "* **Prefer `state_dict`:** For sharing models, inference, and transfer learning, saving and loading the `state_dict` is more robust and flexible.\n",
    "* **Define Model Architecture Separately:** Always have your model class definition available when loading a `state_dict`.\n",
    "* **`model.eval()`:** Always call `model.eval()` after loading a trained model and before performing inference. This ensures layers like dropout and batch normalization are in evaluation mode.\n",
    "* **`model.train()`:** If you load a checkpoint to resume training, remember to call `model.train()` to set these layers back to training mode.\n",
    "* **Use `map_location`:** Be mindful of devices. Use `map_location` in `torch.load` when loading models that might have been trained on a different device setup.\n",
    "* **Clean Up:** Delete saved files if no longer needed using `os.remove(PATH)`.\n",
    "\n",
    "```python\n",
    "# --- Clean up dummy files ---\n",
    "if os.path.exists(STATE_DICT_PATH): os.remove(STATE_DICT_PATH)\n",
    "if os.path.exists(ENTIRE_MODEL_PATH): os.remove(ENTIRE_MODEL_PATH)\n",
    "if os.path.exists(CHECKPOINT_PATH): os.remove(CHECKPOINT_PATH)\n",
    "if os.path.exists(STATE_DICT_GPU_PATH): os.remove(STATE_DICT_GPU_PATH)\n",
    "print(\"\\nDummy saved files cleaned up.\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446b9bc-6edd-4cf1-812e-b2dde38086fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
