{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c46101e-04dc-470a-b9c1-381b1b9c952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MultiIndex (Hierarchical Indexing) ---\n",
      "MultiIndex created from arrays:\n",
      " MultiIndex([('bar', 'one'),\n",
      "            ('bar', 'two'),\n",
      "            ('baz', 'one'),\n",
      "            ('baz', 'two'),\n",
      "            ('foo', 'one'),\n",
      "            ('foo', 'two'),\n",
      "            ('qux', 'one'),\n",
      "            ('qux', 'two')],\n",
      "           names=['first', 'second'])\n",
      "\n",
      "Series with MultiIndex:\n",
      " first  second\n",
      "bar    one      -0.459839\n",
      "       two       0.422791\n",
      "baz    one       0.951586\n",
      "       two       1.733919\n",
      "foo    one       1.415242\n",
      "       two       0.202581\n",
      "qux    one       0.394281\n",
      "       two       1.025072\n",
      "dtype: float64\n",
      "\n",
      "DataFrame with MultiIndex on rows:\n",
      "                      A         B         C\n",
      "first second                              \n",
      "bar   one     1.005384 -0.900951 -0.599336\n",
      "      two    -0.820504  0.080305  0.257593\n",
      "baz   one    -1.657937  0.599923 -0.934853\n",
      "      two    -0.069383  0.655565  1.173372\n",
      "foo   one    -1.230530  0.845230  0.500707\n",
      "      two     1.177004  0.052342 -0.558967\n",
      "qux   one     0.494288 -0.977645  1.456884\n",
      "      two     0.976289  0.077229 -0.937399\n",
      "\n",
      "DataFrame with MultiIndex on columns:\n",
      " Metric     Stat1               Stat2          \n",
      "Type        Mean       Std      Mean       Std\n",
      "R1      0.406668 -0.309961 -0.242316  1.962022\n",
      "R2     -0.997514 -0.406625 -0.392757  0.071603\n",
      "R3      0.525773 -1.811150  0.085709 -0.713761\n",
      "R4      1.001858  0.760388  2.167520 -0.731652\n",
      "\n",
      "--- Selecting with MultiIndex ---\n",
      "Using df_multi_row:\n",
      "                      A         B         C\n",
      "first second                              \n",
      "bar   one     1.005384 -0.900951 -0.599336\n",
      "      two    -0.820504  0.080305  0.257593\n",
      "baz   one    -1.657937  0.599923 -0.934853\n",
      "      two    -0.069383  0.655565  1.173372\n",
      "foo   one    -1.230530  0.845230  0.500707\n",
      "      two     1.177004  0.052342 -0.558967\n",
      "qux   one     0.494288 -0.977645  1.456884\n",
      "      two     0.976289  0.077229 -0.937399\n",
      "\n",
      "Select outer level 'bar':\n",
      "                A         B         C\n",
      "second                              \n",
      "one     1.005384 -0.900951 -0.599336\n",
      "two    -0.820504  0.080305  0.257593\n",
      "\n",
      "Select ('baz', 'two'):\n",
      " A   -0.069383\n",
      "B    0.655565\n",
      "C    1.173372\n",
      "Name: (baz, two), dtype: float64\n",
      "\n",
      "Select slice 'baz' to 'foo':\n",
      "                      A         B         C\n",
      "first second                              \n",
      "baz   one    -1.657937  0.599923 -0.934853\n",
      "      two    -0.069383  0.655565  1.173372\n",
      "foo   one    -1.230530  0.845230  0.500707\n",
      "      two     1.177004  0.052342 -0.558967\n",
      "\n",
      "Select all 'one' from inner level:\n",
      "                      A         B         C\n",
      "first second                              \n",
      "bar   one     1.005384 -0.900951 -0.599336\n",
      "baz   one    -1.657937  0.599923 -0.934853\n",
      "foo   one    -1.230530  0.845230  0.500707\n",
      "qux   one     0.494288 -0.977645  1.456884\n",
      "\n",
      "Using df_multi_col:\n",
      " Metric     Stat1               Stat2          \n",
      "Type        Mean       Std      Mean       Std\n",
      "R1      0.406668 -0.309961 -0.242316  1.962022\n",
      "R2     -0.997514 -0.406625 -0.392757  0.071603\n",
      "R3      0.525773 -1.811150  0.085709 -0.713761\n",
      "R4      1.001858  0.760388  2.167520 -0.731652\n",
      "\n",
      "Select outer column 'Stat1':\n",
      " Type      Mean       Std\n",
      "R1    0.406668 -0.309961\n",
      "R2   -0.997514 -0.406625\n",
      "R3    0.525773 -1.811150\n",
      "R4    1.001858  0.760388\n",
      "\n",
      "Select inner column ('Stat1', 'Std'):\n",
      " R1   -0.309961\n",
      "R2   -0.406625\n",
      "R3   -1.811150\n",
      "R4    0.760388\n",
      "Name: (Stat1, Std), dtype: float64\n",
      "\n",
      "Unstacking inner row level ('second') of df_multi_row:\n",
      "                A                   B                   C          \n",
      "second       one       two       one       two       one       two\n",
      "first                                                             \n",
      "bar     1.005384 -0.820504 -0.900951  0.080305 -0.599336  0.257593\n",
      "baz    -1.657937 -0.069383  0.599923  0.655565 -0.934853  1.173372\n",
      "foo    -1.230530  1.177004  0.845230  0.052342  0.500707 -0.558967\n",
      "qux     0.494288  0.976289 -0.977645  0.077229  1.456884 -0.937399\n",
      "\n",
      "Stacking columns of df_multi_row:\n",
      " first  second   \n",
      "bar    one     A    1.005384\n",
      "               B   -0.900951\n",
      "               C   -0.599336\n",
      "       two     A   -0.820504\n",
      "               B    0.080305\n",
      "               C    0.257593\n",
      "baz    one     A   -1.657937\n",
      "               B    0.599923\n",
      "               C   -0.934853\n",
      "       two     A   -0.069383\n",
      "               B    0.655565\n",
      "               C    1.173372\n",
      "foo    one     A   -1.230530\n",
      "               B    0.845230\n",
      "               C    0.500707\n",
      "       two     A    1.177004\n",
      "               B    0.052342\n",
      "               C   -0.558967\n",
      "qux    one     A    0.494288\n",
      "               B   -0.977645\n",
      "               C    1.456884\n",
      "       two     A    0.976289\n",
      "               B    0.077229\n",
      "               C   -0.937399\n",
      "dtype: float64\n",
      "\n",
      "Resetting MultiIndex:\n",
      "   first second         A         B         C\n",
      "0   bar    one  1.005384 -0.900951 -0.599336\n",
      "1   bar    two -0.820504  0.080305  0.257593\n",
      "2   baz    one -1.657937  0.599923 -0.934853\n",
      "3   baz    two -0.069383  0.655565  1.173372\n",
      "4   foo    one -1.230530  0.845230  0.500707\n",
      "5   foo    two  1.177004  0.052342 -0.558967\n",
      "6   qux    one  0.494288 -0.977645  1.456884\n",
      "7   qux    two  0.976289  0.077229 -0.937399\n",
      "\n",
      "Setting MultiIndex again:\n",
      "                      A         B         C\n",
      "first second                              \n",
      "bar   one     1.005384 -0.900951 -0.599336\n",
      "      two    -0.820504  0.080305  0.257593\n",
      "baz   one    -1.657937  0.599923 -0.934853\n",
      "      two    -0.069383  0.655565  1.173372\n",
      "foo   one    -1.230530  0.845230  0.500707\n",
      "      two     1.177004  0.052342 -0.558967\n",
      "qux   one     0.494288 -0.977645  1.456884\n",
      "      two     0.976289  0.077229 -0.937399\n",
      "------------------------------\n",
      "--- Performance Optimization ---\n",
      "Original memory usage:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype  \n",
      "---  ------    --------------    -----  \n",
      " 0   ID        1000000 non-null  int64  \n",
      " 1   Category  1000000 non-null  object \n",
      " 2   Value     1000000 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 62.9 MB\n",
      "\n",
      "Memory usage after dtype conversion:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count    Dtype   \n",
      "---  ------    --------------    -----   \n",
      " 0   ID        1000000 non-null  int32   \n",
      " 1   Category  1000000 non-null  category\n",
      " 2   Value     1000000 non-null  float32 \n",
      "dtypes: category(1), float32(1), int32(1)\n",
      "memory usage: 8.6 MB\n",
      "--------------------\n",
      "\n",
      "Vectorized operation time: 0.000845 seconds\n",
      ".apply() operation time: 0.053415 seconds\n",
      "Vectorization is significantly faster than .apply() or iteration.\n",
      "--------------------\n",
      "\n",
      "Boolean Indexing time: 0.004335\n",
      ".query() time: 0.009059\n",
      "\n",
      "Standard Arithmetic time: 0.004256\n",
      "pd.eval() time: 0.005595\n",
      "--------------------\n",
      "Using chunksize in pd.read_csv helps process files too large for memory.\n",
      "--------------------\n",
      "Parquet, Feather, HDF5 offer more efficient storage/retrieval than CSV.\n",
      "------------------------------\n",
      "--- Options & Settings ---\n",
      "Max rows displayed: 60\n",
      "Max columns displayed: 20\n",
      "\n",
      "Float precision display: 6\n",
      "Use pd.set_option() to control display formats, computation behavior, etc.\n",
      "------------------------------\n",
      "--- Extending Pandas (Conceptual) ---\n",
      "Advanced users can add custom functionality via accessors or extension types.\n",
      "------------------------------\n",
      "--- Integration with Other Libraries ---\n",
      "Pandas DataFrames integrate seamlessly with Scikit-learn, Statsmodels, Matplotlib, Seaborn, NumPy, etc.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time # For performance comparison examples\n",
    "\n",
    "# --- 1. MultiIndex (Hierarchical Indexing) ---\n",
    "# Allows having multiple index levels on an axis.\n",
    "# Useful for representing higher-dimensional data in a 1D (Series) or 2D (DataFrame) structure.\n",
    "\n",
    "print(\"--- MultiIndex (Hierarchical Indexing) ---\")\n",
    "\n",
    "# a) Creating a MultiIndex\n",
    "arrays = [\n",
    "    ['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "    ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']\n",
    "]\n",
    "multi_index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n",
    "print(\"MultiIndex created from arrays:\\n\", multi_index)\n",
    "\n",
    "# Create a Series with a MultiIndex\n",
    "s_multi = pd.Series(np.random.randn(8), index=multi_index)\n",
    "print(\"\\nSeries with MultiIndex:\\n\", s_multi)\n",
    "\n",
    "# Create a DataFrame with MultiIndex on rows and/or columns\n",
    "df_multi_row = pd.DataFrame(np.random.randn(8, 3), index=multi_index, columns=['A', 'B', 'C'])\n",
    "print(\"\\nDataFrame with MultiIndex on rows:\\n\", df_multi_row)\n",
    "\n",
    "arrays_cols = [\n",
    "    ['Stat1', 'Stat1', 'Stat2', 'Stat2'],\n",
    "    ['Mean', 'Std', 'Mean', 'Std']\n",
    "]\n",
    "multi_cols = pd.MultiIndex.from_arrays(arrays_cols, names=['Metric', 'Type'])\n",
    "df_multi_col = pd.DataFrame(np.random.randn(4, 4), index=['R1', 'R2', 'R3', 'R4'], columns=multi_cols)\n",
    "print(\"\\nDataFrame with MultiIndex on columns:\\n\", df_multi_col)\n",
    "\n",
    "# b) Selecting and Slicing with MultiIndex\n",
    "print(\"\\n--- Selecting with MultiIndex ---\")\n",
    "print(\"Using df_multi_row:\\n\", df_multi_row)\n",
    "\n",
    "# Select based on the outer level ('first')\n",
    "print(\"\\nSelect outer level 'bar':\\n\", df_multi_row.loc['bar'])\n",
    "\n",
    "# Select based on both levels (tuple)\n",
    "print(\"\\nSelect ('baz', 'two'):\\n\", df_multi_row.loc[('baz', 'two')]) # Returns a Series\n",
    "\n",
    "# Select slice on outer level\n",
    "print(\"\\nSelect slice 'baz' to 'foo':\\n\", df_multi_row.loc['baz':'foo'])\n",
    "\n",
    "# Select specific inner level across outer levels using slice(None)\n",
    "# Get all 'one' entries\n",
    "print(\"\\nSelect all 'one' from inner level:\\n\", df_multi_row.loc[(slice(None), 'one'), :])\n",
    "\n",
    "# Selecting with MultiIndex columns\n",
    "print(\"\\nUsing df_multi_col:\\n\", df_multi_col)\n",
    "print(\"\\nSelect outer column 'Stat1':\\n\", df_multi_col['Stat1'])\n",
    "print(\"\\nSelect inner column ('Stat1', 'Std'):\\n\", df_multi_col[('Stat1', 'Std')])\n",
    "\n",
    "# c) Stacking and Unstacking (revisited) - Key operations for MultiIndex\n",
    "# .unstack() moves an index level (default: innermost) to columns\n",
    "# .stack() moves columns to become the innermost index level\n",
    "print(\"\\nUnstacking inner row level ('second') of df_multi_row:\\n\", df_multi_row.unstack(level='second'))\n",
    "print(\"\\nStacking columns of df_multi_row:\\n\", df_multi_row.stack())\n",
    "\n",
    "# d) Setting and Resetting MultiIndex\n",
    "# Use set_index with a list of columns, reset_index works as usual\n",
    "df_flat = df_multi_row.reset_index()\n",
    "print(\"\\nResetting MultiIndex:\\n\", df_flat)\n",
    "df_reindexed = df_flat.set_index(['first', 'second'])\n",
    "print(\"\\nSetting MultiIndex again:\\n\", df_reindexed)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 2. Performance Optimization ---\n",
    "\n",
    "print(\"--- Performance Optimization ---\")\n",
    "\n",
    "# a) Use Efficient Data Types\n",
    "# - Convert object columns with few unique string values to 'category'.\n",
    "# - Use smaller integer types (int8, int16, int32) or float types (float32)\n",
    "#   if the full range/precision of int64/float64 is not needed.\n",
    "df_mem = pd.DataFrame({\n",
    "    'ID': np.arange(1000000),\n",
    "    'Category': np.random.choice(['A', 'B', 'C', 'D', 'E'], 1000000),\n",
    "    'Value': np.random.rand(1000000)\n",
    "})\n",
    "print(\"Original memory usage:\")\n",
    "df_mem.info(memory_usage='deep')\n",
    "\n",
    "df_mem['Category'] = df_mem['Category'].astype('category')\n",
    "df_mem['Value'] = df_mem['Value'].astype(np.float32)\n",
    "df_mem['ID'] = df_mem['ID'].astype(np.int32) # Assuming ID fits in int32\n",
    "\n",
    "print(\"\\nMemory usage after dtype conversion:\")\n",
    "df_mem.info(memory_usage='deep') # Significant reduction expected\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# b) Vectorization (Avoid Loops)\n",
    "# Use built-in Pandas/NumPy functions which operate on entire arrays/Series.\n",
    "# Avoid iterating row by row using loops or df.iterrows(), df.itertuples() if possible.\n",
    "# Avoid df.apply() with simple arithmetic/logical operations - direct vectorized ops are faster.\n",
    "\n",
    "# Example: Calculate Value * 2\n",
    "n = 100000\n",
    "df_perf = pd.DataFrame({'Value': np.random.randn(n)})\n",
    "\n",
    "start_time = time.time()\n",
    "result_vectorized = df_perf['Value'] * 2\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result_apply = df_perf['Value'].apply(lambda x: x * 2)\n",
    "apply_time = time.time() - start_time\n",
    "\n",
    "# Iterrows is usually the slowest\n",
    "# start_time = time.time()\n",
    "# result_iterrows = []\n",
    "# for index, row in df_perf.iterrows():\n",
    "#     result_iterrows.append(row['Value'] * 2)\n",
    "# result_iterrows = pd.Series(result_iterrows)\n",
    "# iterrows_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nVectorized operation time: {vectorized_time:.6f} seconds\")\n",
    "print(f\".apply() operation time: {apply_time:.6f} seconds\")\n",
    "# print(f\".iterrows() operation time: {iterrows_time:.6f} seconds\") # Expected to be much slower\n",
    "print(\"Vectorization is significantly faster than .apply() or iteration.\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# c) Using .eval() and .query() (for large DataFrames)\n",
    "# Can sometimes speed up complex arithmetic or boolean expressions by using numexpr library.\n",
    "df_eval = pd.DataFrame(np.random.randn(100000, 4), columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Standard boolean indexing\n",
    "start_time = time.time()\n",
    "result_bool = df_eval[(df_eval['A'] > 0) & (df_eval['B'] < 0)]\n",
    "bool_time = time.time() - start_time\n",
    "\n",
    "# Using .query()\n",
    "start_time = time.time()\n",
    "result_query = df_eval.query('A > 0 and B < 0') # Uses string expression\n",
    "query_time = time.time() - start_time\n",
    "\n",
    "# Standard arithmetic\n",
    "start_time = time.time()\n",
    "result_arith = (df_eval['A'] + df_eval['B']) / (df_eval['C'] - df_eval['D'])\n",
    "arith_time = time.time() - start_time\n",
    "\n",
    "# Using .eval()\n",
    "start_time = time.time()\n",
    "result_eval = pd.eval(\"(df_eval.A + df_eval.B) / (df_eval.C - df_eval.D)\") # Uses string expression\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nBoolean Indexing time: {bool_time:.6f}\")\n",
    "print(f\".query() time: {query_time:.6f}\") # Often faster on large DFs\n",
    "print(f\"\\nStandard Arithmetic time: {arith_time:.6f}\")\n",
    "print(f\"pd.eval() time: {eval_time:.6f}\") # Often faster on large DFs\n",
    "# Note: Performance gains depend on expression complexity and DataFrame size. Requires 'numexpr' library.\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# d) Reading Large Files in Chunks\n",
    "# Use `chunksize` parameter in `pd.read_csv` (or other readers) to process large files piece by piece.\n",
    "# filename = 'very_large_file.csv'\n",
    "# chunk_list = []\n",
    "# chunk_iter = pd.read_csv(filename, chunksize=10000) # Process 10000 rows at a time\n",
    "# for chunk in chunk_iter:\n",
    "#     # Process each chunk (e.g., filter, aggregate)\n",
    "#     processed_chunk = chunk[chunk['Value'] > 0].groupby('Category').size()\n",
    "#     chunk_list.append(processed_chunk)\n",
    "# final_result = pd.concat(chunk_list).sum(level=0) # Combine results\n",
    "print(\"Using chunksize in pd.read_csv helps process files too large for memory.\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# e) Choosing Efficient File Formats\n",
    "# For intermediate storage or faster I/O, consider binary formats:\n",
    "# - Parquet (.parquet): Efficient columnar storage, good compression. Requires 'pyarrow' or 'fastparquet'.\n",
    "# - Feather (.feather): Fast, lightweight binary format for DataFrame exchange (especially between Python and R). Requires 'pyarrow'.\n",
    "# - HDF5 (.h5): Hierarchical format, good for storing multiple datasets and metadata. Requires 'tables'.\n",
    "# df_mem.to_parquet('efficient_data.parquet')\n",
    "# df_read_parquet = pd.read_parquet('efficient_data.parquet')\n",
    "print(\"Parquet, Feather, HDF5 offer more efficient storage/retrieval than CSV.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. Options & Settings ---\n",
    "# Customize Pandas behavior using pd.set_option() or pd.options.\n",
    "\n",
    "print(\"--- Options & Settings ---\")\n",
    "# Display options (e.g., max rows/columns shown)\n",
    "print(f\"Max rows displayed: {pd.options.display.max_rows}\")\n",
    "print(f\"Max columns displayed: {pd.options.display.max_columns}\")\n",
    "\n",
    "# Set max rows to 10 for display\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "# print(\"\\nDataFrame display after setting max_rows=10:\\n\", df_mem.head(20)) # Only 10 rows would show (...)\n",
    "\n",
    "# Reset to default\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "# Control float precision display\n",
    "print(f\"\\nFloat precision display: {pd.options.display.precision}\")\n",
    "# pd.set_option('display.precision', 3)\n",
    "# print(\"\\nDataFrame display after setting precision=3:\\n\", pd.DataFrame(np.random.randn(3,3)))\n",
    "# pd.reset_option('display.precision')\n",
    "\n",
    "# Other options exist for plotting, computation, etc.\n",
    "# pd.describe_option() # See all options\n",
    "# pd.describe_option('display') # See display options\n",
    "print(\"Use pd.set_option() to control display formats, computation behavior, etc.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Extending Pandas (Brief Overview) ---\n",
    "# Advanced users can extend Pandas functionality:\n",
    "# - Custom Accessors: Add custom namespaces to Series/DataFrame objects (like .str, .cat, .dt). Requires defining a class decorated with @pd.api.extensions.register_dataframe_accessor (or series/index).\n",
    "# - Custom Extension Types/Arrays: Define custom data types beyond NumPy's defaults (more complex).\n",
    "print(\"--- Extending Pandas (Conceptual) ---\")\n",
    "print(\"Advanced users can add custom functionality via accessors or extension types.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Integration with Other Libraries ---\n",
    "# Pandas DataFrames are the standard input/output for many data science libraries:\n",
    "# - Scikit-learn: Pass DataFrames directly for model training (select features/target).\n",
    "# - Statsmodels: Statistical modeling library that works well with DataFrames.\n",
    "# - Matplotlib/Seaborn: Visualization libraries that accept DataFrames/Series.\n",
    "# - NumPy: Pandas is built on NumPy; easily convert using .values or passing DF/Series to NumPy functions.\n",
    "print(\"--- Integration with Other Libraries ---\")\n",
    "print(\"Pandas DataFrames integrate seamlessly with Scikit-learn, Statsmodels, Matplotlib, Seaborn, NumPy, etc.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20071294-2711-43e6-9c25-e9a64aa4362a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
