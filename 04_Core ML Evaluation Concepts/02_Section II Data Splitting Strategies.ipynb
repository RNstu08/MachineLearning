{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4259e0f-5f07-4d11-a866-1a3018c40009",
   "metadata": {},
   "source": [
    "This is the fundamental practice for estimating how well your model will perform on unseen data. We reserve portions of our data exclusively for testing or validation, ensuring our evaluation isn't biased by the data the model was trained on.\n",
    "\n",
    "## Data Splitting Strategies for Model Evaluation\n",
    "\n",
    "This document covers:\n",
    "\n",
    "* **Why Split:** The fundamental need to evaluate models on unseen data to estimate generalization performance.\n",
    "* **Train/Test Split:** Demonstrates the basic two-way split using `train_test_split` and explains key parameters like `test_size`, `random_state`, `shuffle`, and `stratify`.\n",
    "* **Train/Validation/Test Split:** Explains the rationale for a three-way split (separating data for tuning/model selection from the final test data) and shows how to implement it using two calls to `train_test_split`.\n",
    "* **Stratification:** Highlights the importance of using the `stratify` parameter in classification tasks to maintain representative class distributions in all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80fefb57-6ff0-4911-be4a-18f6e749a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Strategy 1: Train/Test Split ---\n",
      "Original data shape: X=(150, 4), y=(150,)\n",
      "\n",
      "Training set shape: X=(105, 4), y=(105,)\n",
      "Test set shape: X=(45, 4), y=(45,)\n",
      "\n",
      "Original class distribution (%):\n",
      " 0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Training set class distribution (%):\n",
      " 0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution (%):\n",
      " 0    33.333333\n",
      "1    33.333333\n",
      "2    33.333333\n",
      "Name: proportion, dtype: float64\n",
      "Note: Proportions should be very similar due to stratify=y.\n",
      "------------------------------\n",
      "--- Strategy 2: Train/Validation/Test Split ---\n",
      "\n",
      "Original data size: 150\n",
      "Final Training set size: 90 (60.0%)\n",
      "Validation set size: 30 (20.0%)\n",
      "Final Test set size: 30 (20.0%)\n",
      "\n",
      "This creates three distinct sets for robust model development and evaluation.\n",
      "------------------------------\n",
      "--- Stratification Importance ---\n",
      "Stratification (using stratify=y) maintains class proportions across splits.\n",
      "This is crucial for reliable evaluation in classification tasks,\n",
      "especially when dealing with imbalanced datasets.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris # Example dataset for classification\n",
    "\n",
    "# --- 1. The Need for Splitting ---\n",
    "# Evaluating a model on the same data it was trained on gives an overly\n",
    "# optimistic performance estimate (training accuracy/error).\n",
    "# We need to test the model on data it has *never* seen during training\n",
    "# to estimate its ability to generalize to new, real-world data.\n",
    "\n",
    "# --- 2. Strategy 1: Train/Test Split ---\n",
    "# The most basic split. Divide the data into two sets:\n",
    "# - Training Set: Used to train the model (fit the estimator).\n",
    "# - Test Set: Used ONLY at the very end to evaluate the final, trained model's performance.\n",
    "\n",
    "print(\"--- Strategy 1: Train/Test Split ---\")\n",
    "\n",
    "# Load Iris dataset (classification)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "print(f\"Original data shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Perform the train/test split using train_test_split\n",
    "# Common split ratios: 80/20, 70/30, 75/25\n",
    "# Key parameters:\n",
    "# - test_size: Proportion (float between 0.0 and 1.0) or absolute number for the test set.\n",
    "# - train_size: Alternative to test_size.\n",
    "# - random_state: Seed for the random number generator used for shuffling. Ensures reproducibility.\n",
    "#                 Use the same integer value to get the same split every time.\n",
    "# - shuffle: Whether to shuffle the data before splitting (default=True). Recommended.\n",
    "# - stratify: Ensures class proportions are maintained in both splits. Crucial for classification.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,       # 30% of data for the test set\n",
    "    random_state=42,     # For reproducible results\n",
    "    shuffle=True,        # Shuffle the data before splitting\n",
    "    stratify=y           # Maintain class proportions based on 'y'\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "\n",
    "# Verify stratification (optional check)\n",
    "print(\"\\nOriginal class distribution (%):\\n\", pd.Series(y).value_counts(normalize=True).sort_index() * 100)\n",
    "print(\"\\nTraining set class distribution (%):\\n\", pd.Series(y_train).value_counts(normalize=True).sort_index() * 100)\n",
    "print(\"\\nTest set class distribution (%):\\n\", pd.Series(y_test).value_counts(normalize=True).sort_index() * 100)\n",
    "print(\"Note: Proportions should be very similar due to stratify=y.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. Strategy 2: Train/Validation/Test Split ---\n",
    "# Often needed during model development to tune hyperparameters or compare models\n",
    "# without \"contaminating\" the final test set.\n",
    "# Workflow:\n",
    "# 1. Split data into Train+Validation and Test sets.\n",
    "# 2. Split Train+Validation into Train and Validation sets.\n",
    "# 3. Train models on the Train set.\n",
    "# 4. Evaluate/tune models using the Validation set.\n",
    "# 5. Select the best model/hyperparameters based on validation performance.\n",
    "# 6. Train the final chosen model on the *entire* Train+Validation set.\n",
    "# 7. Perform a final, single evaluation on the held-out Test set.\n",
    "\n",
    "print(\"--- Strategy 2: Train/Validation/Test Split ---\")\n",
    "\n",
    "# Use the same original data (X, y)\n",
    "# Step 1: Split into initial training (e.g., 80%) and final test (e.g., 20%)\n",
    "X_train_val, X_final_test, y_train_val, y_final_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,      # 20% for the final test set\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Split the initial training set into actual training and validation sets\n",
    "# Example: Use 25% of the train_val set for validation (0.25 * 80% = 20% of total)\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, # Split the 80% portion\n",
    "    test_size=0.25,      # 25% of the train_val set -> 20% of original data\n",
    "    random_state=42,\n",
    "    stratify=y_train_val # Stratify based on the y of this subset\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal data size: {len(X)}\")\n",
    "print(f\"Final Training set size: {len(X_train_final)} ({len(X_train_final)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set size: {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Final Test set size: {len(X_final_test)} ({len(X_final_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Now you would:\n",
    "# - Train models on X_train_final, y_train_final\n",
    "# - Tune/compare using X_val, y_val\n",
    "# - Retrain best model on X_train_val, y_train_val\n",
    "# - Get final performance estimate using X_final_test, y_final_test\n",
    "print(\"\\nThis creates three distinct sets for robust model development and evaluation.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Stratification Importance ---\n",
    "# Stratification ensures that the class distribution in the original dataset\n",
    "# is preserved in the split datasets. This is vital for:\n",
    "# - Classification tasks in general.\n",
    "# - Especially important for imbalanced datasets where one class is much rarer.\n",
    "#   Without stratification, a split might accidentally put very few (or even zero)\n",
    "#   samples of the minority class into the test or validation set, making\n",
    "#   evaluation unreliable or impossible.\n",
    "# - How it works: `stratify=y` uses the labels in `y` to guide the split.\n",
    "\n",
    "print(\"--- Stratification Importance ---\")\n",
    "print(\"Stratification (using stratify=y) maintains class proportions across splits.\")\n",
    "print(\"This is crucial for reliable evaluation in classification tasks,\")\n",
    "print(\"especially when dealing with imbalanced datasets.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ae989-1bab-467a-8a11-56db292518d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
