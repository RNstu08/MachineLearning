{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c2178e-e974-412a-99da-08ccfee9af0b",
   "metadata": {},
   "source": [
    "###### Machine learning algorithms require numerical input. This section focuses on techniques to convert categorical features (text labels like 'Red', 'Blue', 'High', 'Low') into a numerical format that algorithms can understand. The choice of encoding method depends on the type of categorical data.\n",
    "---\n",
    "\n",
    "## Encoding Categorical Data in Python\n",
    "\n",
    "This document covers:\n",
    "\n",
    "* **Types:** Differentiates between Nominal and Ordinal categorical data.\n",
    "* **Ordinal Encoding:** Demonstrates `OrdinalEncoder` for features with inherent order, emphasizing the need to specify the category sequence.\n",
    "* **One-Hot Encoding (OHE):** Shows how to use `OneHotEncoder` (recommended for pipelines) and `pd.get_dummies` (for convenience) for nominal features, explaining parameters like `drop` and `handle_unknown`. Discusses the dimensionality increase.\n",
    "* **Label Encoding:** Explains `LabelEncoder` and why it's typically used only for the target variable `y`.\n",
    "* **Considerations:** Summarizes key points about choosing the right encoder and applying it correctly within an ML workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc971c6-a115-426c-935e-26291b7f43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame with Categorical Features ---\n",
      "   ID  Color Size Quality  Target\n",
      "0   1    Red    M    Good  ClassA\n",
      "1   2  Green    L   Great  ClassB\n",
      "2   3   Blue    S    Fair  ClassA\n",
      "3   4  Green    M    Good  ClassA\n",
      "4   5    Red    L   Great  ClassB\n",
      "5   6   Blue    M    Good  ClassA\n",
      "6   7  Green    S    Fair  ClassB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   ID       7 non-null      int64 \n",
      " 1   Color    7 non-null      object\n",
      " 2   Size     7 non-null      object\n",
      " 3   Quality  7 non-null      object\n",
      " 4   Target   7 non-null      object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 412.0+ bytes\n",
      "------------------------------\n",
      "--- Ordinal Encoding (for Ordinal Features) ---\n",
      "DataFrame after Ordinal Encoding ('Size', 'Quality'):\n",
      "    ID  Color  Size  Quality  Target\n",
      "0   1    Red   1.0      1.0  ClassA\n",
      "1   2  Green   2.0      2.0  ClassB\n",
      "2   3   Blue   0.0      0.0  ClassA\n",
      "3   4  Green   1.0      1.0  ClassA\n",
      "4   5    Red   2.0      2.0  ClassB\n",
      "5   6   Blue   1.0      1.0  ClassA\n",
      "6   7  Green   0.0      0.0  ClassB\n",
      "\n",
      "Learned categories for OrdinalEncoder:\n",
      " [array(['S', 'M', 'L'], dtype=object), array(['Fair', 'Good', 'Great'], dtype=object)]\n",
      "------------------------------\n",
      "--- One-Hot Encoding (for Nominal Features) ---\n",
      "\n",
      "Generated One-Hot Feature Names: ['Color_Green' 'Color_Red']\n",
      "\n",
      "DataFrame after One-Hot Encoding ('Color') using OneHotEncoder:\n",
      "    ID Size Quality  Target  Color_Green  Color_Red\n",
      "0   1    M    Good  ClassA          0.0        1.0\n",
      "1   2    L   Great  ClassB          1.0        0.0\n",
      "2   3    S    Fair  ClassA          0.0        0.0\n",
      "3   4    M    Good  ClassA          1.0        0.0\n",
      "4   5    L   Great  ClassB          0.0        1.0\n",
      "5   6    M    Good  ClassA          0.0        0.0\n",
      "6   7    S    Fair  ClassB          1.0        0.0\n",
      "--------------------\n",
      "\n",
      "DataFrame after One-Hot Encoding using pd.get_dummies():\n",
      "    ID Quality  Target  Color_Green  Color_Red  Size_M  Size_S\n",
      "0   1    Good  ClassA        False       True    True   False\n",
      "1   2   Great  ClassB         True      False   False   False\n",
      "2   3    Fair  ClassA        False      False   False    True\n",
      "3   4    Good  ClassA         True      False    True   False\n",
      "4   5   Great  ClassB        False       True   False   False\n",
      "5   6    Good  ClassA        False      False    True   False\n",
      "6   7    Fair  ClassB         True      False   False    True\n",
      "------------------------------\n",
      "--- Label Encoding (for Target Variable) ---\n",
      "DataFrame after Label Encoding the 'Target' column:\n",
      "    Target  Target_Encoded\n",
      "0  ClassA               0\n",
      "1  ClassB               1\n",
      "2  ClassA               0\n",
      "3  ClassA               0\n",
      "4  ClassB               1\n",
      "5  ClassA               0\n",
      "6  ClassB               1\n",
      "\n",
      "Mapping learned by LabelEncoder (Target):\n",
      "  'ClassA' -> 0\n",
      "  'ClassB' -> 1\n",
      "------------------------------\n",
      "--- Considerations ---\n",
      "- Choose encoding based on data type (Nominal vs. Ordinal).\n",
      "- One-Hot Encoding is standard for nominal data but increases dimensionality.\n",
      "- Ordinal Encoding implies order; use only for truly ordinal features.\n",
      "- Label Encoding is generally reserved for the target variable 'y'.\n",
      "- For high cardinality features (many unique categories), consider other techniques\n",
      "  like Binary Encoding, Feature Hashing, or Target Encoding (use with care).\n",
      "- Apply encoding *after* train-test split, fitting ONLY on training data.\n",
      "- Integrate encoders into Pipelines (Section VIII) for robust workflows.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# --- 1. Understanding Categorical Data Types ---\n",
    "# - Nominal Data: Categories with NO intrinsic order or ranking (e.g., Country, Color, Gender).\n",
    "# - Ordinal Data: Categories with a meaningful order or ranking (e.g., Size [Small, Medium, Large],\n",
    "#                 Education Level [High School, Bachelor, Master], Quality [Fair, Good, Great]).\n",
    "\n",
    "# --- 2. Create Sample Data ---\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'Color': ['Red', 'Green', 'Blue', 'Green', 'Red', 'Blue', 'Green'], # Nominal\n",
    "    'Size': ['M', 'L', 'S', 'M', 'L', 'M', 'S'], # Ordinal\n",
    "    'Quality': ['Good', 'Great', 'Fair', 'Good', 'Great', 'Good', 'Fair'], # Ordinal\n",
    "    'Target': ['ClassA', 'ClassB', 'ClassA', 'ClassA', 'ClassB', 'ClassA', 'ClassB'] # Target variable\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- Original DataFrame with Categorical Features ---\")\n",
    "print(df)\n",
    "df.info()\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. Technique 1: Ordinal Encoding ---\n",
    "# Assigns a unique integer to each category based on a specified order.\n",
    "# Use Case: Suitable ONLY for ORDINAL features where the numerical order is meaningful.\n",
    "#           Using it on nominal data can mislead models by implying a false order.\n",
    "\n",
    "print(\"--- Ordinal Encoding (for Ordinal Features) ---\")\n",
    "df_ordinal = df.copy() # Work on a copy\n",
    "\n",
    "# Define the explicit order for each ordinal feature\n",
    "size_categories = ['S', 'M', 'L']\n",
    "quality_categories = ['Fair', 'Good', 'Great']\n",
    "\n",
    "# Initialize OrdinalEncoder with the specified categories\n",
    "# The order of lists in 'categories' must match the order of columns passed to fit_transform\n",
    "ordinal_encoder = OrdinalEncoder(categories=[size_categories, quality_categories])\n",
    "\n",
    "# Apply to the ordinal columns\n",
    "ordinal_cols = ['Size', 'Quality']\n",
    "df_ordinal[ordinal_cols] = ordinal_encoder.fit_transform(df_ordinal[ordinal_cols])\n",
    "\n",
    "print(\"DataFrame after Ordinal Encoding ('Size', 'Quality'):\\n\", df_ordinal)\n",
    "print(\"\\nLearned categories for OrdinalEncoder:\\n\", ordinal_encoder.categories_)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Technique 2: One-Hot Encoding (OHE) ---\n",
    "# Creates new binary (0/1) columns for each unique category in the original feature.\n",
    "# Use Case: Standard approach for NOMINAL features. Avoids implying order.\n",
    "\n",
    "print(\"--- One-Hot Encoding (for Nominal Features) ---\")\n",
    "df_ohe = df.copy() # Work on a copy\n",
    "\n",
    "# a) Using sklearn.preprocessing.OneHotEncoder (Recommended for pipelines)\n",
    "# Initialize OneHotEncoder\n",
    "# sparse_output=False: Returns a dense NumPy array (easier to view). Default is True (sparse matrix).\n",
    "# drop='first': Drops the first category in each feature to avoid multicollinearity (dummy variable trap).\n",
    "#              Can also use drop='if_binary' to drop only for binary features. Default is None.\n",
    "# handle_unknown='ignore': Assigns all zeros if an unknown category is encountered during transform (e.g., in test data).\n",
    "#                          'error' (default) would raise an error.\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "\n",
    "# Apply to the nominal column 'Color'\n",
    "nominal_cols = ['Color']\n",
    "# Fit the encoder on the training data (here, df_ohe) and transform\n",
    "encoded_data = ohe.fit_transform(df_ohe[nominal_cols])\n",
    "\n",
    "# Get the names of the new features created\n",
    "# (e.g., 'Color_Green', 'Color_Red' - 'Color_Blue' was dropped due to drop='first')\n",
    "feature_names_ohe = ohe.get_feature_names_out(nominal_cols)\n",
    "print(f\"\\nGenerated One-Hot Feature Names: {feature_names_ohe}\")\n",
    "\n",
    "# Create a DataFrame with the new encoded columns\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=feature_names_ohe, index=df_ohe.index)\n",
    "\n",
    "# Concatenate with the original DataFrame and drop the original nominal column\n",
    "df_ohe = pd.concat([df_ohe.drop(nominal_cols, axis=1), encoded_df], axis=1)\n",
    "print(\"\\nDataFrame after One-Hot Encoding ('Color') using OneHotEncoder:\\n\", df_ohe)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# b) Using pandas.get_dummies() (Convenient for quick analysis)\n",
    "# Simpler syntax, but less suitable for use within Scikit-learn pipelines.\n",
    "df_dummies = df.copy()\n",
    "dummies_df = pd.get_dummies(df_dummies, columns=['Color', 'Size'], drop_first=True, prefix=['Color', 'Size'])\n",
    "# drop_first=True avoids multicollinearity\n",
    "# prefix adds context to new column names\n",
    "print(\"\\nDataFrame after One-Hot Encoding using pd.get_dummies():\\n\", dummies_df)\n",
    "# Note: get_dummies also encoded 'Size' here, which might not be desired if it's truly ordinal.\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Technique 3: Label Encoding (for Target Variable y) ---\n",
    "# Assigns a unique integer (0 to n_classes-1) to each class label in the target variable.\n",
    "# Use Case: Specifically for encoding the TARGET variable (y), not features (X).\n",
    "#           Most Scikit-learn classifiers handle string labels directly for y,\n",
    "#           but explicit encoding is sometimes needed or preferred.\n",
    "\n",
    "print(\"--- Label Encoding (for Target Variable) ---\")\n",
    "df_label = df.copy()\n",
    "target_col = 'Target'\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit on the target column and transform it\n",
    "df_label[target_col + '_Encoded'] = le.fit_transform(df_label[target_col])\n",
    "\n",
    "print(\"DataFrame after Label Encoding the 'Target' column:\\n\", df_label[['Target', 'Target_Encoded']])\n",
    "print(f\"\\nMapping learned by LabelEncoder ({target_col}):\")\n",
    "# Show the mapping from class name to encoded integer\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    print(f\"  '{class_name}' -> {i}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 6. Considerations ---\n",
    "print(\"--- Considerations ---\")\n",
    "print(\"- Choose encoding based on data type (Nominal vs. Ordinal).\")\n",
    "print(\"- One-Hot Encoding is standard for nominal data but increases dimensionality.\")\n",
    "print(\"- Ordinal Encoding implies order; use only for truly ordinal features.\")\n",
    "print(\"- Label Encoding is generally reserved for the target variable 'y'.\")\n",
    "print(\"- For high cardinality features (many unique categories), consider other techniques\")\n",
    "print(\"  like Binary Encoding, Feature Hashing, or Target Encoding (use with care).\")\n",
    "print(\"- Apply encoding *after* train-test split, fitting ONLY on training data.\")\n",
    "print(\"- Integrate encoders into Pipelines (Section VIII) for robust workflows.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d70a2-a3ac-49a3-a10d-5db5a6bb4d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
