{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671d7c3b-ca47-4147-bc21-4294fc45de80",
   "metadata": {},
   "source": [
    "- let's build a more complex Convolutional Neural Network (CNN) example using PyTorch, still on the CIFAR-10 dataset. This will allow us to see how adding more layers and techniques like Batch Normalization, Dropout, and Data Augmentation can improve performance and robustness.\n",
    "\n",
    "- Complexity Additions in this Example:\n",
    "\n",
    "- Deeper Architecture: We'll use more convolutional layers.\n",
    "- Batch Normalization (nn.BatchNorm2d): Added after convolutional layers (before activation) to stabilize and accelerate training.\n",
    "- Dropout (nn.Dropout): Added in the fully connected part to reduce overfitting.\n",
    "- Data Augmentation: Simple augmentations will be applied to the training dataset to make the model more robust.\n",
    "- Validation Loop: We'll split the training data to create a validation set and monitor performance on it during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed50901-adc1-4071-9b72-7c0b919f77af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- 1. Device Configuration ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 2. Hyperparameters ---\n",
    "num_epochs = 25 # Increased epochs for a more complex model and data augmentation\n",
    "batch_size = 128 # Can adjust based on GPU memory\n",
    "learning_rate = 0.001\n",
    "num_classes = 10 # CIFAR-10 has 10 classes\n",
    "dropout_prob = 0.5\n",
    "\n",
    "# --- 3. Load and Prepare CIFAR-10 Dataset with Data Augmentation ---\n",
    "print(\"Loading CIFAR-10 dataset with augmentation...\")\n",
    "\n",
    "# Transformations for the training set (with augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(), # Randomly flip images horizontally\n",
    "    transforms.RandomCrop(32, padding=4), # Randomly crop images with padding\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Transformations for the validation and test set (only normalization)\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Download and load the full training data (will be split)\n",
    "full_train_dataset_aug = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                                      train=True,\n",
    "                                                      transform=transform_train, # Apply training transforms\n",
    "                                                      download=True)\n",
    "\n",
    "# Create a separate dataset instance for validation with validation transforms\n",
    "val_dataset_for_transform = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                                          train=True, # Still from the original training split\n",
    "                                                          transform=transform_val_test, # Apply validation/test transforms\n",
    "                                                          download=True)\n",
    "\n",
    "\n",
    "# Download and load the test data\n",
    "test_dataset_aug = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                                train=False,\n",
    "                                                transform=transform_val_test) # Apply validation/test transforms\n",
    "\n",
    "# Split full training data into training and validation sets\n",
    "# We need to be careful here: apply different transforms to train and val splits.\n",
    "# One way is to get indices from random_split and then create Subset datasets with different transforms.\n",
    "# Or, simpler for this example: split, then wrap with DataLoaders that apply transforms if needed,\n",
    "# but torchvision Datasets apply transform at __getitem__.\n",
    "# So, we'll split the full_train_dataset_aug and then for validation, we'd ideally re-wrap the val_subset\n",
    "# with a dataset object that uses transform_val_test.\n",
    "# A common approach:\n",
    "train_size = int(0.85 * len(full_train_dataset_aug)) # 85% for training\n",
    "val_size = len(full_train_dataset_aug) - train_size   # 15% for validation\n",
    "\n",
    "# Get indices for split\n",
    "torch.manual_seed(42) # for reproducibility of split\n",
    "train_indices, val_indices = random_split(range(len(full_train_dataset_aug)), [train_size, val_size])\n",
    "\n",
    "# Create training dataset with augmentation\n",
    "train_dataset_aug = torch.utils.data.Subset(full_train_dataset_aug, train_indices)\n",
    "\n",
    "# Create validation dataset. For validation, we want the non-augmented version of these images.\n",
    "# We use the 'val_dataset_for_transform' which has the correct non-augmenting transform.\n",
    "val_dataset_aug = torch.utils.data.Subset(val_dataset_for_transform, val_indices)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader_aug = DataLoader(dataset=train_dataset_aug, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader_aug = DataLoader(dataset=val_dataset_aug, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader_aug = DataLoader(dataset=test_dataset_aug, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Dataset loaded. Train samples: {len(train_dataset_aug)}, Validation samples: {len(val_dataset_aug)}, Test samples: {len(test_dataset_aug)}\")\n",
    "cifar10_classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# --- 4. Define a More Complex Convolutional Neural Network (CNN) Model ---\n",
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, dropout_prob=0.5):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32) # Batch Norm after Conv, before ReLU\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32 -> 16x16\n",
    "        self.dropout_conv1 = nn.Dropout2d(p=0.25) # Dropout for conv layers (spatial dropout)\n",
    "\n",
    "        # Block 2\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 16x16 -> 8x8\n",
    "        self.dropout_conv2 = nn.Dropout2d(p=0.25)\n",
    "\n",
    "        # Block 3 (Optional, can add more)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 8x8 -> 4x4\n",
    "        self.dropout_conv3 = nn.Dropout2d(p=0.25)\n",
    "\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        # Input features: 128 channels * 4 width * 4 height = 128 * 4 * 4 = 2048\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout_fc = nn.Dropout(dropout_prob) # Dropout before output layer\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout_conv1(x)\n",
    "\n",
    "        # Block 2\n",
    "        x = self.relu3(self.bn3(self.conv3(x)))\n",
    "        x = self.relu4(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout_conv2(x)\n",
    "        \n",
    "        # Block 3\n",
    "        x = self.relu5(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout_conv3(x)\n",
    "\n",
    "        # Fully Connected Part\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_fc1(x)\n",
    "        x = self.dropout_fc(x)\n",
    "        x = self.fc2(x) # Logits\n",
    "        return x\n",
    "\n",
    "# --- 5. Instantiate the Model, Loss, and Optimizer ---\n",
    "model = ComplexCNN(num_classes=num_classes, dropout_prob=dropout_prob).to(device)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Learning rate scheduler (optional, but often helpful for deeper models)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Reduce LR every 7 epochs\n",
    "\n",
    "# --- 6. Training Loop with Validation ---\n",
    "print(\"\\nStarting Training...\")\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss, n_correct_train, n_samples_train = 0.0, 0, 0\n",
    "    for i, (images, labels) in enumerate(train_loader_aug):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples_train += labels.size(0)\n",
    "        n_correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / n_samples_train\n",
    "    epoch_train_acc = 100.0 * n_correct_train / n_samples_train\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(epoch_train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss, n_correct_val, n_samples_val = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images_val, labels_val in val_loader_aug:\n",
    "            images_val, labels_val = images_val.to(device), labels_val.to(device)\n",
    "            outputs_val = model(images_val)\n",
    "            loss_val = criterion(outputs_val, labels_val)\n",
    "            running_val_loss += loss_val.item() * images_val.size(0)\n",
    "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
    "            n_samples_val += labels_val.size(0)\n",
    "            n_correct_val += (predicted_val == labels_val).sum().item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / n_samples_val\n",
    "    epoch_val_acc = 100.0 * n_correct_val / n_samples_val\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(epoch_val__acc)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, '\n",
    "          f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
    "    # if scheduler: scheduler.step() # Step the LR scheduler\n",
    "\n",
    "print(\"Finished Training.\")\n",
    "\n",
    "# --- 7. Evaluation on Test Set ---\n",
    "print(\"\\nStarting Evaluation on Test Set...\")\n",
    "model.eval()\n",
    "all_labels_test_aug, all_predicted_test_aug = [], []\n",
    "with torch.no_grad():\n",
    "    n_correct_test, n_samples_test = 0, 0\n",
    "    for images_test, labels_test in test_loader_aug:\n",
    "        images_test, labels_test = images_test.to(device), labels_test.to(device)\n",
    "        outputs_test = model(images_test)\n",
    "        _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "        n_samples_test += labels_test.size(0)\n",
    "        n_correct_test += (predicted_test == labels_test).sum().item()\n",
    "        all_labels_test_aug.extend(labels_test.cpu().numpy())\n",
    "        all_predicted_test_aug.extend(predicted_test.cpu().numpy())\n",
    "\n",
    "accuracy_test_aug = 100.0 * n_correct_test / n_samples_test\n",
    "print(f'Accuracy of the complex CNN on test images: {accuracy_test_aug:.2f} %')\n",
    "\n",
    "# --- 8. Confusion Matrix and Classification Report for Test Set ---\n",
    "print(\"\\nConfusion Matrix (Complex CNN Test Set):\")\n",
    "cm_cnn_test_aug = confusion_matrix(all_labels_test_aug, all_predicted_test_aug)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_cnn_test_aug, annot=True, fmt=\"d\", cmap=\"YlGnBu\",\n",
    "            xticklabels=cifar10_classes, yticklabels=cifar10_classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Complex CNN (CIFAR-10 Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report (Complex CNN Test Set):\")\n",
    "print(classification_report(all_labels_test_aug, all_predicted_test_aug, target_names=cifar10_classes))\n",
    "\n",
    "# --- 9. Plot Training and Validation Loss and Accuracy ---\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_losses, 'bo-', label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, 'ro-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss (Complex CNN)')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Loss (CrossEntropy)'); plt.legend(); plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_accuracies, 'bs-', label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracies, 'rs-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy (Complex CNN)')\n",
    "plt.xlabel('Epochs'); plt.ylabel('Accuracy (%)'); plt.legend(); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd3a78-8d81-47bc-a670-ec1c46e7e014",
   "metadata": {},
   "source": [
    "# PyTorch \"More Complex\" CNN: Key Enhancements for CIFAR-10 Classification\n",
    "\n",
    "This document details significant enhancements applied to a Convolutional Neural Network (CNN) for improved performance and robustness on the CIFAR-10 image classification task. These changes incorporate common techniques used in modern deep learning.\n",
    "\n",
    "## 1. Data Augmentation (`transform_train`)\n",
    "- **Purpose**: To artificially increase the diversity of the training dataset, which helps the model learn more invariant features and generalize better to unseen data, thereby reducing overfitting.\n",
    "- **Techniques Applied (Only to the Training Set)**:\n",
    "    - **`transforms.RandomHorizontalFlip()`**: Randomly flips images horizontally with a certain probability (typically 0.5) during each training epoch. This is effective for datasets where horizontal orientation doesn't change the class label (e.g., a cat is still a cat if flipped horizontally).\n",
    "    - **`transforms.RandomCrop(32, padding=4)`**:\n",
    "        - First, the 32x32 input image is padded with 4 pixels on each side (making it 40x40).\n",
    "        - Then, a random 32x32 crop is taken from this padded image.\n",
    "        - This introduces variations in the object's position and scale within the image, forcing the model to be less sensitive to exact object placement.\n",
    "- **Validation/Test Set Transforms**: The validation and test sets **do not** use these random augmentations. They only use `transforms.ToTensor()` and `transforms.Normalize()` to ensure consistent evaluation.\n",
    "\n",
    "## 2. Deeper and More Sophisticated Architecture (`ComplexCNN` class)\n",
    "- **Increased Depth**: The network architecture features three convolutional blocks, allowing it to learn a hierarchy of features from simple to more complex.\n",
    "- **Typical Block Structure**: Each convolutional block generally follows a pattern:\n",
    "    - One or two `nn.Conv2d` layers.\n",
    "    - `nn.BatchNorm2d` layer after each convolution.\n",
    "    - `nn.ReLU` activation function.\n",
    "    - `nn.MaxPool2d` layer at the end of the block (or sometimes `nn.Dropout2d` before or after pooling).\n",
    "- **Increasing Filter Depth**: A common design pattern is to increase the number of filters (output channels) in deeper convolutional layers (e.g., starting with 32 filters, then 64, then 128).\n",
    "    - **Rationale**: Early layers detect low-level features (edges, corners, textures). As the network goes deeper, these features are combined to form more abstract and complex patterns. Increasing the number of filters provides more capacity for these higher-level representations.\n",
    "\n",
    "## 3. Batch Normalization (`nn.BatchNorm2d`)\n",
    "- **Implementation**: `nn.BatchNorm2d(num_features)` layers are inserted after each convolutional layer, typically *before* the ReLU activation function. `num_features` corresponds to the number of output channels from the preceding convolutional layer.\n",
    "- **Benefits**:\n",
    "    - **Stabilizes Training**: Normalizes the activations of the previous layer by re-centering them to have a mean of 0 and re-scaling them to have a standard deviation of 1 for each channel across the current mini-batch. This helps combat the \"internal covariate shift\" problem.\n",
    "    - **Allows Higher Learning Rates**: Makes the model less sensitive to the scale of parameters and activations, often permitting the use of higher learning rates, which can speed up convergence.\n",
    "    - **Reduces Sensitivity to Initialization**: Training deep networks becomes less dependent on careful weight initialization.\n",
    "    - **Acts as a Regularizer**: Has a slight regularization effect, sometimes reducing the need for other forms of regularization like Dropout (though they are often used together).\n",
    "    - **During `model.eval()`**: Batch Normalization uses the learned running mean and variance (accumulated during training) instead of mini-batch statistics for normalization.\n",
    "\n",
    "## 4. Dropout (`nn.Dropout2d` and `nn.Dropout`)\n",
    "- **Purpose**: A powerful regularization technique to prevent overfitting by randomly deactivating units (neurons or channels) during training.\n",
    "- **Types Used**:\n",
    "    - **`nn.Dropout2d(p=dropout_probability)` (Spatial Dropout)**:\n",
    "        - Applied typically after pooling layers or between convolutional blocks.\n",
    "        - Instead of dropping individual elements, `nn.Dropout2d` randomly zeros out entire *channels* (feature maps) from its input.\n",
    "        - This is often considered more effective for convolutional layers because features in feature maps are spatially correlated. Dropping entire channels encourages the network to learn more diverse and less co-dependent feature representations.\n",
    "    - **`nn.Dropout(p=dropout_probability)` (Standard Dropout)**:\n",
    "        - Applied before the final fully connected classification layer(s).\n",
    "        - Randomly zeros out individual elements (neurons) of its input tensor.\n",
    "- **Behavior**: Dropout is only active during `model.train()` mode. It is automatically disabled during `model.eval()` mode, ensuring deterministic output for inference.\n",
    "\n",
    "## 5. Enhanced Training Workflow with a Validation Set\n",
    "- **Data Split**: The original training dataset is partitioned into a (new, smaller) training subset and a validation subset (e.g., using `torch.utils.data.random_split`).\n",
    "- **Integrated Validation Loop**:\n",
    "    - After each epoch of training on the training subset (with `model.train()` active):\n",
    "        1.  The model is switched to evaluation mode: `model.eval()`. This ensures Dropout is turned off and Batch Normalization uses its running statistics.\n",
    "        2.  Performance metrics (typically loss and accuracy) are computed on the validation set using a `DataLoader` for the validation data.\n",
    "        3.  Crucially, these computations are done within a `with torch.no_grad():` block to disable gradient calculations, saving memory and computation.\n",
    "- **Monitoring for Overfitting**: This process allows for continuous monitoring of the model's ability to generalize to unseen data.\n",
    "    - If training loss/accuracy continues to improve but validation loss/accuracy stagnates or worsens, it's a strong indicator of overfitting. This information can be used for decisions like early stopping or adjusting hyperparameters.\n",
    "\n",
    "## 6. Increased Number of Training Epochs\n",
    "- **Rationale**: More complex models with data augmentation and regularization often"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
