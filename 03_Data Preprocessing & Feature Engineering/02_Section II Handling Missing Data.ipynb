{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c59e237d-7036-440e-96dd-60a29c4d9b2c",
   "metadata": {},
   "source": [
    "This section focuses on identifying and addressing missing values (often represented as `NaN`) in your dataset, which is a crucial step as most machine learning algorithms cannot handle them directly.\n",
    "\n",
    "## Handling Missing Data in Python\n",
    "\n",
    "\n",
    "This document provides a hands-on look at handling missing data:\n",
    "\n",
    "* **Identifying:** Using `Pandas` `.isnull().sum()` and percentages. Mentions visualization libraries like `missingno`.\n",
    "* **Deletion:** Demonstrating row (`.dropna()`) and column (`.dropna(axis=1, thresh=...)`) removal.\n",
    "* **Simple Imputation:** Using `SimpleImputer` with strategies like `mean`, `median` (for numerical), `most_frequent` (for categorical), and `constant`.\n",
    "* **Advanced Imputation:** Introducing `KNNImputer` and `IterativeImputer`, noting their requirement for numerical data and increased complexity.\n",
    "* **Missing Indicators:** Showing how `SimpleImputer(add_indicator=True)` can create binary features flagging imputed values.\n",
    "* **Implementation Notes:** Emphasizing the critical importance of fitting imputers only on training data to prevent data leakage.\n",
    "\n",
    "---\n",
    "\n",
    "This covers the core techniques for addressing missing values in your datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2004a473-b5d8-4fd2-96d7-75167b3fc960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original DataFrame with Missing Values ---\n",
      "    Age   Salary  Gender  Experience    Education\n",
      "0  25.0  50000.0    Male           2     Bachelor\n",
      "1  45.0  80000.0  Female          20       Master\n",
      "2   NaN  60000.0  Female          10     Bachelor\n",
      "3  55.0  95000.0    Male          30          PhD\n",
      "4  22.0  48000.0  Female           1  High School\n",
      "5  38.0      NaN    Male          12       Master\n",
      "6  42.0  72000.0     NaN          15          PhD\n",
      "7   NaN  85000.0    Male          25       Master\n",
      "8  29.0  52000.0  Female           5          NaN\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Age         7 non-null      float64\n",
      " 1   Salary      8 non-null      float64\n",
      " 2   Gender      8 non-null      object \n",
      " 3   Experience  9 non-null      int64  \n",
      " 4   Education   8 non-null      object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 492.0+ bytes\n",
      "------------------------------\n",
      "--- Identifying Missing Values ---\n",
      "Missing values count per column (.isnull().sum()):\n",
      " Age           2\n",
      "Salary        1\n",
      "Gender        1\n",
      "Experience    0\n",
      "Education     1\n",
      "dtype: int64\n",
      "\n",
      "Missing values percentage per column:\n",
      " Age           22.22\n",
      "Salary        11.11\n",
      "Gender        11.11\n",
      "Experience     0.00\n",
      "Education     11.11\n",
      "dtype: float64\n",
      "------------------------------\n",
      "--- Strategy 1: Deletion ---\n",
      "Shape before dropping rows: (9, 5)\n",
      "Shape after dropping rows with any NaN: (4, 5)\n",
      "\n",
      "Shape before dropping columns: (9, 5)\n",
      "Shape after dropping columns > 50% missing: (9, 5)\n",
      "------------------------------\n",
      "--- Strategy 2: Imputation ---\n",
      "Numerical columns: ['Age', 'Salary', 'Experience']\n",
      "Categorical columns: ['Gender', 'Education']\n",
      "\n",
      "--- a) Simple Imputation ---\n",
      "DataFrame after Mean Imputation (Numerical):\n",
      "          Age   Salary  Experience\n",
      "0  25.000000  50000.0         2.0\n",
      "1  45.000000  80000.0        20.0\n",
      "2  36.571429  60000.0        10.0\n",
      "3  55.000000  95000.0        30.0\n",
      "4  22.000000  48000.0         1.0\n",
      "\n",
      "DataFrame after Median Imputation (Numerical):\n",
      "     Age   Salary  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  45.0  80000.0        20.0\n",
      "2  38.0  60000.0        10.0\n",
      "3  55.0  95000.0        30.0\n",
      "4  22.0  48000.0         1.0\n",
      "\n",
      "DataFrame after Mode Imputation (Categorical):\n",
      "    Gender    Education\n",
      "0    Male     Bachelor\n",
      "1  Female       Master\n",
      "2  Female     Bachelor\n",
      "3    Male          PhD\n",
      "4  Female  High School\n",
      "--------------------\n",
      "\n",
      "--- b) Advanced Imputation ---\n",
      "KNN Imputation (on numerical columns):\n",
      "DataFrame after KNN Imputation (Numerical):\n",
      "          Age   Salary  Experience\n",
      "0  25.000000  50000.0         2.0\n",
      "1  45.000000  80000.0        20.0\n",
      "2  30.666667  60000.0        10.0\n",
      "3  55.000000  95000.0        30.0\n",
      "4  22.000000  48000.0         1.0\n",
      "\n",
      "Iterative Imputation (on numerical columns):\n",
      "DataFrame after Iterative Imputation (Numerical):\n",
      "     Age   Salary  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  45.0  80000.0        20.0\n",
      "2  32.4  60000.0        10.0\n",
      "3  55.0  95000.0        30.0\n",
      "4  22.0  48000.0         1.0\n",
      "------------------------------\n",
      "--- Strategy 3: Missing Indicator Feature ---\n",
      "DataFrame after Median Imputation with Missing Indicators (Numerical):\n",
      "     Age   Salary  Experience  missingindicator_Age  missingindicator_Salary\n",
      "0  25.0  50000.0         2.0                   0.0                      0.0\n",
      "1  45.0  80000.0        20.0                   0.0                      0.0\n",
      "2  38.0  60000.0        10.0                   1.0                      0.0\n",
      "3  55.0  95000.0        30.0                   0.0                      0.0\n",
      "4  22.0  48000.0         1.0                   0.0                      0.0\n",
      "------------------------------\n",
      "--- Implementation Notes ---\n",
      "1. Identify and understand the extent and pattern of missing data.\n",
      "2. Choose a strategy (deletion, imputation, indicators) based on the data and problem.\n",
      "3. CRITICAL: In ML workflows, fit imputers ONLY on the training data.\n",
      "4. Apply the *fitted* imputer to transform both training and test data.\n",
      "5. Consider using Pipelines (Section VIII) to manage imputation correctly within cross-validation.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Enable experimental features (like IterativeImputer)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "# Now import imputers\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "\n",
    "# Optional: for visualizing missing data (install with: pip install missingno)\n",
    "# import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Create Sample Data with Missing Values ---\n",
    "data = {\n",
    "    'Age': [25, 45, np.nan, 55, 22, 38, 42, np.nan, 29],\n",
    "    'Salary': [50000, 80000, 60000, 95000, 48000, np.nan, 72000, 85000, 52000],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female', 'Male', np.nan, 'Male', 'Female'],\n",
    "    'Experience': [2, 20, 10, 30, 1, 12, 15, 25, 5],\n",
    "    'Education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'High School', 'Master', 'PhD', 'Master', np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- Original DataFrame with Missing Values ---\")\n",
    "print(df)\n",
    "df.info() # Initial check for non-null counts and dtypes\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 2. Identifying Missing Values ---\n",
    "\n",
    "print(\"--- Identifying Missing Values ---\")\n",
    "\n",
    "# a) Count missing values per column\n",
    "print(\"Missing values count per column (.isnull().sum()):\\n\", df.isnull().sum())\n",
    "\n",
    "# b) Percentage of missing values per column\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"\\nMissing values percentage per column:\\n\", missing_percentage.round(2))\n",
    "\n",
    "# c) Visualizing missingness (using missingno - optional)\n",
    "# Provides visual patterns of missing data.\n",
    "# print(\"\\nVisualizing missing data patterns (requires 'missingno' library)...\")\n",
    "# try:\n",
    "#     import missingno as msno\n",
    "#     msno.matrix(df)\n",
    "#     plt.title(\"Missing Data Matrix\", fontsize=16)\n",
    "#     plt.show()\n",
    "#     msno.heatmap(df)\n",
    "#     plt.title(\"Missing Data Correlation Heatmap\", fontsize=16)\n",
    "#     plt.show()\n",
    "# except ImportError:\n",
    "#     print(\"Install 'missingno' library (`pip install missingno`) to visualize patterns.\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 3. Strategy 1: Deletion ---\n",
    "# Removing rows or columns with missing data. Use with caution due to data loss.\n",
    "\n",
    "print(\"--- Strategy 1: Deletion ---\")\n",
    "# Create copies to avoid modifying the original df for later examples\n",
    "df_copy_del = df.copy()\n",
    "\n",
    "# a) Listwise Deletion (Row Removal)\n",
    "# Remove rows containing *any* NaN values.\n",
    "df_dropped_rows = df_copy_del.dropna() # Default axis=0, how='any'\n",
    "print(f\"Shape before dropping rows: {df_copy_del.shape}\")\n",
    "print(f\"Shape after dropping rows with any NaN: {df_dropped_rows.shape}\")\n",
    "# print(\"\\nDataFrame after dropping rows:\\n\", df_dropped_rows)\n",
    "\n",
    "# b) Column Deletion (Feature Removal)\n",
    "# Remove columns where the percentage of missing values exceeds a threshold.\n",
    "threshold_percent = 50 # Example: Drop columns with more than 50% missing\n",
    "threshold_count = len(df_copy_del) * (1 - threshold_percent / 100)\n",
    "df_dropped_cols = df_copy_del.dropna(axis=1, thresh=threshold_count) # Keep cols with at least threshold_count non-NaNs\n",
    "print(f\"\\nShape before dropping columns: {df_copy_del.shape}\")\n",
    "print(f\"Shape after dropping columns > {threshold_percent}% missing: {df_dropped_cols.shape}\")\n",
    "# print(\"\\nDataFrame after dropping columns:\\n\", df_dropped_cols)\n",
    "\n",
    "# Note: Deletion is simple but often not ideal due to information loss.\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Strategy 2: Imputation (Filling Values) ---\n",
    "# Replacing missing values. Often preferred over deletion.\n",
    "# IMPORTANT: Fit imputers ONLY on training data in a real ML workflow.\n",
    "# For demonstration, we apply to the whole sample DataFrame here.\n",
    "\n",
    "print(\"--- Strategy 2: Imputation ---\")\n",
    "df_copy_imp = df.copy()\n",
    "\n",
    "# Separate columns by type for appropriate imputation\n",
    "numerical_cols = df_copy_imp.select_dtypes(include=np.number).columns\n",
    "categorical_cols = df_copy_imp.select_dtypes(include='object').columns\n",
    "print(f\"Numerical columns: {list(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {list(categorical_cols)}\")\n",
    "\n",
    "# a) Simple Imputation (using SimpleImputer)\n",
    "print(\"\\n--- a) Simple Imputation ---\")\n",
    "\n",
    "# Mean Imputation (Numerical) - Sensitive to outliers\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "# Use .copy() to avoid SettingWithCopyWarning if df_copy_imp is later modified\n",
    "df_copy_imp_mean = df_copy_imp.copy()\n",
    "df_copy_imp_mean[numerical_cols] = imputer_mean.fit_transform(df_copy_imp_mean[numerical_cols])\n",
    "print(\"DataFrame after Mean Imputation (Numerical):\\n\", df_copy_imp_mean[numerical_cols].head())\n",
    "\n",
    "\n",
    "# Median Imputation (Numerical) - Robust to outliers\n",
    "imputer_median = SimpleImputer(strategy='median')\n",
    "# Use .copy() to avoid SettingWithCopyWarning\n",
    "df_copy_imp_median = df_copy_imp.copy()\n",
    "df_copy_imp_median[numerical_cols] = imputer_median.fit_transform(df_copy_imp_median[numerical_cols])\n",
    "print(\"\\nDataFrame after Median Imputation (Numerical):\\n\", df_copy_imp_median[numerical_cols].head())\n",
    "\n",
    "\n",
    "# Mode Imputation (Categorical)\n",
    "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
    "# Use .copy() to avoid SettingWithCopyWarning\n",
    "df_copy_imp_mode = df_copy_imp.copy()\n",
    "df_copy_imp_mode[categorical_cols] = imputer_mode.fit_transform(df_copy_imp_mode[categorical_cols])\n",
    "print(\"\\nDataFrame after Mode Imputation (Categorical):\\n\", df_copy_imp_mode[categorical_cols].head())\n",
    "\n",
    "\n",
    "# Constant Imputation\n",
    "imputer_constant_num = SimpleImputer(strategy='constant', fill_value=-99)\n",
    "imputer_constant_cat = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "# Example application:\n",
    "# df_copy_imp_const = df_copy_imp.copy()\n",
    "# df_copy_imp_const['Salary'] = imputer_constant_num.fit_transform(df_copy_imp_const[['Salary']])\n",
    "# df_copy_imp_const['Education'] = imputer_constant_cat.fit_transform(df_copy_imp_const[['Education']])\n",
    "# print(\"\\nDataFrame after Constant Imputation (Example):\\n\", df_copy_imp_const[['Salary', 'Education']].head())\n",
    "\n",
    "# Reset for next examples\n",
    "df_copy_imp = df.copy()\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# b) Advanced Imputation\n",
    "print(\"\\n--- b) Advanced Imputation ---\")\n",
    "\n",
    "# KNN Imputation (Uses k-Nearest Neighbors)\n",
    "# Requires all data to be numerical. Need to encode categoricals first (covered in Section III).\n",
    "# For demonstration, let's impute only numerical columns.\n",
    "print(\"KNN Imputation (on numerical columns):\")\n",
    "df_copy_knn = df.copy() # Use a fresh copy\n",
    "try:\n",
    "    knn_imputer = KNNImputer(n_neighbors=3) # Use 3 neighbors\n",
    "    df_knn_imputed_num = knn_imputer.fit_transform(df_copy_knn[numerical_cols])\n",
    "    df_copy_knn[numerical_cols] = df_knn_imputed_num\n",
    "    print(\"DataFrame after KNN Imputation (Numerical):\\n\", df_copy_knn[numerical_cols].head())\n",
    "except Exception as e:\n",
    "    print(f\"KNN Imputation failed (might need encoding first): {e}\")\n",
    "\n",
    "\n",
    "# Multivariate Imputation (IterativeImputer - e.g., MICE)\n",
    "# Models each feature with missing values as a function of other features.\n",
    "# Also requires numerical data.\n",
    "print(\"\\nIterative Imputation (on numerical columns):\")\n",
    "df_copy_iter = df.copy() # Use a fresh copy\n",
    "try:\n",
    "    # Note: enable_iterative_imputer was imported at the top\n",
    "    iter_imputer = IterativeImputer(max_iter=10, random_state=42) # max_iter controls iterations\n",
    "    df_iter_imputed_num = iter_imputer.fit_transform(df_copy_iter[numerical_cols])\n",
    "    df_copy_iter[numerical_cols] = df_iter_imputed_num\n",
    "    print(\"DataFrame after Iterative Imputation (Numerical):\\n\", df_copy_iter[numerical_cols].head().round(2))\n",
    "except Exception as e:\n",
    "    print(f\"Iterative Imputation failed (might need encoding first): {e}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Strategy 3: Missing Indicator Feature ---\n",
    "# Add binary columns indicating where data was originally missing.\n",
    "# Can be used alongside imputation.\n",
    "\n",
    "print(\"--- Strategy 3: Missing Indicator Feature ---\")\n",
    "df_copy_indicator = df.copy() # Use a fresh copy\n",
    "\n",
    "# Using SimpleImputer with add_indicator=True\n",
    "imputer_indicator = SimpleImputer(strategy='median', add_indicator=True)\n",
    "\n",
    "# Apply to numerical features\n",
    "df_imputed_with_indicator_num = imputer_indicator.fit_transform(df_copy_indicator[numerical_cols])\n",
    "# Get feature names (original + indicator names)\n",
    "indicator_names = imputer_indicator.get_feature_names_out(numerical_cols)\n",
    "df_processed_num = pd.DataFrame(df_imputed_with_indicator_num, columns=indicator_names)\n",
    "\n",
    "print(\"DataFrame after Median Imputation with Missing Indicators (Numerical):\\n\", df_processed_num.head())\n",
    "\n",
    "# Note: The indicator columns show True where the original value was NaN.\n",
    "# This allows the model to potentially learn from the pattern of missingness.\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 6. Implementation Notes (Recap) ---\n",
    "print(\"--- Implementation Notes ---\")\n",
    "print(\"1. Identify and understand the extent and pattern of missing data.\")\n",
    "print(\"2. Choose a strategy (deletion, imputation, indicators) based on the data and problem.\")\n",
    "print(\"3. CRITICAL: In ML workflows, fit imputers ONLY on the training data.\")\n",
    "print(\"4. Apply the *fitted* imputer to transform both training and test data.\")\n",
    "print(\"5. Consider using Pipelines (Section VIII) to manage imputation correctly within cross-validation.\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7f176-51bb-482c-b5db-d8c7f3889e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
