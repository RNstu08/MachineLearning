{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c08cfb-7a07-4e7a-8fc7-24b800eac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de838b9-745c-476e-91c4-1c677d989ba2",
   "metadata": {},
   "source": [
    "#### 1. Prepare Sample Data ---\n",
    "- Create a DataFrame with missing values, duplicates, and mixed types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfa4fe3-b8eb-4f05-8991-d438377ca0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "0      101       A        X      10.50       5.0    Shipped       C100\n",
      "1      102       B        Y      25.00       2.0    Pending       C200\n",
      "2      103       A        X      10.50       NaN    Shipped       C100\n",
      "3      104       C        X       5.25      10.0    Shipped       C300\n",
      "4      101       A        X      10.50       5.0    Shipped       C100\n",
      "5      105       B        Y      25.00       3.0    Pending       C400\n",
      "6      106       C        Z        NaN       7.0  Cancelled       C200\n",
      "7      107       D        Y       8.00       4.0    Shipped       C500\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'OrderID': [101, 102, 103, 104, 101, 105, 106, 107], # Duplicate OrderID 101\n",
    "    'Product': ['A', 'B', 'A', 'C', 'A', 'B', 'C', 'D'],\n",
    "    'Category': ['X', 'Y', 'X', 'X', 'X', 'Y', 'Z', 'Y'],\n",
    "    'UnitPrice': [10.5, 25.0, 10.5, 5.25, 10.5, 25.0, np.nan, 8.0], # Missing UnitPrice\n",
    "    'Quantity': [5, 2, np.nan, 10, 5, 3, 7, 4], # Missing Quantity\n",
    "    'Status': ['Shipped', 'Pending', 'Shipped', 'Shipped', 'Shipped', 'Pending', 'Cancelled', 'Shipped'],\n",
    "    'CustomerID': ['C100', 'C200', 'C100', 'C300', 'C100', 'C400', 'C200', 'C500']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cc63dc-cb15-449c-b0c5-b5e5b6464e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fully duplicate row\n",
    "duplicate_row = pd.DataFrame([df.iloc[0].to_dict()]) # Get first row as dict, make DataFrame\n",
    "df = pd.concat([df, duplicate_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb57361-18df-4ee3-885d-1339d083152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Messy DataFrame ---\n",
      "   OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "0      101       A        X      10.50       5.0    Shipped       C100\n",
      "1      102       B        Y      25.00       2.0    Pending       C200\n",
      "2      103       A        X      10.50       NaN    Shipped       C100\n",
      "3      104       C        X       5.25      10.0    Shipped       C300\n",
      "4      101       A        X      10.50       5.0    Shipped       C100\n",
      "5      105       B        Y      25.00       3.0    Pending       C400\n",
      "6      106       C        Z        NaN       7.0  Cancelled       C200\n",
      "7      107       D        Y       8.00       4.0    Shipped       C500\n",
      "8      101       A        X      10.50       5.0    Shipped       C100\n",
      "------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   OrderID     9 non-null      int64  \n",
      " 1   Product     9 non-null      object \n",
      " 2   Category    9 non-null      object \n",
      " 3   UnitPrice   8 non-null      float64\n",
      " 4   Quantity    8 non-null      float64\n",
      " 5   Status      9 non-null      object \n",
      " 6   CustomerID  9 non-null      object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 636.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Original Messy DataFrame ---\")\n",
    "print(df)\n",
    "print(\"-\" * 30)\n",
    "df.info() # Show initial dtypes and non-null counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d05e1-5e6f-4275-ae9d-8cb228569202",
   "metadata": {},
   "source": [
    "#### 2. Handling Missing Data (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2028713f-481b-44ca-b426-789c6f13b16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for missing values (.isnull()):\n",
      "    OrderID  Product  Category  UnitPrice  Quantity  Status  CustomerID\n",
      "0    False    False     False      False     False   False       False\n",
      "1    False    False     False      False     False   False       False\n",
      "2    False    False     False      False      True   False       False\n",
      "3    False    False     False      False     False   False       False\n",
      "4    False    False     False      False     False   False       False\n",
      "5    False    False     False      False     False   False       False\n",
      "6    False    False     False       True     False   False       False\n",
      "7    False    False     False      False     False   False       False\n",
      "\n",
      "Check for non-missing values (.notnull()):\n",
      "    OrderID  Product  Category  UnitPrice  Quantity  Status  CustomerID\n",
      "0     True     True      True       True      True    True        True\n",
      "1     True     True      True       True      True    True        True\n",
      "2     True     True      True       True     False    True        True\n",
      "3     True     True      True       True      True    True        True\n",
      "4     True     True      True       True      True    True        True\n",
      "5     True     True      True       True      True    True        True\n",
      "6     True     True      True      False      True    True        True\n",
      "7     True     True      True       True      True    True        True\n"
     ]
    }
   ],
   "source": [
    "# a) Identifying missing data\n",
    "print(\"Check for missing values (.isnull()):\\n\", df.isnull())\n",
    "print(\"\\nCheck for non-missing values (.notnull()):\\n\", df.notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affb8477-e639-4a25-98bd-474ff4c57c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of missing values per column (.isnull().sum()):\n",
      " OrderID       0\n",
      "Product       0\n",
      "Category      0\n",
      "UnitPrice     1\n",
      "Quantity      1\n",
      "Status        0\n",
      "CustomerID    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "print(\"\\nCount of missing values per column (.isnull().sum()):\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb402d8d-1a53-4256-9545-98880c29323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping rows with any NaN (.dropna()):\n",
      "    OrderID Product Category  UnitPrice  Quantity   Status CustomerID\n",
      "0      101       A        X      10.50       5.0  Shipped       C100\n",
      "1      102       B        Y      25.00       2.0  Pending       C200\n",
      "3      104       C        X       5.25      10.0  Shipped       C300\n",
      "4      101       A        X      10.50       5.0  Shipped       C100\n",
      "5      105       B        Y      25.00       3.0  Pending       C400\n",
      "7      107       D        Y       8.00       4.0  Shipped       C500\n"
     ]
    }
   ],
   "source": [
    "# b) Dropping missing data (.dropna())\n",
    "# Drop rows containing *any* missing values\n",
    "\n",
    "df_dropped_rows = df.dropna() # Default axis=0 (rows), how='any'\n",
    "print(\"DataFrame after dropping rows with any NaN (.dropna()):\\n\", df_dropped_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e48ba3e-3cc9-4c8c-a303-59dcaeb935e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping columns with any NaN (.dropna(axis=1)):\n",
      "    OrderID Product Category     Status CustomerID\n",
      "0      101       A        X    Shipped       C100\n",
      "1      102       B        Y    Pending       C200\n",
      "2      103       A        X    Shipped       C100\n",
      "3      104       C        X    Shipped       C300\n",
      "4      101       A        X    Shipped       C100\n",
      "5      105       B        Y    Pending       C400\n",
      "6      106       C        Z  Cancelled       C200\n",
      "7      107       D        Y    Shipped       C500\n"
     ]
    }
   ],
   "source": [
    "# Drop columns containing *any* missing values\n",
    "df_dropped_cols = df.dropna(axis=1) # axis='columns' or 1\n",
    "print(\"\\nDataFrame after dropping columns with any NaN (.dropna(axis=1)):\\n\", df_dropped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b7fac3-1db7-42e6-8572-964446d49a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows only if *all* values are missing (less common)\n",
    "# df_dropped_all_nan = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d99985a-89eb-4796-9966-3b0e9c23cefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping rows with less than 6 non-NaN values (.dropna(thresh=6)):\n",
      "    OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "0      101       A        X      10.50       5.0    Shipped       C100\n",
      "1      102       B        Y      25.00       2.0    Pending       C200\n",
      "2      103       A        X      10.50       NaN    Shipped       C100\n",
      "3      104       C        X       5.25      10.0    Shipped       C300\n",
      "4      101       A        X      10.50       5.0    Shipped       C100\n",
      "5      105       B        Y      25.00       3.0    Pending       C400\n",
      "6      106       C        Z        NaN       7.0  Cancelled       C200\n",
      "7      107       D        Y       8.00       4.0    Shipped       C500\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that do not have at least 'thresh' non-NaN values\n",
    "# Keep rows with at least 6 non-NaN values (out of 7 columns)\n",
    "\n",
    "df_dropped_thresh = df.dropna(thresh=6)\n",
    "print(\"\\nDataFrame after dropping rows with less than 6 non-NaN values (.dropna(thresh=6)):\\n\", df_dropped_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cb9b34-9f60-4f51-b028-a4b4af44f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after dropping rows with NaN in 'UnitPrice' or 'Quantity' (.dropna(subset=...)):\n",
      "    OrderID Product Category  UnitPrice  Quantity   Status CustomerID\n",
      "0      101       A        X      10.50       5.0  Shipped       C100\n",
      "1      102       B        Y      25.00       2.0  Pending       C200\n",
      "3      104       C        X       5.25      10.0  Shipped       C300\n",
      "4      101       A        X      10.50       5.0  Shipped       C100\n",
      "5      105       B        Y      25.00       3.0  Pending       C400\n",
      "7      107       D        Y       8.00       4.0  Shipped       C500\n"
     ]
    }
   ],
   "source": [
    "# Drop NaNs only in specific columns using 'subset'\n",
    "df_dropped_subset = df.dropna(subset=['UnitPrice', 'Quantity'])\n",
    "print(\"\\nDataFrame after dropping rows with NaN in 'UnitPrice' or 'Quantity' (.dropna(subset=...)):\\n\", df_dropped_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72576e46-58b3-4321-9a83-9e1763336408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing data:\n",
      "DataFrame after filling all NaN with 0 (.fillna(0)):\n",
      "    UnitPrice  Quantity\n",
      "0      10.50       5.0\n",
      "1      25.00       2.0\n",
      "2      10.50       0.0\n",
      "3       5.25      10.0\n",
      "4      10.50       5.0\n"
     ]
    }
   ],
   "source": [
    "# c) Filling missing data (.fillna())\n",
    "print(\"Filling missing data:\")\n",
    "\n",
    "# Fill all NaN with a specific value (e.g., 0)\n",
    "df_filled_zero = df.fillna(0)\n",
    "\n",
    "print(\"DataFrame after filling all NaN with 0 (.fillna(0)):\\n\", df_filled_zero[['UnitPrice', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7805cae-5975-4955-92e7-e3549e9a70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after filling NaN with column mean/median (.fillna(value=dict)):\n",
      "    UnitPrice  Quantity\n",
      "0      10.50       5.0\n",
      "1      25.00       2.0\n",
      "2      10.50       5.0\n",
      "3       5.25      10.0\n",
      "4      10.50       5.0\n"
     ]
    }
   ],
   "source": [
    "# Fill NaN in specific columns with different values\n",
    "fill_values = {'UnitPrice': df['UnitPrice'].mean(), 'Quantity': df['Quantity'].median()}\n",
    "\n",
    "df_filled_specific = df.fillna(value=fill_values)\n",
    "print(\"\\nDataFrame after filling NaN with column mean/median (.fillna(value=dict)):\\n\", df_filled_specific[['UnitPrice', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79ccfb7b-f5e9-4f0d-a30d-bec9d8e506fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after forward fill (.fillna(method='ffill')):\n",
      "    UnitPrice  Quantity\n",
      "0      10.50       5.0\n",
      "1      25.00       2.0\n",
      "2      10.50       2.0\n",
      "3       5.25      10.0\n",
      "4      10.50       5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\93477861.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill = df.fillna(method='ffill') # or .ffill()\n"
     ]
    }
   ],
   "source": [
    "# Forward fill (propagate last valid observation forward)\n",
    "df_ffill = df.fillna(method='ffill') # or .ffill()\n",
    "print(\"\\nDataFrame after forward fill (.fillna(method='ffill')):\\n\", df_ffill[['UnitPrice', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be2025f-ebf3-469a-8ed8-03f2544de535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after backward fill (.fillna(method='bfill')):\n",
      "    UnitPrice  Quantity\n",
      "0      10.50       5.0\n",
      "1      25.00       2.0\n",
      "2      10.50      10.0\n",
      "3       5.25      10.0\n",
      "4      10.50       5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\1623142785.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_bfill = df.fillna(method='bfill') # or .bfill()\n"
     ]
    }
   ],
   "source": [
    "# Backward fill (propagate next valid observation backward)\n",
    "df_bfill = df.fillna(method='bfill') # or .bfill()\n",
    "print(\"\\nDataFrame after backward fill (.fillna(method='bfill')):\\n\", df_bfill[['UnitPrice', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d857568e-b4ab-4a28-bf2e-f7ea9cf24a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after forward fill with limit=1:\n",
      "    UnitPrice  Quantity\n",
      "0      10.50       5.0\n",
      "1      25.00       2.0\n",
      "2      10.50       2.0\n",
      "3       5.25      10.0\n",
      "4      10.50       5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\3781235180.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill_limit = df.fillna(method='ffill', limit=1)\n"
     ]
    }
   ],
   "source": [
    "# Limit the number of consecutive fills\n",
    "df_ffill_limit = df.fillna(method='ffill', limit=1)\n",
    "print(\"\\nDataFrame after forward fill with limit=1:\\n\", df_ffill_limit[['UnitPrice', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e5cd3d1-e272-4a2c-9c2f-9118b2f48a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after filling NaNs for subsequent steps:\n",
      "    OrderID Product Category  UnitPrice  Quantity   Status CustomerID\n",
      "0      101       A        X      10.50       5.0  Shipped       C100\n",
      "1      102       B        Y      25.00       2.0  Pending       C200\n",
      "2      103       A        X      10.50       5.0  Shipped       C100\n",
      "3      104       C        X       5.25      10.0  Shipped       C300\n",
      "4      101       A        X      10.50       5.0  Shipped       C100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\4132826043.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['UnitPrice'].fillna(df['UnitPrice'].mean(), inplace=True) # inplace=True modifies df directly\n",
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\4132826043.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Quantity'].fillna(df['Quantity'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# For this example, let's fill UnitPrice with mean and Quantity with median for further steps\n",
    "df['UnitPrice'].fillna(df['UnitPrice'].mean(), inplace=True) # inplace=True modifies df directly\n",
    "df['Quantity'].fillna(df['Quantity'].median(), inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after filling NaNs for subsequent steps:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2850f-c281-478d-af13-5963ca6e4ee2",
   "metadata": {},
   "source": [
    "#### 3. Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c74a862-4bd7-4dcf-9c83-86f0a715ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Handling Duplicates ---\n",
      "Check for duplicate rows (.duplicated()):\n",
      " 0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n",
      "\n",
      "Check for duplicates based on 'OrderID' (.duplicated(subset=['OrderID'])):\n",
      " 0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n",
      "\n",
      "Check for duplicates, keeping last (.duplicated(keep='last')):\n",
      " 0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n",
      "\n",
      "Mark all duplicates as True (.duplicated(keep=False)):\n",
      " 0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "dtype: bool\n",
      "--------------------\n",
      "DataFrame after dropping duplicate rows (.drop_duplicates()):\n",
      "    OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "0      101       A        X  10.500000       5.0    Shipped       C100\n",
      "1      102       B        Y  25.000000       2.0    Pending       C200\n",
      "2      103       A        X  10.500000       5.0    Shipped       C100\n",
      "3      104       C        X   5.250000      10.0    Shipped       C300\n",
      "5      105       B        Y  25.000000       3.0    Pending       C400\n",
      "6      106       C        Z  13.535714       7.0  Cancelled       C200\n",
      "7      107       D        Y   8.000000       4.0    Shipped       C500\n",
      "Original shape: (8, 7), After drop_duplicates: (7, 7)\n",
      "\n",
      "DataFrame after dropping duplicates based on 'OrderID' & 'CustomerID', keeping last:\n",
      "    OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "1      102       B        Y  25.000000       2.0    Pending       C200\n",
      "2      103       A        X  10.500000       5.0    Shipped       C100\n",
      "3      104       C        X   5.250000      10.0    Shipped       C300\n",
      "4      101       A        X  10.500000       5.0    Shipped       C100\n",
      "5      105       B        Y  25.000000       3.0    Pending       C400\n",
      "6      106       C        Z  13.535714       7.0  Cancelled       C200\n",
      "7      107       D        Y   8.000000       4.0    Shipped       C500\n",
      "\n",
      "DataFrame after dropping full duplicates for subsequent steps:\n",
      "    OrderID Product Category  UnitPrice  Quantity     Status CustomerID\n",
      "0      101       A        X  10.500000       5.0    Shipped       C100\n",
      "1      102       B        Y  25.000000       2.0    Pending       C200\n",
      "2      103       A        X  10.500000       5.0    Shipped       C100\n",
      "3      104       C        X   5.250000      10.0    Shipped       C300\n",
      "4      105       B        Y  25.000000       3.0    Pending       C400\n",
      "5      106       C        Z  13.535714       7.0  Cancelled       C200\n",
      "6      107       D        Y   8.000000       4.0    Shipped       C500\n",
      "------------------------------\n",
      "--- Data Type Conversion ---\n",
      "Original dtypes:\n",
      " OrderID         int64\n",
      "Product        object\n",
      "Category       object\n",
      "UnitPrice     float64\n",
      "Quantity      float64\n",
      "Status         object\n",
      "CustomerID     object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion (.astype()):\n",
      " OrderID         object\n",
      "Product         object\n",
      "Category      category\n",
      "UnitPrice      float64\n",
      "Quantity         int64\n",
      "Status          object\n",
      "CustomerID      object\n",
      "dtype: object\n",
      "\n",
      "Category codes:\n",
      " 0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    2\n",
      "6    1\n",
      "dtype: int8\n",
      "Category values:\n",
      " Index(['X', 'Y', 'Z'], dtype='object')\n",
      "------------------------------\n",
      "--- Renaming Columns & Index ---\n",
      "DataFrame after renaming columns:\n",
      " Index(['OrderID', 'Product', 'Category', 'Price_per_Unit', 'Quantity',\n",
      "       'Status', 'CustID'],\n",
      "      dtype='object')\n",
      "------------------------------\n",
      "--- Applying Functions ---\n",
      "DataFrame with Status mapped to codes (.map()):\n",
      "     Status  Status_Code\n",
      "0  Shipped            1\n",
      "1  Pending            0\n",
      "2  Shipped            1\n",
      "3  Shipped            1\n",
      "4  Pending            0\n",
      "\n",
      "DataFrame with Total_Price calculated using .apply(axis=1):\n",
      "    UnitPrice  Quantity  Total_Price\n",
      "0      10.50         5         52.5\n",
      "1      25.00         2         50.0\n",
      "2      10.50         5         52.5\n",
      "3       5.25        10         52.5\n",
      "4      25.00         3         75.0\n",
      "\n",
      "Range (max-min) for numerical columns using .apply(axis=0):\n",
      " UnitPrice      19.75\n",
      "Quantity        8.00\n",
      "Status_Code     2.00\n",
      "Total_Price    62.75\n",
      "dtype: float64\n",
      "------------------------------\n",
      "--- Replacing Values ---\n",
      "DataFrame after replacing 'A' with 'Product_A':\n",
      "      Product\n",
      "0  Product_A\n",
      "1          B\n",
      "2  Product_A\n",
      "3          C\n",
      "4          B\n",
      "\n",
      "DataFrame after replacing 'Pending'/'Cancelled' with 'Not Shipped':\n",
      "         Status\n",
      "0      Shipped\n",
      "1  Not Shipped\n",
      "2      Shipped\n",
      "3      Shipped\n",
      "4  Not Shipped\n",
      "\n",
      "DataFrame after replacing using dictionary:\n",
      "   Category    Status\n",
      "0    Cat_X  Complete\n",
      "1    Cat_Y   Pending\n",
      "2    Cat_X  Complete\n",
      "3    Cat_X  Complete\n",
      "4    Cat_Y   Pending\n",
      "------------------------------\n",
      "--- Sorting ---\n",
      "DataFrame sorted by UnitPrice descending:\n",
      "   OrderID Product Category  UnitPrice  Quantity     Status CustomerID  \\\n",
      "1     102       B        Y  25.000000         2    Pending       C200   \n",
      "4     105       B        Y  25.000000         3    Pending       C400   \n",
      "5     106       C        Z  13.535714         7  Cancelled       C200   \n",
      "2     103       A        X  10.500000         5    Shipped       C100   \n",
      "0     101       A        X  10.500000         5    Shipped       C100   \n",
      "\n",
      "   Status_Code  Total_Price  \n",
      "1            0        50.00  \n",
      "4            0        75.00  \n",
      "5           -1        94.75  \n",
      "2            1        52.50  \n",
      "0            1        52.50  \n",
      "\n",
      "DataFrame sorted by Category, then Product:\n",
      "   OrderID Product Category  UnitPrice  Quantity     Status CustomerID  \\\n",
      "0     101       A        X  10.500000         5    Shipped       C100   \n",
      "2     103       A        X  10.500000         5    Shipped       C100   \n",
      "3     104       C        X   5.250000        10    Shipped       C300   \n",
      "1     102       B        Y  25.000000         2    Pending       C200   \n",
      "4     105       B        Y  25.000000         3    Pending       C400   \n",
      "6     107       D        Y   8.000000         4    Shipped       C500   \n",
      "5     106       C        Z  13.535714         7  Cancelled       C200   \n",
      "\n",
      "   Status_Code  Total_Price  \n",
      "0            1        52.50  \n",
      "2            1        52.50  \n",
      "3            1        52.50  \n",
      "1            0        50.00  \n",
      "4            0        75.00  \n",
      "6            1        32.00  \n",
      "5           -1        94.75  \n",
      "\n",
      "DataFrame sorted by index descending:\n",
      "   OrderID Product Category  UnitPrice  Quantity     Status CustomerID  \\\n",
      "6     107       D        Y   8.000000         4    Shipped       C500   \n",
      "5     106       C        Z  13.535714         7  Cancelled       C200   \n",
      "4     105       B        Y  25.000000         3    Pending       C400   \n",
      "3     104       C        X   5.250000        10    Shipped       C300   \n",
      "2     103       A        X  10.500000         5    Shipped       C100   \n",
      "\n",
      "   Status_Code  Total_Price  \n",
      "6            1        32.00  \n",
      "5           -1        94.75  \n",
      "4            0        75.00  \n",
      "3            1        52.50  \n",
      "2            1        52.50  \n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\king\\AppData\\Local\\Temp\\ipykernel_11084\\484319391.py:123: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df_replaced_dict = df.replace({'Category': {'X': 'Cat_X', 'Y': 'Cat_Y'}, 'Status': {'Shipped': 'Complete'}})\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Handling Duplicates ---\")\n",
    "\n",
    "# a) Identifying duplicate rows (.duplicated())\n",
    "# Returns a boolean Series indicating which rows are duplicates\n",
    "# By default, keeps the first occurrence ('first') as non-duplicate\n",
    "print(\"Check for duplicate rows (.duplicated()):\\n\", df.duplicated())\n",
    "\n",
    "# Identify duplicates based on specific columns\n",
    "print(\"\\nCheck for duplicates based on 'OrderID' (.duplicated(subset=['OrderID'])):\\n\", df.duplicated(subset=['OrderID']))\n",
    "\n",
    "# Keep the last occurrence as non-duplicate\n",
    "print(\"\\nCheck for duplicates, keeping last (.duplicated(keep='last')):\\n\", df.duplicated(keep='last'))\n",
    "\n",
    "# Mark all duplicates as True\n",
    "print(\"\\nMark all duplicates as True (.duplicated(keep=False)):\\n\", df.duplicated(keep=False))\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# b) Dropping duplicate rows (.drop_duplicates())\n",
    "# Returns DataFrame with duplicates removed\n",
    "# Keeps 'first' occurrence by default\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"DataFrame after dropping duplicate rows (.drop_duplicates()):\\n\", df_no_duplicates)\n",
    "print(f\"Original shape: {df.shape}, After drop_duplicates: {df_no_duplicates.shape}\")\n",
    "\n",
    "# Drop duplicates based on specific columns, keeping the last occurrence\n",
    "df_no_dup_subset = df.drop_duplicates(subset=['OrderID', 'CustomerID'], keep='last')\n",
    "print(\"\\nDataFrame after dropping duplicates based on 'OrderID' & 'CustomerID', keeping last:\\n\", df_no_dup_subset)\n",
    "\n",
    "# For subsequent steps, let's work with the version where full row duplicates are dropped\n",
    "df = df.drop_duplicates().reset_index(drop=True) # Reset index after dropping\n",
    "print(\"\\nDataFrame after dropping full duplicates for subsequent steps:\\n\", df)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 4. Data Type Conversion (.astype()) ---\n",
    "\n",
    "print(\"--- Data Type Conversion ---\")\n",
    "print(\"Original dtypes:\\n\", df.dtypes)\n",
    "\n",
    "# Convert Quantity (currently float due to NaN fill) to integer\n",
    "df['Quantity'] = df['Quantity'].astype(int)\n",
    "\n",
    "# Convert OrderID to string (object)\n",
    "df['OrderID'] = df['OrderID'].astype(str)\n",
    "\n",
    "# Convert Category to a memory-efficient 'category' type\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "\n",
    "print(\"\\nData types after conversion (.astype()):\\n\", df.dtypes)\n",
    "# Note: 'category' type can save memory and speed up operations like groupbys\n",
    "print(\"\\nCategory codes:\\n\", df['Category'].cat.codes) # Internal integer representation\n",
    "print(\"Category values:\\n\", df['Category'].cat.categories) # Unique category values\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 5. Renaming Columns & Index (.rename()) ---\n",
    "\n",
    "print(\"--- Renaming Columns & Index ---\")\n",
    "# Rename specific columns using a dictionary\n",
    "df_renamed = df.rename(columns={'UnitPrice': 'Price_per_Unit', 'CustomerID': 'CustID'})\n",
    "print(\"DataFrame after renaming columns:\\n\", df_renamed.columns)\n",
    "\n",
    "# Rename index labels (if index wasn't reset) - using a function/lambda\n",
    "# df.index = pd.RangeIndex(start=1000, stop=1000+len(df)) # Example: Set a new index first\n",
    "# df_renamed_index = df.rename(index=lambda x: f\"Row_{x}\")\n",
    "# print(\"\\nDataFrame after renaming index:\\n\", df_renamed_index.head())\n",
    "\n",
    "# Rename can also use inplace=True\n",
    "# df.rename(columns={'Status': 'Order_Status'}, inplace=True)\n",
    "# print(\"\\nOriginal DataFrame columns after inplace rename:\\n\", df.columns)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 6. Applying Functions ---\n",
    "\n",
    "print(\"--- Applying Functions ---\")\n",
    "\n",
    "# a) .map() (Series method - element-wise, often for substitution/mapping)\n",
    "# Create a mapping for Status\n",
    "status_map = {'Shipped': 1, 'Pending': 0, 'Cancelled': -1}\n",
    "df['Status_Code'] = df['Status'].map(status_map)\n",
    "print(\"DataFrame with Status mapped to codes (.map()):\\n\", df[['Status', 'Status_Code']].head())\n",
    "\n",
    "# b) .apply() (DataFrame method - row-wise or column-wise)\n",
    "# Apply a function along an axis (axis=0 for columns, axis=1 for rows)\n",
    "\n",
    "# Example: Calculate Total Price (row-wise)\n",
    "def calculate_total(row):\n",
    "    # Ensure Price_per_Unit exists if using df_renamed, else use UnitPrice\n",
    "    price_col = 'Price_per_Unit' if 'Price_per_Unit' in row.index else 'UnitPrice'\n",
    "    return row[price_col] * row['Quantity']\n",
    "\n",
    "# Use the original df for this example\n",
    "df['Total_Price'] = df.apply(calculate_total, axis=1)\n",
    "print(\"\\nDataFrame with Total_Price calculated using .apply(axis=1):\\n\", df[['UnitPrice', 'Quantity', 'Total_Price']].head())\n",
    "\n",
    "# Example: Calculate range (max-min) for numerical columns (column-wise)\n",
    "numerical_cols = df.select_dtypes(include=np.number) # Select only numerical columns\n",
    "column_ranges = numerical_cols.apply(lambda x: x.max() - x.min(), axis=0) # axis=0 is default\n",
    "print(\"\\nRange (max-min) for numerical columns using .apply(axis=0):\\n\", column_ranges)\n",
    "\n",
    "# c) .applymap() (DataFrame method - element-wise) - Use less often, consider .map or vectorization\n",
    "# Example: Convert all string columns to uppercase (if they are strings)\n",
    "# def to_upper_if_str(x):\n",
    "#     return x.upper() if isinstance(x, str) else x\n",
    "# df_upper = df.applymap(to_upper_if_str) # Apply to every element\n",
    "# print(\"\\nDataFrame after applying uppercase function with applymap:\\n\", df_upper.head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 7. Replacing Values (.replace()) ---\n",
    "\n",
    "print(\"--- Replacing Values ---\")\n",
    "# Replace a single value across the whole DataFrame\n",
    "df_replaced_A = df.replace('A', 'Product_A')\n",
    "print(\"DataFrame after replacing 'A' with 'Product_A':\\n\", df_replaced_A[['Product']].head())\n",
    "\n",
    "# Replace multiple values with a single value\n",
    "df_replaced_status = df.replace(['Pending', 'Cancelled'], 'Not Shipped')\n",
    "print(\"\\nDataFrame after replacing 'Pending'/'Cancelled' with 'Not Shipped':\\n\", df_replaced_status[['Status']].head())\n",
    "\n",
    "# Replace multiple values with different values using a dictionary\n",
    "df_replaced_dict = df.replace({'Category': {'X': 'Cat_X', 'Y': 'Cat_Y'}, 'Status': {'Shipped': 'Complete'}})\n",
    "print(\"\\nDataFrame after replacing using dictionary:\\n\", df_replaced_dict[['Category', 'Status']].head())\n",
    "\n",
    "# Replace using regular expressions (regex=True)\n",
    "# df_replaced_regex = df.replace(r'^C(\\d+)$', r'Customer_\\1', regex=True) # Example: Replace C100 -> Customer_100\n",
    "# print(\"\\nDataFrame after replacing using regex:\\n\", df_replaced_regex[['CustomerID']].head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 8. Sorting (.sort_values(), .sort_index()) ---\n",
    "\n",
    "print(\"--- Sorting ---\")\n",
    "# Sort by a single column (.sort_values())\n",
    "df_sorted_sales = df.sort_values(by='UnitPrice', ascending=False) # Sort by UnitPrice descending\n",
    "print(\"DataFrame sorted by UnitPrice descending:\\n\", df_sorted_sales.head())\n",
    "\n",
    "# Sort by multiple columns\n",
    "df_sorted_multi = df.sort_values(by=['Category', 'Product']) # Sort by Category, then Product\n",
    "print(\"\\nDataFrame sorted by Category, then Product:\\n\", df_sorted_multi)\n",
    "\n",
    "# Sort by index (.sort_index())\n",
    "df_sorted_index = df.sort_index(ascending=False) # Sort by index descending\n",
    "print(\"\\nDataFrame sorted by index descending:\\n\", df_sorted_index.head())\n",
    "\n",
    "# Sorting can also use inplace=True\n",
    "# df.sort_values(by='Quantity', inplace=True)\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a4042-c3a2-43df-b0be-0c01a2f5aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
